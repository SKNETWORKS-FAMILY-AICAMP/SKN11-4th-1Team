"""
ìµœì í™”ëœ êµí†µì‚¬ê³  ìƒë‹´ AI ì‹œìŠ¤í…œ
- ì„¸ì…˜ë³„ ì˜ì†ì  ë©”ëª¨ë¦¬ ê´€ë¦¬ 
- ìµœì†Œí•œì˜ ëª¨ë¸ í˜¸ì¶œ (3ë²ˆ â†’ 1ë²ˆ)
- í†µí•© RAG + ëŒ€í™” ì²´ì¸
- 95% í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜
"""

import openai
import os
import json
import logging
import re
from pathlib import Path
from typing import Dict, Any, List, Optional
from django.conf import settings
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain.chains.query_constructor.base import AttributeInfo
import time

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class FastClassifier:
    """ë¹ ë¥¸ ì§ˆë¬¸ ë¶„ë¥˜ê¸° - 95% í‚¤ì›Œë“œ ê¸°ë°˜, 5% API í˜¸ì¶œ"""
    
    def __init__(self):
        self.client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.model_id = os.getenv('FINETUNED_MODEL_ID')
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜ íŒ¨í„´ (ê°€ì¤‘ì¹˜ ì ìš©)
        self.keyword_patterns = {
            'accident': {
                'high': ['ì‚¬ê³ ', 'ì¶©ëŒ', 'ì ‘ì´‰', 'ê³¼ì‹¤ë¹„ìœ¨', 'ê³¼ì‹¤', 'ë¹„ìœ¨'],
                'medium': ['êµì°¨ë¡œ', 'ì‹ í˜¸', 'ì¢ŒíšŒì „', 'ìš°íšŒì „', 'ì§ì§„', 'í›„ì§„', 'ì£¼ì°¨'],
                'low': ['ì°¨ëŸ‰', 'ìë™ì°¨', 'ìš´ì „', 'ë„ë¡œ', 'Aì°¨ëŸ‰', 'Bì°¨ëŸ‰']
            },
            'precedent': {
                'high': ['íŒë¡€', 'ëŒ€ë²•ì›', 'ê³ ë“±ë²•ì›', 'ì§€ë°©ë²•ì›', 'ì‚¬ê±´ë²ˆí˜¸'],
                'medium': ['ë²•ì›', 'ì¬íŒ', 'ì†Œì†¡', 'ê²°ì •', 'ê³ ë²•', 'ì§€ë°©ë²•ì›', 'ê³ ë“±ë²•ì›', 'ê´€ë ¨ëœ', 'ê´€ë ¨', 'ì°¾ì•„', 'ê²€ìƒ‰'],
                'low': ['ì‚¬ê±´', 'ê²°ê³¼', '20', '19', 'ìˆ˜ì›', 'ì„œìš¸', 'ë¶€ì‚°', 'ì´ì™€', 'í•´ë‹¹']
            },
            'law': {
                'high': ['ë„ë¡œêµí†µë²•', 'ë²•ë¥ ', 'ì¡°ë¬¸', 'ë²•ë ¹'],
                'medium': ['ì œ', 'ì¡°', 'í•­', 'ê·œì •', 'ìœ„ë°˜'],
                'low': ['ë²•', 'ê·œì¹™', 'ì²˜ë²Œ']
            },
            'term': {
                'high': ['ì •ì˜', 'ì˜ë¯¸', 'ëœ»', 'ì„¤ëª…', 'ë¬´ì—‡'],
                'medium': ['ìš©ì–´', 'ê°œë…', 'ë§'],
                'low': ['ì´ë€', 'ë¼ëŠ”']
            }
        }
        
        logger.info("FastClassifier ì´ˆê¸°í™” ì™„ë£Œ - í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸°")
    
    def classify(self, user_input: str) -> str:
        """
        1ì°¨: í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜ (95% ì¼€ì´ìŠ¤, API í˜¸ì¶œ ì—†ìŒ)
        2ì°¨: ëª¨í˜¸í•œ ê²½ìš°ë§Œ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© (5% ì¼€ì´ìŠ¤)
        """
        start_time = time.time()
        
        # 1ì°¨: ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ë¥˜
        category_scores = self._calculate_keyword_scores(user_input.lower())
        
        if category_scores:
            best_category = max(category_scores, key=category_scores.get)
            max_score = category_scores[best_category]
            total_scores = sum(category_scores.values())
            confidence = max_score / total_scores if total_scores > 0 else 0
            
            # ğŸ“Š ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¶„ë¥˜ ë¡œì§ (ì‚¬ê³  ê´€ë ¨ ê°ì§€ ê°•í™”)
            confidence_threshold = 0.65  # ì‹ ë¢°ë„ ì„ê³„ê°’
            min_score_threshold = 4       # ìµœì†Œ ì ìˆ˜ ì„ê³„ê°’
            
            # ê³ ì‹ ë¢°ë„ ë¶„ë¥˜ (ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ í™•ì‹¤)
            if confidence >= confidence_threshold and max_score >= min_score_threshold:
                predicted_category = max(category_scores, key=category_scores.get)
                logger.info(f"ê³ ì‹ ë¢°ë„ ë¶„ë¥˜: {predicted_category} (ì‹ ë¢°ë„: {confidence:.2f}, ì ìˆ˜: {max_score})")
                return predicted_category
            
            # ì €ì‹ ë¢°ë„ ë˜ëŠ” ì• ë§¤í•œ ê²½ìš° - ì¼ë°˜ ìƒë‹´ìœ¼ë¡œ ë¶„ë¥˜
            if confidence < confidence_threshold or max_score < min_score_threshold:
                logger.info(f"ì €ì‹ ë¢°ë„ ë¶„ë¥˜ - ì¼ë°˜ìƒë‹´ ì ìš© (ì‹ ë¢°ë„: {confidence:.2f}, ìµœê³ ì ìˆ˜: {max_score})")
                return 'general'
        
        # 2ì°¨: ëª¨í˜¸í•œ ê²½ìš°ë§Œ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© (ì™„ì „íˆ ì• ë§¤í•œ ê²½ìš°)
        try:
            if self.model_id and len(user_input.strip()) > 10:  # ë„ˆë¬´ ì§§ì€ ì…ë ¥ì€ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© ì•ˆí•¨
                logger.info(f"íŒŒì¸íŠœë‹ ë¶„ë¥˜ ì‚¬ìš©: '{user_input[:30]}...'")
                category = self._classify_with_finetuned_model(user_input)
                classification_time = time.time() - start_time
                logger.info(f"íŒŒì¸íŠœë‹ ë¶„ë¥˜ ì™„ë£Œ: {category} ({classification_time:.2f}ì´ˆ)")
                return category
        except Exception as e:
            logger.warning(f"íŒŒì¸íŠœë‹ ëª¨ë¸ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
        
        # í´ë°±: general (ë” êµ¬ì²´ì ì¸ ì •ë³´ ìš”ì²­)
        fallback_category = 'general'
        logger.info(f"í´ë°± ë¶„ë¥˜: {fallback_category} - ì‚¬ìš©ì ì •ë³´ ìˆ˜ì§‘ ëª¨ë“œ")
        return fallback_category
    
    def _calculate_keyword_scores(self, user_input: str) -> Dict[str, float]:
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°"""
        scores = {}
        
        for category, patterns in self.keyword_patterns.items():
            score = 0
            
            # ë†’ì€ ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ (3ì )
            for keyword in patterns['high']:
                if keyword in user_input:
                    score += 3
            
            # ì¤‘ê°„ ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ (2ì )
            for keyword in patterns['medium']:
                if keyword in user_input:
                    score += 2
            
            # ë‚®ì€ ê°€ì¤‘ì¹˜ í‚¤ì›Œë“œ (1ì )
            for keyword in patterns['low']:
                if keyword in user_input:
                    score += 1
            
            if score > 0:
                scores[category] = score
        
        return scores
    
    def _detect_accident_related_hints(self, user_input: str) -> Dict[str, Any]:
        """ì‚¬ê³  ê´€ë ¨ ì§•í›„ ê°ì§€ (ë¶„ë¥˜ ì‹ ë¢°ë„ê°€ ë‚®ì„ ë•Œ ì‚¬ìš©) - ë‹¤ì–‘í•œ ì‚¬ê³  ìœ í˜• í¬í•¨"""
        
        # ì‚¬ê³  ê´€ë ¨ ê¸°ë³¸ ì§•í›„ í‚¤ì›Œë“œ - í™•ì¥
        accident_hints = [
            # ì§ì ‘ì  ì‚¬ê³  í‘œí˜„
            'ì‚¬ê³ ', 'ì¶©ëŒ', 'ë¶€ë”ªí˜”', 'ì ‘ì´‰', 'ë°•ì•˜', 'ë°›ì•˜ì–´',
            # ì°¨ëŒ€ë³´í–‰ì ê´€ë ¨
            'ë³´í–‰ì', 'ì‚¬ëŒ', 'ì¹˜ì—ˆ', 'ê±´ë“œë ¸', 'ê±´ë„ˆë‹¤', 'íš¡ë‹¨ë³´ë„', 'ë¬´ë‹¨íš¡ë‹¨',
            'ë…¹ìƒ‰ë¶ˆ', 'ë¹¨ê°„ë¶ˆ', 'ì‹ í˜¸ë“±', 'ì¸ë„', 'ê±·ë‹¤', 'ì‚°ì±…', 'ì•„ì´', 'í•™ìƒ',
            # ì°¨ëŒ€ìì „ê±° ê´€ë ¨
            'ìì „ê±°', 'ë°”ì´í¬', 'ë”°ë¦‰ì´', 'í‚¥ë³´ë“œ', 'ì „ë™í‚¥ë³´ë“œ', 'ìì „ê±°ë„ë¡œ',
            'í˜ë‹¬', 'í—¬ë©§', 'íƒ€ê³ ', 'ë‹¬ë¦¬ë‹¤',
            # ì°¨ëŒ€ë†ê¸°êµ¬ ê´€ë ¨
            'ë†ê¸°êµ¬', 'íŠ¸ë™í„°', 'ë†ë¡œ', 'ê²½ìš´ê¸°', 'ë†ë²ˆê¸°', 'ë†ì‚¬', 'ë†ì´Œ', 
            'ë†ê¸°ê³„', 'ë†ì–´ì´Œ', 'ê°‘ìê¸°', 'ë‚˜ì™€ì„œ', 'ì €ì†', 'ë°­', 'ë…¼', 'ë†ë¯¼',
            # ìì—°ìŠ¤ëŸ¬ìš´ ì–¸ê¸‰
            'ë‚˜ì…¨ì–´ìš”', 'ë‚˜ì…¨ë„¤ìš”', 'ë§ì•˜ì–´ìš”', 'ë‹¹í–ˆì–´ìš”',
            # ìƒí™© ì„¤ëª…
            'ë“œë¼ì´ë¸Œ', 'ìš´ì „', 'ì°¨ëŸ‰', 'ìë™ì°¨',
            # ê°ì • í‘œí˜„
            'ë†€ë', 'ë‹¹í™©', 'ëŒ€ë°•', 'ë¬´ì„œìš´', 'ê¹œì§',
            # ì§ˆë¬¸/ëŒ€í™” ìœ ë„ í‘œí˜„
            'ì–´ë–»ê²Œ', 'ë­í•´ì•¼', 'ì–´ì©Œê²Œ', 'ë„ì›€',
            # ìœ„ì¹˜/ìƒí™© ì–¸ê¸‰
            'êµì°¨ë¡œ', 'ë„ë¡œ', 'ì£¼ì°¨ì¥', 'ì‹ í˜¸ë“±', 'ê¸¸', 'ì‹œê³¨ê¸¸'
        ]
        
        detected_hints = []
        for hint in accident_hints:
            if hint in user_input:
                detected_hints.append(hint)
        
        # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì§•í›„ê°€ ìˆìœ¼ë©´ ì‚¬ê³  ê´€ë ¨ìœ¼ë¡œ ê°„ì£¼
        is_accident_related = len(detected_hints) >= 1
        
        return {
            'is_accident_related': is_accident_related,
            'hints': detected_hints,
            'hint_count': len(detected_hints)
        }
    
    def _classify_with_finetuned_model(self, user_input: str) -> str:
        """íŒŒì¸íŠœë‹ ëª¨ë¸ ë¶„ë¥˜ (í•„ìš”ì‹œë§Œ)"""
        response = self.client.chat.completions.create(
            model=self.model_id,
            messages=[{"role": "user", "content": user_input}],
            max_tokens=10,
            temperature=0,
            timeout=45  # OpenAI API íƒ€ì„ì•„ì›ƒ 45ì´ˆ
        )
        category = response.choices[0].message.content.strip().lower()
        
        # ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ì¸ì§€ í™•ì¸
        valid_categories = {'accident', 'precedent', 'law', 'term', 'general'}
        return category if category in valid_categories else 'general'
    
    def classify_with_context(self, user_input: str, previous_category: str = None) -> str:
        """ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë¶„ë¥˜"""
        primary_result = self.classify(user_input)
        
        # ì €ì‹ ë¢°ë„ì¼ ë•Œ ì´ì „ ì¹´í…Œê³ ë¦¬ ê³ ë ¤
        if primary_result == 'general' and previous_category:
            category_scores = self._calculate_keyword_scores(user_input.lower())
            
            # ì´ì „ ì¹´í…Œê³ ë¦¬ì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ ë¶€ì—¬
            context_keywords = {
                'accident': ['ê´€ë ¨', 'ì´ê²ƒ', 'ì´ê±°', 'í•´ë‹¹', 'ìœ„'],
                'precedent': ['ê´€ë ¨', 'ì´ê²ƒ', 'ì´ê±°', 'í•´ë‹¹', 'ìœ„', 'ì°¾ì•„', 'ê²€ìƒ‰'],
                'law': ['ê´€ë ¨', 'ì´ê²ƒ', 'ì´ê±°', 'í•´ë‹¹', 'ìœ„'],
                'term': ['ê´€ë ¨', 'ì´ê²ƒ', 'ì´ê±°', 'í•´ë‹¹', 'ìœ„']
            }
            
            if previous_category in context_keywords:
                context_score = sum(2 for keyword in context_keywords[previous_category] 
                                  if keyword in user_input.lower())
                
                if context_score >= 2:  # ë¬¸ë§¥ í‚¤ì›Œë“œê°€ 2ê°œ ì´ìƒ
                    logger.info(f"ë¬¸ë§¥ ê³ ë ¤ ë¶„ë¥˜: {user_input} â†’ {previous_category} (ë¬¸ë§¥ì ìˆ˜: {context_score})")
                    return previous_category
        
        return primary_result


class HybridRAGSystem:
    """í•˜ì´ë¸Œë¦¬ë“œ RAG ì‹œìŠ¤í…œ - Direct Search + Self-Query Retriever ì¡°í•©"""
    
    def __init__(self):
        from ..utils.vector_db import get_vector_db_manager
        self.vector_db_manager = get_vector_db_manager()
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì»¬ë ‰ì…˜ ë§¤í•‘
        self.collection_mapping = {
            'accident': 'car_case',
            'precedent': 'precedent', 
            'law': 'law',
            'term': 'term'
        }
        
        # Self-Queryìš© LLM (ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©)
        self.self_query_llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0,
            api_key=os.getenv('OPENAI_API_KEY'),
            max_tokens=100,  # Self-QueryëŠ” ì§§ì€ ì‘ë‹µë§Œ í•„ìš”
            request_timeout=10
        )
        
        # ì¹´í…Œê³ ë¦¬ë³„ Self-Query Retriever ì„¤ì •
        self.self_query_retrievers = {}
        self.metadata_field_info = self._initialize_metadata_info()
        
        # ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ (ë™ì¼ ì§ˆë¬¸ ë°˜ë³µ ì‹œ ì„±ëŠ¥ í–¥ìƒ)
        self._search_cache = {}
        
        # ì„±ëŠ¥ í†µê³„
        self.search_stats = {
            'direct_searches': 0,
            'self_query_searches': 0,
            'cache_hits': 0,
            'hybrid_searches': 0
        }
        
        logger.info("HybridRAGSystem ì´ˆê¸°í™” ì™„ë£Œ - Direct + Self-Query ì¡°í•©")
    
    def _initialize_metadata_info(self) -> Dict[str, List[AttributeInfo]]:
        """ì¹´í…Œê³ ë¦¬ë³„ ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ë³´ ì •ì˜"""
        return {
            'accident': [
                AttributeInfo(
                    name="ì‚¬ê±´ ID",
                    description="êµí†µì‚¬ê³  ì‚¬ë¡€ì˜ ê³ ìœ  ì‹ë³„ì (ì˜ˆ: ì°¨01-1, ì°¨02-3)",
                    type="string"
                ),
                AttributeInfo(
                    name="ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨",
                    description="Aì°¨ëŸ‰ê³¼ Bì°¨ëŸ‰ì˜ ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨ ì •ë³´",
                    type="string"
                ),
                AttributeInfo(
                    name="ê´€ë ¨ ë²•ê·œ",
                    description="ì ìš©ë˜ëŠ” ë„ë¡œêµí†µë²• ì¡°ë¬¸ (ì˜ˆ: ë„ë¡œêµí†µë²• ì œ25ì¡°)",
                    type="string"
                ),
                AttributeInfo(
                    name="ì°¸ê³  íŒë¡€",
                    description="ê´€ë ¨ ë²•ì› íŒë¡€ (ì˜ˆ: ëŒ€ë²•ì› 2011ë‹¤3250)",
                    type="string"
                )
            ],
            'precedent': [
                AttributeInfo(
                    name="court",
                    description="íŒê²°ì„ ë‚´ë¦° ë²•ì›ëª… (ì˜ˆ: ëŒ€ë²•ì›, ì„œìš¸ê³ ë“±ë²•ì›)",
                    type="string"
                ),
                AttributeInfo(
                    name="case_id",
                    description="ì‚¬ê±´ë²ˆí˜¸ (ì˜ˆ: 2019ë‹¤12345, 92ë„2077)",
                    type="string"
                ),
                AttributeInfo(
                    name="year",
                    description="íŒê²° ì—°ë„ (4ìë¦¬ ìˆ«ì)",
                    type="integer"
                )
            ],
            'law': [
                AttributeInfo(
                    name="title",
                    description="ì¡°ë¬¸ ì œëª© (ì˜ˆ: ì œ5ì¡°(ì‹ í˜¸ ë˜ëŠ” ì§€ì‹œì— ë”°ë¥¼ ì˜ë¬´))",
                    type="string"
                ),
                AttributeInfo(
                    name="article_number",
                    description="ì¡°ë¬¸ ë²ˆí˜¸ (ì˜ˆ: ì œ5ì¡°, ì œ25ì¡°)",
                    type="string"
                ),
                AttributeInfo(
                    name="category",
                    description="ë²•ë¥  ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ì‹ í˜¸ì¤€ìˆ˜, êµì°¨ë¡œí†µí–‰, ì•ˆì „ìš´ì „)",
                    type="string"
                )
            ],
            'term': [
                AttributeInfo(
                    name="term",
                    description="ë²•ë¥  ìš©ì–´ëª… (ì˜ˆ: ê³¼ì‹¤, ë„ë¡œ, ì°¨ë¡œ)",
                    type="string"
                ),
                AttributeInfo(
                    name="category",
                    description="ìš©ì–´ ë¶„ë¥˜ (ì˜ˆ: êµí†µë²•ê·œ, ì‚¬ê³ ì²˜ë¦¬, ë„ë¡œì‹œì„¤)",
                    type="string"
                )
            ]
        }
        
    def search_context(self, query: str, category: str, max_docs: int = 2) -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: Direct Search + Self-Query Retriever ì¡°í•©"""
        start_time = time.time()
        
        try:
            # íŒë¡€ ì¹´í…Œê³ ë¦¬ì˜ ê²½ìš° íŒë¡€ë²ˆí˜¸ ê²€ì¦ ë¡œì§ ì ìš©
            if category == 'precedent':
                case_number = self._extract_case_number(query)
                if case_number:
                    # íŒë¡€ë²ˆí˜¸ê°€ ê°ì§€ëœ ê²½ìš° ì •í™•í•œ ë§¤ì¹­ ê²€ìƒ‰
                    exact_match_result = self._search_exact_precedent(case_number, query)
                    if exact_match_result:
                        return exact_match_result
                    else:
                        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íŒë¡€ë²ˆí˜¸ê°€ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ë„ ì°¨ë‹¨
                        return f"EXACT_PRECEDENT_NOT_FOUND: {case_number}"
                else:
                    # íŒë¡€ë²ˆí˜¸ê°€ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰ í—ˆìš©í•˜ì§€ë§Œ ê²½ê³  í¬í•¨
                    logger.warning(f"íŒë¡€ë²ˆí˜¸ ë¯¸ê°ì§€: {query}")
            
            # ìºì‹œ í™•ì¸
            cache_key = f"{category}_{hash(query)}"
            if cache_key in self._search_cache:
                self.search_stats['cache_hits'] += 1
                logger.info(f"RAG ìºì‹œ íˆíŠ¸: {category} ({time.time() - start_time:.3f}ì´ˆ)")
                return self._search_cache[cache_key]
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
            hybrid_result = self._hybrid_search(query, category, max_docs)
            
            if not hybrid_result:
                logger.info(f"RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {category}")
                return ""
            
            # ìºì‹œ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ)
            if len(self._search_cache) < 100:
                self._search_cache[cache_key] = hybrid_result
            
            search_time = time.time() - start_time
            logger.info(f"RAG ê²€ìƒ‰ ì™„ë£Œ: {category} ({search_time:.3f}ì´ˆ)")
            return hybrid_result
            
        except Exception as e:
            logger.warning(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨ ({category}): {str(e)}")
            return ""
    
    def _hybrid_search(self, query: str, category: str, max_docs: int) -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: Direct + Self-Query ì¡°í•©"""
        self.search_stats['hybrid_searches'] += 1
        
        # 1ë‹¨ê³„: ë¹ ë¥¸ Direct Search (ê¸°ë³¸ ê²€ìƒ‰)
        direct_results = self._direct_search(query, category, max_docs)
        self.search_stats['direct_searches'] += 1
        
        # 2ë‹¨ê³„: ìì—°ì–´ ì¿ ë¦¬ì— í•„í„° í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        needs_self_query = self._should_use_self_query(query, category)
        
        if needs_self_query:
            # Self-Query Retriever ì‚¬ìš© (ë©”íƒ€ë°ì´í„° í•„í„°ë§)
            try:
                self_query_results = self._self_query_search(query, category, max_docs)
                self.search_stats['self_query_searches'] += 1
                
                # ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
                combined_results = self._combine_search_results(direct_results, self_query_results)
                
                if combined_results:
                    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ê³µ: Direct({len(direct_results)}) + Self-Query({len(self_query_results)}) = {len(combined_results)}")
                    return self._format_search_results(combined_results, category)
                    
            except Exception as e:
                logger.warning(f"Self-Query ê²€ìƒ‰ ì‹¤íŒ¨, Direct ê²°ê³¼ ì‚¬ìš©: {str(e)}")
        
        # Self-Query ì‹¤íŒ¨ ë˜ëŠ” ë¶ˆí•„ìš” ì‹œ Direct ê²°ê³¼ë§Œ ì‚¬ìš©
        if direct_results:
            return self._format_search_results(direct_results, category)
        
        return ""
    
    def _direct_search(self, query: str, category: str, max_docs: int) -> List[Document]:
        """ë¹ ë¥¸ Direct VectorDB ê²€ìƒ‰"""
        try:
            collection_key = self.collection_mapping.get(category)
            if not collection_key:
                return []
            
            collection_name = self.vector_db_manager.COLLECTIONS.get(collection_key, collection_key)
            docs = self.vector_db_manager.search_similar_documents(
                query=query,
                collection_name=collection_name,
                k=max_docs * 2  # Self-Queryì™€ ë³‘í•©ì„ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜¤ê¸°
            )
            
            return docs or []
            
        except Exception as e:
            logger.warning(f"Direct ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _should_use_self_query(self, query: str, category: str) -> bool:
        """ìì—°ì–´ ì¿ ë¦¬ì— ë©”íƒ€ë°ì´í„° í•„í„°ë§ì´ ë„ì›€ì´ ë ì§€ íŒë‹¨"""
        
        # ì¹´í…Œê³ ë¦¬ë³„ Self-Query í•„ìš” ì¡°ê±´
        self_query_triggers = {
            'precedent': [
                'ëŒ€ë²•ì›', 'ê³ ë“±ë²•ì›', 'ì§€ë°©ë²•ì›', 'ë²•ì›',
                '20', '19', 'ì—°ë„', 'ë…„ë„'
            ],
            'law': [
                'ì œ', 'ì¡°', 'í•­', 'ë²ˆí˜¸',
                'ì‹ í˜¸', 'êµì°¨ë¡œ', 'ì•ˆì „', 'ìš´ì „'
            ],
            'accident': [
                'Aì°¨ëŸ‰', 'Bì°¨ëŸ‰', 'ë¹„ìœ¨', 'ê³¼ì‹¤',
                'ì¢ŒíšŒì „', 'ì§ì§„', 'êµì°¨ë¡œ', 'ì‹ í˜¸'
            ],
            'term': [
                'ì •ì˜', 'ì˜ë¯¸', 'ê°œë…', 'ìš©ì–´'
            ]
        }
        
        triggers = self_query_triggers.get(category, [])
        
        # íŠ¸ë¦¬ê±° í‚¤ì›Œë“œê°€ 2ê°œ ì´ìƒ ìˆìœ¼ë©´ Self-Query ì‚¬ìš©
        trigger_count = sum(1 for trigger in triggers if trigger in query)
        
        should_use = trigger_count >= 2 or len(query) > 30  # ê¸´ ì¿ ë¦¬ëŠ” ë” ì •êµí•œ ê²€ìƒ‰ í•„ìš”
        
        if should_use:
            logger.info(f"Self-Query ì‚¬ìš© ê²°ì •: {category}, íŠ¸ë¦¬ê±°={trigger_count}, ì¿ ë¦¬ê¸¸ì´={len(query)}")
        
        return should_use
    
    def _self_query_search(self, query: str, category: str, max_docs: int) -> List[Document]:
        """ë©”íƒ€ë°ì´í„° í•„í„°ë§ì´ ê°€ëŠ¥í•œ Self-Query Retriever ê²€ìƒ‰"""
        try:
            # ì¹´í…Œê³ ë¦¬ë³„ Self-Query Retriever ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            retriever = self._get_or_create_self_query_retriever(category)
            if not retriever:
                return []
            
            # Self-Query ê²€ìƒ‰ ìˆ˜í–‰
            docs = retriever.get_relevant_documents(query)
            
            # ìµœëŒ€ ë¬¸ì„œ ìˆ˜ ì œí•œ
            return docs[:max_docs] if docs else []
            
        except Exception as e:
            logger.warning(f"Self-Query ê²€ìƒ‰ ì‹¤íŒ¨ ({category}): {str(e)}")
            return []
    
    def _get_or_create_self_query_retriever(self, category: str) -> Optional[SelfQueryRetriever]:
        """ì¹´í…Œê³ ë¦¬ë³„ Self-Query Retriever ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        
        # ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ë°˜í™˜
        if category in self.self_query_retrievers:
            return self.self_query_retrievers[category]
        
        try:
            # VectorStore ê°€ì ¸ì˜¤ê¸°
            collection_key = self.collection_mapping.get(category)
            if not collection_key:
                return None
            
            collection_name = self.vector_db_manager.COLLECTIONS.get(collection_key, collection_key)
            vectorstore = self.vector_db_manager.get_collection_as_vectorstore(collection_name)
            
            if not vectorstore:
                logger.warning(f"VectorStoreë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {collection_name}")
                return None
            
            # ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            metadata_info = self.metadata_field_info.get(category, [])
            if not metadata_info:
                logger.warning(f"ë©”íƒ€ë°ì´í„° ì •ë³´ ì—†ìŒ: {category}")
                return None
            
            # ë¬¸ì„œ ë‚´ìš© ì„¤ëª…
            document_content_description = self._get_document_content_description(category)
            
            # Self-Query Retriever ìƒì„±
            retriever = SelfQueryRetriever.from_llm(
                llm=self.self_query_llm,
                vectorstore=vectorstore,
                document_contents=document_content_description,
                metadata_field_info=metadata_info,
                enable_limit=True,
                verbose=False
            )
            
            # ìºì‹œì— ì €ì¥
            self.self_query_retrievers[category] = retriever
            logger.info(f"Self-Query Retriever ìƒì„± ì™„ë£Œ: {category}")
            
            return retriever
            
        except Exception as e:
            logger.error(f"Self-Query Retriever ìƒì„± ì‹¤íŒ¨ ({category}): {str(e)}")
            return None
    
    def _get_document_content_description(self, category: str) -> str:
        """ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ë‚´ìš© ì„¤ëª…"""
        descriptions = {
            'accident': "êµí†µì‚¬ê³  ì‚¬ë¡€, ê³¼ì‹¤ë¹„ìœ¨, ë²•ì  ê·¼ê±° ë° íŒë¡€ ì •ë³´",
            'precedent': "ë²•ì› íŒë¡€, ì‚¬ê±´ë²ˆí˜¸, íŒê²° ë‚´ìš© ë° ë²•ì  íŒë‹¨",
            'law': "ë„ë¡œêµí†µë²• ì¡°ë¬¸, ë²•ë¥  ë‚´ìš© ë° ì²˜ë²Œ ê·œì •",
            'term': "ë²•ë¥  ìš©ì–´ ì •ì˜, êµí†µì‚¬ê³  ê´€ë ¨ ìš©ì–´ ì„¤ëª…"
        }
        
        return descriptions.get(category, "êµí†µì‚¬ê³  ê´€ë ¨ ë²•ë¥  ì •ë³´")
    
    def _combine_search_results(self, direct_results: List[Document], self_query_results: List[Document]) -> List[Document]:
        """ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ê³  ì¤‘ë³µ ì œê±°"""
        
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ìœ ë‹ˆí¬ ì‹ë³„ì ì§‘í•©
        seen_content = set()
        combined_results = []
        
        # Self-Query ê²°ê³¼ë¥¼ ìš°ì„  (ë” ì •í™•í•œ ê²°ê³¼)
        for doc in self_query_results:
            content_hash = hash(doc.page_content[:100])  # ì²˜ìŒ 100ìë¡œ ì¤‘ë³µ íŒë‹¨
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                combined_results.append(doc)
        
        # Direct ê²°ê³¼ ì¶”ê°€ (ì¤‘ë³µ ì œì™¸)
        for doc in direct_results:
            content_hash = hash(doc.page_content[:100])
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                combined_results.append(doc)
        
        return combined_results
    
    def _format_search_results(self, docs: List[Document], category: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ë¬¸ìì—´ë¡œ ë¦¬í„´"""
        if not docs:
            return ""
        
        context_parts = []
        for i, doc in enumerate(docs[:3], 1):  # ìµœëŒ€ 3ê°œë§Œ ì‚¬ìš©
            content = doc.page_content[:200]  # 200ìë¡œ ì œí•œ
            metadata = self._format_metadata(doc.metadata, category)
            context_parts.append(f"[{i}] {content}\n{metadata}")
        
        return "\n".join(context_parts)
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ ì •ë³´ ë°˜í™˜"""
        total_searches = self.search_stats['hybrid_searches']
        
        stats = {
            'total_hybrid_searches': total_searches,
            'direct_searches': self.search_stats['direct_searches'],
            'self_query_searches': self.search_stats['self_query_searches'],
            'cache_hits': self.search_stats['cache_hits'],
            'cache_hit_ratio': round(self.search_stats['cache_hits'] / max(total_searches, 1) * 100, 1),
            'self_query_usage_ratio': round(self.search_stats['self_query_searches'] / max(total_searches, 1) * 100, 1),
            'active_self_query_retrievers': len(self.self_query_retrievers)
        }
        
        return stats
    
    def clear_cache(self):
        """ê²€ìƒ‰ ìºì‹œ ì´ˆê¸°í™”"""
        self._search_cache.clear()
        logger.info("RAG ê²€ìƒ‰ ìºì‹œ ì´ˆê¸°í™”")
    
    def clear_self_query_retrievers(self):
        """ìƒì„±ëœ Self-Query Retrieverë“¤ ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ì ˆì•½)"""
        self.self_query_retrievers.clear()
        logger.info("Self-Query Retrievers ì´ˆê¸°í™”")
    
    def _extract_case_number(self, query: str) -> Optional[str]:
        """íŒë¡€ë²ˆí˜¸ ì¶”ì¶œ - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›"""
        # íŒë¡€ë²ˆí˜¸ íŒ¨í„´ (ëŒ€ë²•ì›, ê³ ë“±ë²•ì›, ì§€ë°©ë²•ì› ë“±)
        patterns = [
            r'(ëŒ€ë²•ì›\s*\d{4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)',  # ëŒ€ë²•ì› 2019ë‹¤12345, 92ë„2077
            r'(ì„œìš¸ê³ ë²•\s*\d{4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)',  # ì„œìš¸ê³ ë²• 2020ë‚˜56789
            r'(ì„œìš¸ê³ ë“±ë²•ì›\s*\d{4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)',  # ì„œìš¸ê³ ë“±ë²•ì› 2020ë‚˜56789
            r'(ì„œìš¸ì¤‘ì•™ì§€ë°©ë²•ì›\s*\d{4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)',  # ì§€ë°©ë²•ì›
            r'(ì„œìš¸ì§€ë°©ë²•ì›\s*\d{4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)',  # ì§€ë°©ë²•ì› ì¶•ì•½
            r'(\d{2,4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)',  # 2019ë‹¤12345, 92ë„2077 (ë²•ì›ëª… ì—†ì´)
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                case_number = match.group(1).strip()
                logger.info(f"íŒë¡€ë²ˆí˜¸ ê°ì§€: '{case_number}' from '{query}'")
                return case_number
        
        return None
    
    def _search_exact_precedent(self, case_number: str, original_query: str) -> Optional[str]:
        """ì •í™•í•œ íŒë¡€ë²ˆí˜¸ ë§¤ì¹­ ê²€ìƒ‰"""
        try:
            collection_name = self.vector_db_manager.COLLECTIONS.get('precedent', 'precedent')
            
            # 1ì°¨: ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰ (ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°)
            docs = self.vector_db_manager.search_similar_documents(
                query=case_number,
                collection_name=collection_name,
                k=10  # ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰
            )
            
            if not docs:
                return None
            
            # 2ì°¨: ë©”íƒ€ë°ì´í„°ì—ì„œ ì •í™•í•œ ë§¤ì¹­ ì°¾ê¸°
            exact_matches = []
            partial_matches = []
            
            for doc in docs:
                metadata = doc.metadata
                doc_case_id = metadata.get('case_id', '').strip()
                
                # ì •í™•í•œ ì¼ì¹˜ ê²€ì‚¬
                if self._is_exact_case_match(case_number, doc_case_id):
                    exact_matches.append(doc)
                    logger.info(f"ì •í™•í•œ íŒë¡€ ë§¤ì¹­ ë°œê²¬: '{case_number}' == '{doc_case_id}'")
                # ë¶€ë¶„ ì¼ì¹˜ (ì˜ˆ: ë…„ë„ì™€ ì‚¬ê±´ë²ˆí˜¸ë§Œ ë§¤ì¹­)
                elif self._is_partial_case_match(case_number, doc_case_id):
                    partial_matches.append(doc)
            
            # 3ì°¨: ê²°ê³¼ ì„ íƒ ë° í¬ë§·íŒ…
            if exact_matches:
                # ì •í™•í•œ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ìµœê³  1ê°œë§Œ ë°˜í™˜
                best_match = exact_matches[0]
                return self._format_exact_precedent_result(best_match, case_number, True)
            
            elif partial_matches:
                # ë¶€ë¶„ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ìµœê³  1ê°œ ë°˜í™˜
                best_match = partial_matches[0]
                return self._format_exact_precedent_result(best_match, case_number, False)
            
            # ì „í˜€ ë§¤ì¹­ë˜ì§€ ì•ŠìŒ
            return None
            
        except Exception as e:
            logger.warning(f"ì •í™•í•œ íŒë¡€ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _is_exact_case_match(self, input_case: str, db_case: str) -> bool:
        """ì •í™•í•œ íŒë¡€ë²ˆí˜¸ ì¼ì¹˜ ê²€ì‚¬"""
        if not input_case or not db_case:
            return False
        
        # ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
        input_clean = re.sub(r'\s+', '', input_case.lower())
        db_clean = re.sub(r'\s+', '', db_case.lower())
        
        # ì™„ì „ ì¼ì¹˜
        if input_clean == db_clean:
            return True
        
        # ì „ë°˜ëœ ìˆœì„œë„ ê²€ì‚¬ (dbì˜ ê²½ìš° ì…ë ¥ì„ í¬í•¨í•˜ëŠ” ê²½ìš°)
        if input_clean in db_clean or db_clean in input_clean:
            return True
        
        return False
    
    def _is_partial_case_match(self, input_case: str, db_case: str) -> bool:
        """ë¶€ë¶„ íŒë¡€ë²ˆí˜¸ ì¼ì¹˜ ê²€ì‚¬ (ë…„ë„ + ì‚¬ê±´ë²ˆí˜¸)"""
        if not input_case or not db_case:
            return False
        
        # ë…„ë„ì™€ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ (ë„ ì¶”ê°€)
        input_pattern = re.search(r'(\d{2,4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)', input_case)
        db_pattern = re.search(r'(\d{2,4}[ë‹¤ê°€ë‚˜ë„ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\d+)', db_case)
        
        if input_pattern and db_pattern:
            input_core = input_pattern.group(1)
            db_core = db_pattern.group(1)
            return input_core.lower() == db_core.lower()
        
        return False
    
    def _format_exact_precedent_result(self, doc: Document, searched_case: str, is_exact: bool) -> str:
        """ì •í™•í•œ íŒë¡€ ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        metadata = doc.metadata
        content = doc.page_content[:500]  # ë” ìì„¸í•œ ë‚´ìš©
        
        case_id = metadata.get('case_id', searched_case)
        court = metadata.get('court', 'ë¯¸ìƒ')
        
        match_type = "ì •í™•í•œ ë§¤ì¹­" if is_exact else "ë¶€ë¶„ ë§¤ì¹­"
        
        result = f"âœ… **íŒë¡€ ê²€ìƒ‰ ì„±ê³µ** ({match_type})\n\n"
        result += f"ğŸ“ **íŒë¡€ ì •ë³´:**\n"
        result += f"- ì‚¬ê±´ë²ˆí˜¸: {case_id}\n"
        result += f"- ë²•ì›: {court}\n\n"
        result += f"ğŸ“œ **íŒë¡€ ë‚´ìš©:**\n{content}\n\n"
        
        if not is_exact:
            result += f"ğŸ“ **ë§¤ì¹­ ì•ˆë‚´:** ì…ë ¥í•˜ì‹  '{searched_case}'ì™€ ìœ ì‚¬í•œ íŒë¡€ì…ë‹ˆë‹¤.\n"
        
        return result
    
    def _format_metadata(self, metadata: Dict, category: str) -> str:
        """ì¹´í…Œê³ ë¦¬ë³„ ë©”íƒ€ë°ì´í„° í¬ë§·íŒ…"""
        if category == 'accident':
            case_id = metadata.get('ì‚¬ê±´ ID', '')
            ratio = metadata.get('ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨', '')
            return f"ì‚¬ê±´: {case_id}, ë¹„ìœ¨: {ratio}" if case_id else ""
        
        elif category == 'precedent':
            case_id = metadata.get('case_id', '')
            court = metadata.get('court', '')
            return f"íŒë¡€: {case_id}, ë²•ì›: {court}" if case_id else ""
        
        elif category == 'law':
            article = metadata.get('title', '')
            return f"ì¡°ë¬¸: {article}" if article else ""
        
        elif category == 'term':
            term = metadata.get('term', '')
            return f"ìš©ì–´: {term}" if term else ""
        
        return ""
    
    def clear_cache(self):
        """ê²€ìƒ‰ ìºì‹œ ì´ˆê¸°í™”"""
        self._search_cache.clear()
        logger.info("RAG ê²€ìƒ‰ ìºì‹œ ì´ˆê¸°í™”")


class SessionBasedConversationManager:
    """ì„¸ì…˜ë³„ ëŒ€í™” ê´€ë¦¬ì - ì˜ì†ì  ë©”ëª¨ë¦¬ + ì„¸ì…˜ ê²©ë¦¬"""
    
    def __init__(self, main_llm):
        self.main_llm = main_llm
        self.session_chains = {}  # session_id -> ConversationChain
        self.session_metadata = {}  # session_id -> ë©”íƒ€ë°ì´í„°
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤
        self.category_prompts = self._initialize_category_prompts()
        
        # ê¸°ë³¸ í†µí•© í”„ë¡¬í”„íŠ¸ (ì¹´í…Œê³ ë¦¬ êµ¬ë¶„ ì—†ì„ ë•Œ)
        self.unified_prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""ë‹¹ì‹ ì€ êµí†µì‚¬ê³  ì „ë¬¸ ìƒë‹´ì‚¬ 'ë…¸ëŠ'ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ì˜ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ë©´ì„œ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

**ì´ì „ ëŒ€í™”**:
{history}

**ë‹µë³€ ê°€ì´ë“œë¼ì¸**:
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ì¡°í•˜ì„¸ìš”
- êµí†µì‚¬ê³  ì „ë¬¸ì  ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
- ë²•ì  ê·¼ê±°ì™€ ì‹¤ë¬´ ì ìš© ì‚¬ë¡€ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”

ì‚¬ìš©ì: {input}
ë…¸ëŠ:"""
        )
        
        logger.info("SessionBasedConversationManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_category_prompts(self) -> Dict[str, PromptTemplate]:
        """ì¹´í…Œê³ ë¦¬ë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        
        # ğŸš— êµí†µì‚¬ê³  ë¶„ì„ ì „ìš© í”„ë¡¬í”„íŠ¸ (ë‹¤ì–‘í•œ ì‚¬ê³  ìœ í˜• ì§€ì› + ë²•ê·œ/íŒë¡€ ê°•í™”)
        accident_prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""ë‹¹ì‹ ì€ êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ì „ë¬¸ê°€ 'ë…¸ëŠ'ì…ë‹ˆë‹¤. 

**ì¤‘ìš”: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

**ì´ì „ ëŒ€í™”**:
{history}

**1ë‹¨ê³„: ì‚¬ê³  ìœ í˜• íŒŒì•…**
ì‚¬ìš©ì ìƒí™©ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•´ë‹¹í•˜ëŠ” ì‚¬ê³  ìœ í˜•ì„ íŒŒì•…í•˜ì„¸ìš”:
- **ì°¨ëŒ€ì°¨ ì‚¬ê³ **: ìë™ì°¨ì™€ ìë™ì°¨ ê°„ ì¶©ëŒ
- **ì°¨ëŒ€ë³´í–‰ì ì‚¬ê³ **: ìë™ì°¨ì™€ ë³´í–‰ì ê°„ ì¶©ëŒ  
- **ì°¨ëŒ€ìì „ê±° ì‚¬ê³ **: ìë™ì°¨ì™€ ìì „ê±° ê°„ ì¶©ëŒ
- **ì°¨ëŒ€ë†ê¸°êµ¬ ì‚¬ê³ **: ìë™ì°¨ì™€ ë†ê¸°êµ¬/ê¸°íƒ€ ì´ë™ì¥ì¹˜ ê°„ ì¶©ëŒ

**2ë‹¨ê³„: ì‚¬ê³  ìœ í˜•ë³„ ë¶„ì„ ì›ì¹™**
### ğŸš— ì°¨ëŒ€ì°¨ ì‚¬ê³ 
- ì‹ í˜¸ ìœ„ë°˜ > ì‹ í˜¸ ì¤€ìˆ˜
- ë¹„ë³´í˜¸ íšŒì „ > ë³´í˜¸ íšŒì „
- ì¢ŒíšŒì „ > ì§ì§„ (ê°™ì€ ì‹ í˜¸)
- í›„ì§„ì… > ì„ ì§„ì…

### ğŸ‘¨â€ğŸ¦¯ ì°¨ëŒ€ë³´í–‰ì ì‚¬ê³   
- ë³´í–‰ì ë³´í˜¸ ìš°ì„  ì›ì¹™
- ì‹ í˜¸ ìœ„ë°˜ ë³´í–‰ìë„ ì°¨ëŸ‰ì— 10% ê¸°ë³¸ ê³¼ì‹¤
- íš¡ë‹¨ë³´ë„ ì™¸ ë¬´ë‹¨íš¡ë‹¨ ì‹œ ë³´í–‰ì ê³¼ì‹¤ ì¦ê°€
- ì•¼ê°„/ì•…ì²œí›„ ì‹œ ì°¨ëŸ‰ ì£¼ì˜ì˜ë¬´ ê°•í™”

### ğŸš´ ì°¨ëŒ€ìì „ê±° ì‚¬ê³ 
- ìì „ê±° êµí†µì•½ì ë³´í˜¸ ì›ì¹™  
- ì°¨ëŸ‰ ëŒ€ë¹„ ìì „ê±° ê³¼ì‹¤ ê²½ê°
- ìì „ê±°ë„ë¡œ ë¯¸ì´ìš© ì‹œ ìì „ê±° ê³¼ì‹¤ ê°€ì‚°
- ì–´ë¦°ì´/ë…¸ì¸/ì¥ì• ì¸ ìì „ê±° ìš´ì „ì ê³¼ì‹¤ ê°ê²½

### ğŸšœ ì°¨ëŒ€ë†ê¸°êµ¬ ì‚¬ê³ 
- ë†ê¸°êµ¬ ì €ì† ìš´í–‰ íŠ¹ì„± ê³ ë ¤
- ë†ë¡œ ì§„ì¶œì… ì‹œ íŠ¹ë³„ ì£¼ì˜ì˜ë¬´
- ë†ë²ˆê¸° ë“± íŠ¹ìˆ˜ ìƒí™© ê³ ë ¤
- ë†ê¸°êµ¬ ìš´ì „ì ì—°ë ¹ëŒ€ ê³ ë ¤

**3ë‹¨ê³„: ìµœì†Œ ë¶„ì„ ì¡°ê±´ í™•ì¸**
ë‹¤ìŒ ì •ë³´ê°€ ìˆìœ¼ë©´ ë°”ë¡œ ë¶„ì„í•˜ì„¸ìš”:
- ê° ë‹¹ì‚¬ìì˜ ì‹ í˜¸ ìƒíƒœ/í–‰ë™
- ì‚¬ê³  ì§€ì  ë° ìƒí™©
- ì •ë§ ì¤‘ìš”í•œ ì •ë³´ë§Œ ë¹ ì§„ ê²½ìš°ì—ë§Œ ê°„ë‹¨íˆ ì§ˆë¬¸

**ë§ˆí¬ë‹¤ìš´ ë‹µë³€ í˜•ì‹**:

## ğŸ¯ **ì‚¬ê³  ìœ í˜• ë° ìƒí™©**
- **ì‚¬ê³  ìœ í˜•**: [ì°¨ëŒ€ì°¨/ì°¨ëŒ€ë³´í–‰ì/ì°¨ëŒ€ìì „ê±°/ì°¨ëŒ€ë†ê¸°êµ¬]
- **Aë‹¹ì‚¬ì**: [ì°¨ëŸ‰/ë³´í–‰ì/ìì „ê±°/ë†ê¸°êµ¬] - [ì‹ í˜¸ìƒíƒœ + í–‰ë™]
- **Bë‹¹ì‚¬ì**: [ì°¨ëŸ‰/ë³´í–‰ì/ìì „ê±°/ë†ê¸°êµ¬] - [ì‹ í˜¸ìƒíƒœ + í–‰ë™]
- **ì‚¬ê³  ì§€ì **: [êµì°¨ë¡œ/íš¡ë‹¨ë³´ë„/ë†ë¡œ/ì¼ë°˜ë„ë¡œ ë“±]

## âš–ï¸ **ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„**
### ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨
- **Aë‹¹ì‚¬ì**: X% 
- **Bë‹¹ì‚¬ì**: Y%
- **ë¶„ì„ ê·¼ê±°**: [ì‚¬ê³  ìœ í˜•ë³„ íŠ¹ì„± ë° êµí†µë²•ë¦¬ ì ìš©]

## ğŸ”§ **ì¡°ì •ìš”ì†Œ**
### [ì°¨ëŸ‰] ê´€ë ¨ ìˆ˜ì •ìš”ì†Œ
- í˜„ì €í•œ ê³¼ì‹¤ (+10%): [í•´ë‹¹ì‚¬í•­ ìˆì„ ë•Œë§Œ]
- ì¤‘ëŒ€í•œ ê³¼ì‹¤ (+20%): [í•´ë‹¹ì‚¬í•­ ìˆì„ ë•Œë§Œ]

### [ë³´í–‰ì/ìì „ê±°/ë†ê¸°êµ¬] ê´€ë ¨ ìˆ˜ì •ìš”ì†Œ (í•´ë‹¹ ì‚¬ê³ ì¼ ë•Œë§Œ)
- ì•¼ê°„/ì‹œì•¼ì¥ì•  (+5%)
- êµí†µì•½ì ë³´í˜¸ (-10%)  
- ì „ìš©ë„ë¡œ ë¯¸ì´ìš© (+5%)
- ê¸°íƒ€ íŠ¹ìˆ˜ìƒí™©

## ğŸ“Š **ì˜ˆìƒ ê³¼ì‹¤ë¹„ìœ¨**
- **Aë‹¹ì‚¬ì**: X% (ê¸°ë³¸ Â± ì¡°ì •)
- **Bë‹¹ì‚¬ì**: Y% (ê¸°ë³¸ Â± ì¡°ì •)

## ğŸ“ **ì°¸ê³ ìë£Œ ì •ë³´** (ê´€ë ¨ ìë£Œê°€ ìˆëŠ” ê²½ìš°ë§Œ)
- **ì°¸ê³  ì¼€ì´ìŠ¤**: [ì‚¬ê±´ ID ë° ìƒí™©]
- **ì ìš© ê°€ëŠ¥ì„±**: [ì‚¬ìš©ì ìƒí™©ê³¼ì˜ ì¼ì¹˜ë„ í‰ê°€]

## ğŸ“‹ **ê´€ë ¨ ë²•ê·œ ë° ê·¼ê±°**
### ğŸ›ï¸ **ì ìš© ë²•ë¥ **
**ì‚¬ê³  ìœ í˜•ë³„ ê´€ë ¨ ì¡°ë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”:**

#### ì°¨ëŒ€ì°¨ ì‚¬ê³  ê´€ë ¨
- **ë„ë¡œêµí†µë²• ì œ5ì¡° (ì‹ í˜¸ ë˜ëŠ” ì§€ì‹œì— ë”°ë¥¼ ì˜ë¬´)**
  - ëª¨ë“  ì°¨ëŸ‰ê³¼ ë³´í–‰ìëŠ” ì‹ í˜¸ê¸°ì˜ ì‹ í˜¸ì— ë”°ë¼ì•¼ í•¨
- **ë„ë¡œêµí†µë²• ì œ25ì¡° (êµì°¨ë¡œ í†µí–‰ë°©ë²•)**  
  - êµì°¨ë¡œì—ì„œì˜ ìš°ì„ ìˆœìœ„ ë° í†µí–‰ë°©ë²•
- **ë„ë¡œêµí†µë²• ì œ27ì¡° (íš¡ë‹¨Â·ìœ í„´Â·í›„ì§„ì˜ ê¸ˆì§€)**
  - ìœ„í—˜í•œ ì¥ì†Œì—ì„œì˜ ìš´ì „ ê¸ˆì§€

#### ì°¨ëŒ€ë³´í–‰ì ì‚¬ê³  ê´€ë ¨
- **ë„ë¡œêµí†µë²• ì œ12ì¡° (ë³´í–‰ìì˜ ë„ë¡œíš¡ë‹¨)**
  - ë³´í–‰ìì˜ íš¡ë‹¨ë³´ë„ ì´ìš© ì˜ë¬´
- **ë„ë¡œêµí†µë²• ì œ27ì¡° (ë³´í–‰ì ë³´í˜¸ì˜ë¬´)**
  - ìš´ì „ìì˜ ë³´í–‰ì ë³´í˜¸ ì˜ë¬´
- **ë„ë¡œêµí†µë²• ì œ49ì¡° (ì–´ë¦°ì´ ë³´í˜¸êµ¬ì—­)**
  - ì–´ë¦°ì´ ë³´í˜¸êµ¬ì—­ì—ì„œì˜ íŠ¹ë³„ ì£¼ì˜ì˜ë¬´

#### ì°¨ëŒ€ìì „ê±° ì‚¬ê³  ê´€ë ¨  
- **ë„ë¡œêµí†µë²• ì œ13ì¡°ì˜2 (ìì „ê±°ì˜ í†µí–‰ë°©ë²•)**
  - ìì „ê±° í†µí–‰ ê´€ë ¨ íŠ¹ë¡€ ê·œì •
- **ìì „ê±° ì´ìš© í™œì„±í™”ì— ê´€í•œ ë²•ë¥  ì œ3ì¡°**
  - ìì „ê±°ë„ë¡œì˜ êµ¬ë¶„ ë° ì´ìš© ì˜ë¬´

#### ì°¨ëŒ€ë†ê¸°êµ¬ ì‚¬ê³  ê´€ë ¨
- **ë„ë¡œêµí†µë²• ì œ2ì¡° (ì •ì˜)**
  - ë†ê¸°êµ¬ì˜ ì°¨ëŸ‰ ë¶„ë¥˜ ë° ì •ì˜
- **ë†ì–´ì´Œë„ë¡œ ì •ë¹„ë²•**
  - ë†ì–´ì´Œ ë„ë¡œì—ì„œì˜ íŠ¹ë³„ ê·œì •

### âš–ï¸ **ê´€ë ¨ íŒë¡€** 
**ì¤‘ìš”: ì‚¬ìš©ì ì…ë ¥ì˜ [ì°¸ê³ ìë£Œ] ì„¹ì…˜ì— ì‹¤ì œ íŒë¡€ê°€ ìˆì„ ë•Œë§Œ ì´ ì„¹ì…˜ì„ í‘œì‹œí•˜ì„¸ìš”. ì°¸ê³ ìë£Œì— íŒë¡€ê°€ ì—†ìœ¼ë©´ ì´ ì„¹ì…˜ì„ ìƒëµí•˜ê±°ë‚˜ "ê´€ë ¨ íŒë¡€ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.**

**ì°¸ê³ ìë£Œì— ì‹¤ì œ íŒë¡€ê°€ ìˆëŠ” ê²½ìš°ë§Œ:**
- **[ì°¸ê³ ìë£Œì˜ ì‹¤ì œ ë²•ì›ëª…] [ì‹¤ì œ ì‚¬ê±´ë²ˆí˜¸]**
  - íŒë¡€ ìš”ì§€: [ì°¸ê³ ìë£Œì—ì„œ ì§ì ‘ ì¸ìš©í•œ ë‚´ìš©ë§Œ]
  - ì ìš© ê°€ëŠ¥ì„±: [í˜„ì¬ ìƒí™©ê³¼ì˜ ìœ ì‚¬ì„±ë§Œ ë¶„ì„]

**ì°¸ê³ ìë£Œì— íŒë¡€ê°€ ì—†ëŠ” ê²½ìš°:**
í˜„ì¬ ìƒí™©ê³¼ ì§ì ‘ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ íŒë¡€ëŠ” ì°¸ê³ ìë£Œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ êµí†µì‚¬ê³  ë²•ë¦¬ë¥¼ ì ìš©í•˜ì—¬ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.

## ğŸ’¡ **ë²•ë¦¬ì  ê·¼ê±° ë° í•´ì„**
### ğŸ” **ê³¼ì‹¤ë¹„ìœ¨ ì‚°ì • ì›ì¹™**
- **ì‹ í˜¸ ìœ„ë°˜ì˜ ê²½ìš°**: ë„ë¡œêµí†µë²• ì œ5ì¡° ìœ„ë°˜ìœ¼ë¡œ ì¼ë°©ê³¼ì‹¤ ë˜ëŠ” ì¤‘ê³¼ì‹¤ ì¸ì •
- **ë³´í–‰ì ë³´í˜¸ì˜ë¬´**: ë„ë¡œêµí†µë²• ì œ27ì¡°ì— ë”°ë¥¸ ìš´ì „ìì˜ ì ˆëŒ€ì  ì£¼ì˜ì˜ë¬´
- **êµí†µì•½ì ë³´í˜¸**: ìì „ê±°, ë³´í–‰ì ë“± êµí†µì•½ìì— ëŒ€í•œ íŠ¹ë³„ ë³´í˜¸ ì›ì¹™
- **ë†ë¡œ íŠ¹ìˆ˜ì„±**: ë†ì–´ì´Œ ì§€ì—­ì˜ êµí†µ íŠ¹ì„± ë° ìƒí™© ê³ ë ¤

### ğŸ“– **ì¼ë°˜ì ì¸ ë²•ë¦¬ ì›ì¹™**
- **ì‹ í˜¸ ìœ„ë°˜ ì‚¬ê³ **: ì‹ í˜¸ë¥¼ ì¤€ìˆ˜í•œ ì°¨ëŸ‰ë„ ìƒëŒ€ë°© ì°¨ëŸ‰ì„ ë°œê²¬í•  ìˆ˜ ìˆì—ˆë‹¤ë©´ ê²½ë¯¸í•œ ê³¼ì‹¤ ì¸ì •
- **ë³´í–‰ì ì‚¬ê³ **: ë¬´ë‹¨íš¡ë‹¨ ë³´í–‰ìë¼ë„ ìš´ì „ìì—ê²Œ 10% ì´ìƒì˜ ê¸°ë³¸ ê³¼ì‹¤ ë¶€ë‹´
- **ìì „ê±° ì‚¬ê³ **: ìì „ê±°ëŠ” êµí†µì•½ìë¡œì„œ ì°¨ëŸ‰ ëŒ€ë¹„ ê³¼ì‹¤ ê²½ê° ì›ì¹™ ì ìš©
- **ë†ê¸°êµ¬ ì‚¬ê³ **: ë†ê¸°êµ¬ì˜ ì €ì† íŠ¹ì„± ë° ë†ë¡œ ì§„ì¶œì…ì˜ ë¶ˆê°€í”¼ì„± ê³ ë ¤

## â“ **ì¶”ê°€ í™•ì¸ì‚¬í•­** (ê¼­ í•„ìš”í•œ ê²½ìš°ë§Œ)
[ì •ë§ ì¤‘ìš”í•œ ì •ë³´ ë¶€ì¡± ì‹œì—ë§Œ ê°„ë‹¨íˆ ì§ˆë¬¸]

## ğŸ’¡ **íŠ¹ë³„ ì°¸ê³ ì‚¬í•­**
### [í•´ë‹¹ ì‚¬ê³  ìœ í˜•ë³„ íŠ¹ì´ì‚¬í•­]
- **ì°¨ëŒ€ì°¨**: ê³¼ì†, ìŒì£¼ ë“± ì¤‘ëŒ€ê³¼ì‹¤ ì—„ì¤‘ ì ìš©
- **ì°¨ëŒ€ë³´í–‰ì**: ë³´í–‰ì ë³´í˜¸ ì˜ë¬´, ë¬´ë‹¨íš¡ë‹¨ ì‹œì—ë„ ì°¨ëŸ‰ ê³¼ì‹¤ ì¡´ì¬
- **ì°¨ëŒ€ìì „ê±°**: ìì „ê±° êµí†µì•½ì ë³´í˜¸, ì €ì† íŠ¹ì„± ê³ ë ¤
- **ì°¨ëŒ€ë†ê¸°êµ¬**: ë†ê¸°êµ¬ ì €ì† ìš´í–‰, ë†ë¡œ íŠ¹ìˆ˜ì„±, ê³„ì ˆì  ìš”ì¸ ê³ ë ¤

## ğŸš¨ **ì£¼ì˜ì‚¬í•­**
- ì‹¤ì œ ì‚¬ê±´ì€ ê°œë³„ ìƒí™©ì— ë”°ë¼ ê³¼ì‹¤ë¹„ìœ¨ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë³¸ ë¶„ì„ì€ ì¼ë°˜ì ì¸ ë²•ë¦¬ì™€ ì°¸ê³ ìë£Œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•œ ì˜ˆìƒ ê³¼ì‹¤ë¹„ìœ¨ì…ë‹ˆë‹¤
- ì •í™•í•œ ê³¼ì‹¤ë¹„ìœ¨ íŒì •ì€ ë³´í—˜íšŒì‚¬ ë˜ëŠ” ë²•ì›ì˜ ìµœì¢… íŒë‹¨ì— ë”°ë¦…ë‹ˆë‹¤
- **ì ˆëŒ€ë¡œ ì°¸ê³ ìë£Œì— ì—†ëŠ” íŒë¡€ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”**

ì‚¬ìš©ì ì§ˆë¬¸: {input}"""
        )
        
        # âš–ï¸ íŒë¡€ ê²€ìƒ‰ ì „ìš© í”„ë¡¬í”„íŠ¸ (ì°¸ê³ ìë£Œë§Œ ì‚¬ìš©)
        precedent_prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""ë‹¹ì‹ ì€ êµí†µì‚¬ê³  íŒë¡€ ê²€ìƒ‰ ì „ë¬¸ê°€ 'ë…¸ëŠ'ì…ë‹ˆë‹¤. 

**ì¤‘ìš”: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

**í•µì‹¬ ì›ì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜**:
- ì‚¬ìš©ì ì…ë ¥ì˜ [ì°¸ê³ ìë£Œ] ì„¹ì…˜ì— ìˆëŠ” íŒë¡€ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ì°¸ê³ ìë£Œì— ì—†ëŠ” íŒë¡€ ì •ë³´ëŠ” ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
- ì •í™•í•œ íŒë¡€ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”
- ë‹¤ë¥¸ íŒë¡€ë‚˜ ì¼ë°˜ì ì¸ ë²•ë¦¬ë¡œ ë³´ì™„í•˜ì§€ ë§ˆì„¸ìš”

**ì´ì „ ëŒ€í™”**:
{history}

**ë§ˆí¬ë‹¤ìš´ ë‹µë³€ í˜•ì‹ (ì°¸ê³ ìë£Œì— ì •í™•í•œ íŒë¡€ê°€ ìˆì„ ë•Œë§Œ)**:

## âš–ï¸ **íŒë¡€ ì •ë³´**
- **ë²•ì›**: [ì°¸ê³ ìë£Œì˜ court ì •ë³´]
- **ì‚¬ê±´ë²ˆí˜¸**: [ì°¸ê³ ìë£Œì˜ case_id ì •ë³´]

## ğŸ“ **íŒë¡€ ë‚´ìš©**
[ì°¸ê³ ìë£Œì˜ contentë¥¼ ê·¸ëŒ€ë¡œ ì¸ìš©]

## ğŸ” **íŒë¡€ ë¶„ì„**
[í•´ë‹¹ íŒë¡€ì˜ ì£¼ìš” ìŸì ê³¼ ê³¼ì‹¤ë¹„ìœ¨ ì‚°ì • ê·¼ê±°]

## ğŸ’¡ **ì°¸ê³ ì‚¬í•­**
- ì‹¤ì œ ì‚¬ê±´ì€ ê°œë³„ì  ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ ê³¼ì‹¤ë¹„ìœ¨ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì •í™•í•œ íŒë‹¨ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤

**ì°¸ê³ ìë£Œì— í•´ë‹¹ íŒë¡€ê°€ ì—†ëŠ” ê²½ìš°**:
ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  íŒë¡€ë¥¼ ì •í™•íˆ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
ì •í™•í•œ ì‚¬ê±´ë²ˆí˜¸(ì˜ˆ: ëŒ€ë²•ì› 2019ë‹¤12345)ë¥¼ ì…ë ¥í•´ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {input}"""
        )
        
        # ğŸ“š ë²•ë¥  ê²€ìƒ‰ ì „ìš© í”„ë¡¬í”„íŠ¸ (ì°¸ê³ ìë£Œë§Œ ì‚¬ìš©)
        law_prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""ë‹¹ì‹ ì€ êµí†µë²•ê·œ ì „ë¬¸ê°€ 'ë…¸ëŠ'ì…ë‹ˆë‹¤. 

**ì¤‘ìš”: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

**í•µì‹¬ ì›ì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜**:
- ì‚¬ìš©ì ì…ë ¥ì˜ [ì°¸ê³ ìë£Œ] ì„¹ì…˜ì— ìˆëŠ” ë²•ì¡°ë¬¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ì°¸ê³ ìë£Œì— ì—†ëŠ” ë²•ë¥  ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
- ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ì°¸ê³ ìë£Œì—ì„œ í•´ë‹¹ ë²•ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”
- ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•˜ì§€ ë§ˆì„¸ìš”

**ì´ì „ ëŒ€í™”**:
{history}

**ë§ˆí¬ë‹¤ìš´ ë‹µë³€ í˜•ì‹ (ì°¸ê³ ìë£Œì— ë²•ì¡°ë¬¸ì´ ìˆì„ ë•Œë§Œ)**:

## ğŸ“– **ê´€ë ¨ ë²•ë¥ **
### [ì°¸ê³ ìë£Œì˜ ë²•ë¥ ëª… ë° ì¡°í•­]

## ğŸ“ **ì¡°ë¬¸ ë‚´ìš©**
[ì°¸ê³ ìë£Œì—ì„œ ì§ì ‘ ì¸ìš©í•œ ë²•ì¡°ë¬¸ ì „ë¬¸]

## ğŸ” **ì¡°ë¬¸ êµ¬ì¡°** (ì°¸ê³ ìë£Œì— subsectionsê°€ ìˆëŠ” ê²½ìš°)
- **ì œXì¡° ì œ1í•­**: [í•´ë‹¹ í•­ëª©ì˜ content]
- **ì œXì¡° ì œ2í•­**: [í•´ë‹¹ í•­ëª©ì˜ content]
[subsections ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ í‘œì‹œ]

## ğŸ“š **ì„¸ë¶€ ì¡°í•­** (ì°¸ê³ ìë£Œì— itemsê°€ ìˆëŠ” ê²½ìš°)
[ê° í•­ëª©ì˜ items ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ì—¬ í‘œì‹œ]

## ğŸ”‘ **í•µì‹¬ í‚¤ì›Œë“œ** (ì°¸ê³ ìë£Œì— keywordsê°€ ìˆëŠ” ê²½ìš°)
[ì°¸ê³ ìë£Œì˜ keywordsë¥¼ ì •ë¦¬í•˜ì—¬ í‘œì‹œ]

## ğŸ’¡ **í•´ì„ ë° ì ìš©**
[ì°¸ê³ ìë£Œì— ëª…ì‹œëœ í•´ì„ê³¼ ì ìš© ë°©ë²•ë§Œ]

## ğŸš¨ **ìœ„ë°˜ ì‹œ ì²˜ë²Œ**
[ì°¸ê³ ìë£Œì— ëª…ì‹œëœ ì²˜ë²Œ ë‚´ìš©ë§Œ]

**ì°¸ê³ ìë£Œì— í•´ë‹¹ ë²•ì¡°ë¬¸ì´ ì—†ëŠ” ê²½ìš°**:
ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ë²•ì¡°ë¬¸ì— ëŒ€í•œ ì •í™•í•œ ì°¸ê³ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
êµ¬ì²´ì ì¸ ì¡°ë¬¸ ë²ˆí˜¸(ì˜ˆ: ë„ë¡œêµí†µë²• ì œ25ì¡°)ë¥¼ ì…ë ¥í•´ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {input}"""
        )
        
        # ğŸ“– ìš©ì–´ ê²€ìƒ‰ ì „ìš© í”„ë¡¬í”„íŠ¸ (ì°¸ê³ ìë£Œë§Œ ì‚¬ìš©)
        term_prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""ë‹¹ì‹ ì€ êµí†µ ê´€ë ¨ ìš©ì–´ ì „ë¬¸ê°€ 'ë…¸ëŠ'ì…ë‹ˆë‹¤. 

**ì¤‘ìš”: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

**í•µì‹¬ ì›ì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜**:
- ì‚¬ìš©ì ì…ë ¥ì˜ [ì°¸ê³ ìë£Œ] ì„¹ì…˜ì— ìˆëŠ” ìš©ì–´ ì •ì˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ì°¸ê³ ìë£Œì— ì—†ëŠ” ìš©ì–´ ì„¤ëª…ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
- ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ì°¸ê³ ìë£Œì—ì„œ í•´ë‹¹ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”
- ì¼ë°˜ì ì¸ ìƒì‹ìœ¼ë¡œ ë³´ì™„í•˜ì§€ ë§ˆì„¸ìš”

**ì´ì „ ëŒ€í™”**:
{history}

**ë§ˆí¬ë‹¤ìš´ ë‹µë³€ í˜•ì‹ (ì°¸ê³ ìë£Œì— ìš©ì–´ê°€ ìˆì„ ë•Œë§Œ)**:

## ğŸ“ **ìš©ì–´ ì •ì˜**
### **[ì°¸ê³ ìë£Œì˜ term]**

## ğŸ” **ì •ì˜ ë‚´ìš©**
[ì°¸ê³ ìë£Œì˜ desc ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì—¬ í‘œì‹œ]

ì˜ˆì‹œ:
- ì •ì˜ 1: [desc ë°°ì—´ì˜ ì²« ë²ˆì§¸ í•­ëª©]
- ì •ì˜ 2: [desc ë°°ì—´ì˜ ë‘ ë²ˆì§¸ í•­ëª©]
- ...

## ğŸ“š **ìƒì„¸ ì„¤ëª…**
[ì°¸ê³ ìë£Œì˜ descì— ìˆëŠ” êµ¬ì²´ì ì¸ ì„¤ëª…ë“¤ì„ ì •ë¦¬]

## ğŸ’¡ **ì‹¤ì œ ì ìš©**
[í•´ë‹¹ ìš©ì–´ê°€ êµí†µìƒí™©ì—ì„œ ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ ì°¸ê³ ìë£Œ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…]

## ğŸ”— **ê´€ë ¨ ìš©ì–´**
[ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ê´€ë ¨ ìš©ì–´ë“¤ì´ ìˆë‹¤ë©´ í•¨ê»˜ ì–¸ê¸‰]

**ì°¸ê³ ìë£Œì— í•´ë‹¹ ìš©ì–´ê°€ ì—†ëŠ” ê²½ìš°**:
ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ìš©ì–´ì— ëŒ€í•œ ì •í™•í•œ ì •ì˜ë¥¼ ì°¸ê³ ìë£Œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
ë‹¤ë¥¸ ìš©ì–´ë¡œ ê²€ìƒ‰í•´ë³´ì‹œê±°ë‚˜, ë” êµ¬ì²´ì ì¸ ìš©ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {input}"""
        )
        
        # ğŸ’¬ ì¼ë°˜ ìƒë‹´ ì „ìš© í”„ë¡¬í”„íŠ¸ (ì°¸ê³ ìë£Œ ê¸°ë°˜)
        general_prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""ë‹¹ì‹ ì€ ì¹œê·¼í•œ êµí†µì‚¬ê³  ìƒë‹´ ì±—ë´‡ 'ë…¸ëŠ'ì…ë‹ˆë‹¤. 

**ì¤‘ìš”: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

**í•µì‹¬ ì›ì¹™**:
- ì°¸ê³ ìë£Œê°€ ìˆë‹¤ë©´ ê·¸ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ì°¸ê³ ìë£Œê°€ ì—†ë‹¤ë©´ ì¼ë°˜ì ì¸ ì•ˆë‚´ì™€ ì§ˆë¬¸ ìœ ë„ë¥¼ í•˜ì„¸ìš”
- ì¶”ì¸¡ì´ë‚˜ ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì œê³µí•˜ì§€ ë§ˆì„¸ìš”

**ì´ì „ ëŒ€í™”**:
{history}

**ë‹µë³€ ì›ì¹™**:
- ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
- ì‹¤ìš©ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì œê³µ
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë‹µë³€

**ë§ˆí¬ë‹¤ìš´ ë‹µë³€ í˜•ì‹**:

## ğŸ’¬ **ìƒë‹´ ë‚´ìš©**
[ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ - ì°¸ê³ ìë£Œ ê¸°ë°˜ ë˜ëŠ” ì¼ë°˜ì ì¸ ì•ˆë‚´]

## ğŸ“Š **ì°¸ê³ ìë£Œ ì •ë³´** (ì°¸ê³ ìë£Œê°€ ìˆëŠ” ê²½ìš°)
[ì°¸ê³ ìë£Œì˜ ì¢…ë¥˜ì— ë”°ë¼ ë‹¤ìŒ ì¤‘ í•´ë‹¹í•˜ëŠ” ì •ë³´ í‘œì‹œ]

### ì‚¬ê³  ì¼€ì´ìŠ¤ ì •ë³´ (car_to_car, car_to_mobility, car_to_pedestrian ìë£Œ)
- **ì‚¬ê±´ ID**: [ì‚¬ê±´ ID]
- **ì‚¬ê±´ ì œëª©**: [ì‚¬ê±´ ì œëª©]
- **ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨**: [ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨]

### íŒë¡€ ì •ë³´ (precedent ìë£Œ)
- **ë²•ì›**: [court]
- **ì‚¬ê±´ë²ˆí˜¸**: [case_id]
- **ë‚´ìš©**: [content ìš”ì•½]

### ë²•ê·œ ì •ë³´ (traffic_law_rag ìë£Œ)
- **ë²•ì¡°ë¬¸**: [title]
- **ì£¼ìš” ë‚´ìš©**: [content ìš”ì•½]

### ìš©ì–´ ì •ë³´ (term ìë£Œ)
- **ìš©ì–´**: [term]
- **ì •ì˜**: [desc ìš”ì•½]

## ğŸ’¡ **ì°¸ê³ ì‚¬í•­**
- [ì¶”ê°€ ì •ë³´ë‚˜ ì£¼ì˜ì‚¬í•­]
- [ê´€ë ¨ ë„ì›€ë§ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´]

## ğŸ” **ë” ì •í™•í•œ ìƒë‹´ì„ ìœ„í•œ ì •ë³´**
êµ¬ì²´ì ì¸ ë¶„ì„ì„ ì›í•˜ì‹ ë‹¤ë©´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”:
- ì‚¬ê³  ìƒí™© (êµì°¨ë¡œ, ì§ì§„ë¡œ ë“±)
- ì‹ í˜¸ ìƒíƒœ (ë¹¨ê°„ë¶ˆ, ì´ˆë¡ë¶ˆ ë“±)
- ê° ì°¨ëŸ‰ì˜ í–‰ë™ (ì¢ŒíšŒì „, ì§ì§„, ì •ì§€ ë“±)
- ê¸°íƒ€ íŠ¹ì´ì‚¬í•­ (ê³¼ì†, ì‹ í˜¸ìœ„ë°˜ ë“±)

ì‚¬ìš©ì ì§ˆë¬¸: {input}"""
        )
        
        return {
            'accident': accident_prompt,
            'precedent': precedent_prompt,
            'law': law_prompt,
            'term': term_prompt,
            'general': general_prompt
        }
    
    def get_or_create_chain(self, session_id: str, category: str = 'general') -> ConversationChain:
        """ì„¸ì…˜ë³„ ConversationChain ê°€ì ¸ì˜¤ê¸°/ìƒì„± (ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©)"""
        if session_id not in self.session_chains:
            # ìƒˆ ì„¸ì…˜ìš© ë©”ëª¨ë¦¬ ìƒì„± (ìˆœìˆ˜ ëŒ€í™”ë§Œ ì €ì¥)
            memory = ConversationBufferWindowMemory(
                k=8,  # ìµœê·¼ 8ê°œ ëŒ€í™”ìŒ ê¸°ì–µ (16ê°œ ë©”ì‹œì§€)
                return_messages=False,
                memory_key="history",
                input_key="input",
                output_key="response"
            )
            
            # ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            prompt_template = self.category_prompts.get(category, self.unified_prompt)
            
            # ìƒˆ ConversationChain ìƒì„±
            chain = ConversationChain(
                llm=self.main_llm,
                memory=memory,
                prompt=prompt_template,
                verbose=False,
                output_key="response"
            )
            
            self.session_chains[session_id] = chain
            self.session_metadata[session_id] = {
                'created_at': time.time(),
                'last_activity': time.time(),
                'total_interactions': 0,
                'categories_used': {},
                'total_processing_time': 0,
                'primary_category': category  # ì£¼ìš” ì¹´í…Œê³ ë¦¬ ì¶”ê°€
            }
            
            logger.info(f"ìƒˆ ì„¸ì…˜ ì²´ì¸ ìƒì„±: {session_id} (ì¹´í…Œê³ ë¦¬: {category})")
        else:
            # ê¸°ì¡´ ì„¸ì…˜ì´ ìˆìœ¼ë©´ í•­ìƒ ìµœì‹  í”„ë¡¬í”„íŠ¸ë¡œ ì—…ë°ì´íŠ¸ (í”„ë¡¬í”„íŠ¸ ë³€ê²½ ë°˜ì˜)
            current_category = self.session_metadata[session_id].get('primary_category', 'general')
            
            # í•­ìƒ ìµœì‹  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            prompt_template = self.category_prompts.get(category, self.unified_prompt)
            self.session_chains[session_id].prompt = prompt_template
            self.session_metadata[session_id]['primary_category'] = category
            
            if current_category != category:
                logger.info(f"ì„¸ì…˜ {session_id} í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸: {current_category} â†’ {category}")
            else:
                logger.info(f"ì„¸ì…˜ {session_id} í”„ë¡¬í”„íŠ¸ ìƒˆë¡œê³ ì¹¨: {category}")
        
        # í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
        self.session_metadata[session_id]['last_activity'] = time.time()
        return self.session_chains[session_id]
    
    def get_category_prompt_info(self, category: str) -> Dict[str, str]:
        """ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì •ë³´ ì¡°íšŒ"""
        category_info = {
            'accident': {
                'name': 'êµí†µì‚¬ê³  ë¶„ì„',
                'focus': 'ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ + ë²•ì  ê·¼ê±° + ì¡°ì • ìš”ì†Œ',
                'format': 'ìƒí™©ë¶„ì„ â†’ ê³¼ì‹¤ë¹„ìœ¨ â†’ ë²•ì ê·¼ê±° â†’ ì¡°ì •ìš”ì†Œ â†’ ì‹¤ë¬´ì¡°ì–¸'
            },
            'precedent': {
                'name': 'íŒë¡€ ê²€ìƒ‰',
                'focus': 'íŒë¡€ ì •ë³´ + í•µì‹¬ íŒë‹¨ + ìŸì  ë¶„ì„',
                'format': 'íŒë¡€ì •ë³´ â†’ ì‚¬ê±´ê°œìš” â†’ ë²•ì›íŒë‹¨ â†’ íŒë¡€ìš”ì§€ â†’ ì ìš©ì§€ì¹¨'
            },
            'law': {
                'name': 'ë„ë¡œêµí†µë²• ì¡°íšŒ',
                'focus': 'ì¡°ë¬¸ ë‚´ìš© + ì…ë²• ì·¨ì§€ + ì²˜ë²Œ ê·œì •',
                'format': 'ì¡°ë¬¸ë‚´ìš© â†’ í•µì‹¬ë‚´ìš© â†’ ìœ„ë°˜ìœ í˜• â†’ ì²˜ë²Œê¸°ì¤€ â†’ ì‹¤ë¬´ì ìš©'
            },
            'term': {
                'name': 'ìš©ì–´ ì„¤ëª…',
                'focus': 'ì •í™•í•œ ì •ì˜ + ì‰¬ìš´ ì„¤ëª… + ì‹¤ë¬´ ì˜ˆì‹œ',
                'format': 'ì •ì˜ â†’ ì‰¬ìš´ì„¤ëª… â†’ ì‚¬ìš©ìƒí™© â†’ ê´€ë ¨ìš©ì–´ â†’ ì‹¤ë¬´ì˜ˆì‹œ'
            },
            'general': {
                'name': 'ì¼ë°˜ ìƒë‹´',
                'focus': 'ì¹œê·¼í•œ ì‘ë‹µ + ì¢…í•© ì•ˆë‚´ + ë‹¨ê³„ë³„ ê°€ì´ë“œ',
                'format': 'ì¹œê·¼í•œì¸ì‚¬ â†’ ë„ì›€ë°©ë²• â†’ ì œì•ˆì‚¬í•­ â†’ ì¶”ê°€ì§ˆë¬¸ â†’ ê´€ë ¨ê¸°ëŠ¥'
            }
        }
        
        return category_info.get(category, category_info['general'])
    
    def update_session_stats(self, session_id: str, category: str, processing_time: float):
        """ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        if session_id in self.session_metadata:
            metadata = self.session_metadata[session_id]
            metadata['total_interactions'] += 1
            metadata['total_processing_time'] += processing_time
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì‚¬ìš© íšŸìˆ˜
            if category not in metadata['categories_used']:
                metadata['categories_used'][category] = 0
            metadata['categories_used'][category] += 1
    
    def cleanup_old_sessions(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        
        expired_sessions = []
        for session_id, metadata in self.session_metadata.items():
            if current_time - metadata['last_activity'] > max_age_seconds:
                expired_sessions.append(session_id)
        
        for session_id in expired_sessions:
            if session_id in self.session_chains:
                del self.session_chains[session_id]
            if session_id in self.session_metadata:
                del self.session_metadata[session_id]
            logger.info(f"ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬: {session_id}")
        
        if expired_sessions:
            logger.info(f"ì´ {len(expired_sessions)}ê°œ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")
    
    def get_session_stats(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ í†µê³„ ì¡°íšŒ"""
        if session_id not in self.session_metadata:
            return {'exists': False}
        
        metadata = self.session_metadata[session_id]
        chain = self.session_chains.get(session_id)
        
        history_length = 0
        if chain and hasattr(chain.memory, 'chat_memory'):
            history_length = len(chain.memory.chat_memory.messages)
        
        avg_processing_time = 0
        if metadata['total_interactions'] > 0:
            avg_processing_time = metadata['total_processing_time'] / metadata['total_interactions']
        
        return {
            'exists': True,
            'total_interactions': metadata['total_interactions'],
            'session_age_hours': round((time.time() - metadata['created_at']) / 3600, 2),
            'memory_length': history_length,
            'last_activity': metadata['last_activity'],
            'categories_used': metadata['categories_used'],
            'avg_processing_time': round(avg_processing_time, 2),
            'total_processing_time': round(metadata['total_processing_time'], 2)
        }
    
    def clear_session_memory(self, session_id: str):
        """íŠ¹ì • ì„¸ì…˜ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        if session_id in self.session_chains:
            self.session_chains[session_id].memory.clear()
            
            # í†µê³„ë„ ë¦¬ì…‹
            if session_id in self.session_metadata:
                self.session_metadata[session_id].update({
                    'total_interactions': 0,
                    'categories_used': {},
                    'total_processing_time': 0
                })
            
            logger.info(f"ì„¸ì…˜ {session_id} ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_active_sessions(self) -> List[str]:
        """í™œì„± ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
        return list(self.session_chains.keys())


class OptimizedTrafficAccidentBot:
    """ìµœì í™”ëœ êµí†µì‚¬ê³  ìƒë‹´ ë´‡ - í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤
        self.classifier = FastClassifier()
        self.rag_system = HybridRAGSystem()  # í•˜ì´ë¸Œë¦¬ë“œ RAG ì‹œìŠ¤í…œ ì‚¬ìš©
        
        # ë©”ì¸ LLM (ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¹„ìš© ìµœì í™”)
        self.main_llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=os.getenv('OPENAI_API_KEY'),
            max_tokens=800,  # ì‘ë‹µ ê¸¸ì´ ëŠ˜ë¦¼ (600 â†’ 800)
            request_timeout=45  # íƒ€ì„ì•„ì›ƒ ëŒ€í­ ì¦ê°€ (10ì´ˆ â†’ 45ì´ˆ)
        )
        
        # ì„¸ì…˜ë³„ ëŒ€í™” ê´€ë¦¬ì
        self.conversation_manager = SessionBasedConversationManager(self.main_llm)
        
        # ì„±ëŠ¥ í†µê³„
        self.total_requests = 0
        self.total_processing_time = 0
        
        logger.info("OptimizedTrafficAccidentBot ì´ˆê¸°í™” ì™„ë£Œ - í†µí•© AI ì‹œìŠ¤í…œ (Hybrid RAG)")
    
    def process_query(self, user_input: str, session_id: str) -> Dict[str, Any]:
        """í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ - ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ìµœì í™”"""
        start_time = time.time()
        
        try:
            # 1. ë¹ ë¥¸ ë¶„ë¥˜ (95% í‚¤ì›Œë“œ ê¸°ë°˜, API í˜¸ì¶œ ì—†ìŒ)
            classification_start = time.time()
            category = self.classifier.classify(user_input)
            classification_time = time.time() - classification_start
            
            # 2. RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (API í˜¸ì¶œ ì—†ìŒ, VectorDB ì§ì ‘ ê²€ìƒ‰)
            rag_start = time.time()
            context = self.rag_system.search_context(user_input, category)
            rag_time = time.time() - rag_start
            
            # 3. ì„¸ì…˜ë³„ ConversationChain ê°€ì ¸ì˜¤ê¸° (ì¹´í…Œê³ ë¦¬ë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ ì ìš©)
            chain = self.conversation_manager.get_or_create_chain(session_id, category)
            
            # 4. ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ì‘ë‹µ ìƒì„± (í•µì‹¬ ìµœì í™”!)
            llm_start = time.time()
            
            try:
                # ì»¨í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ë˜, ì›ë³¸ ì‚¬ìš©ì ì…ë ¥ì€ ìœ ì§€
                if context:
                    # RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°, ì‚¬ìš©ì ì…ë ¥ì— ê°„ë‹¨íˆ ì¶”ê°€
                    enhanced_input = f"{user_input}\n\n[ì°¸ê³ ìë£Œ: {context[:200]}]"
                else:
                    # ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    enhanced_input = user_input
                
                response = chain.predict(input=enhanced_input)
                
            except Exception as llm_error:
                logger.warning(f"LLM í˜¸ì¶œ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {str(llm_error)}")
                response = self._generate_quick_fallback_response(user_input, category, context)
            
            llm_time = time.time() - llm_start
            
            # 5. í†µê³„ ì—…ë°ì´íŠ¸
            total_time = time.time() - start_time
            self.conversation_manager.update_session_stats(session_id, category, total_time)
            self.total_requests += 1
            self.total_processing_time += total_time
            
            # ì„±ëŠ¥ ë¡œê¹…
            logger.info(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ - ë¶„ë¥˜: {classification_time:.3f}ì´ˆ, RAG: {rag_time:.3f}ì´ˆ, LLM: {llm_time:.3f}ì´ˆ, ì´: {total_time:.2f}ì´ˆ")
            
            return {
                'category': category,
                'response': response.strip() if hasattr(response, 'strip') else str(response),
                'context_used': bool(context),
                'processing_time': round(total_time, 2),
                'performance_breakdown': {
                    'classification_time': round(classification_time, 3),
                    'rag_time': round(rag_time, 3),
                    'llm_time': round(llm_time, 3)
                },
                'session_stats': self.conversation_manager.get_session_stats(session_id)
            }
            
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return self._generate_error_response(user_input, str(e), time.time() - start_time)
    
    def _generate_quick_fallback_response(self, user_input: str, category: str, context: str) -> str:
        """ë¹ ë¥¸ í´ë°± ì‘ë‹µ ìƒì„± (API í˜¸ì¶œ ì—†ìŒ)"""
        
        category_responses = {
            'accident': f"""ì‚¬ê³  ìƒí™©: "{user_input[:50]}..."

í˜„ì¬ ì¼ì‹œì ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ ì•ˆë‚´:
- êµì°¨ë¡œ ì‚¬ê³ ì˜ ê²½ìš° ì¢ŒíšŒì „ ì°¨ëŸ‰ì˜ ê³¼ì‹¤ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤
- ì‹ í˜¸ìœ„ë°˜, ê³¼ì† ë“±ì— ë”°ë¼ ë¹„ìœ¨ì´ ì¡°ì •ë©ë‹ˆë‹¤
- ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ìƒí™©ì„ ë” ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.""",
            
            'precedent': f"""íŒë¡€ ê²€ìƒ‰: "{user_input[:50]}..."

í˜„ì¬ ì¼ì‹œì ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ ì•ˆë‚´:
- ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì •í™•í•˜ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ëŒ€ë²•ì› 2019ë‹¤12345)
- êµí†µì‚¬ê³  ê´€ë ¨ íŒë¡€ëŠ” ëŒ€ë²•ì›, ê³ ë“±ë²•ì›ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤
- íŒë¡€ëŠ” ë¹„ìŠ·í•œ ì‚¬ì•ˆì˜ ì°¸ê³  ìë£Œë¡œ í™œìš©í•©ë‹ˆë‹¤

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.""",
            
            'law': f"""ë²•ë¥  ì¡°íšŒ: "{user_input[:50]}..."

í˜„ì¬ ì¼ì‹œì ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ ì•ˆë‚´:
- ë„ë¡œêµí†µë²•ì€ êµí†µì•ˆì „ì„ ìœ„í•œ ê¸°ë³¸ ë²•ë¥ ì…ë‹ˆë‹¤
- ì¡°ë¬¸ ë²ˆí˜¸ë¥¼ ì •í™•í•˜ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ì œ5ì¡°, ì œ25ì¡°)
- ì‹ í˜¸ìœ„ë°˜, ê³¼ì†, ìŒì£¼ìš´ì „ ë“±ì— ëŒ€í•œ ì²˜ë²Œ ê·œì •ì´ ìˆìŠµë‹ˆë‹¤

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.""",
            
            'term': f"""ìš©ì–´ ì„¤ëª…: "{user_input[:50]}..."

í˜„ì¬ ì¼ì‹œì ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ ì•ˆë‚´:
- ê³¼ì‹¤ë¹„ìœ¨: ì‚¬ê³  ì±…ì„ì˜ ë¹„ìœ¨(í¼ì„¼íŠ¸)
- ë„ë¡œ: ì°¨ëŸ‰ì´ ë‹¤ë‹ˆëŠ” ëª¨ë“  ê¸¸
- ì°¨ë„: ë„ë¡œì—ì„œ ì°¨ëŸ‰ì´ ë‹¤ë‹ˆëŠ” ë¶€ë¶„
- íšë‹¨ë³´ë„: ë³´í–‰ìê°€ ë„ë¡œë¥¼ ê±´ë„ˆëŠ” ê³³

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."""
        }
        
        return category_responses.get(category, f"""ì¼ë°˜ ìƒë‹´: "{user_input[:50]}..."

í˜„ì¬ ì¼ì‹œì ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ ì•ˆë‚´:
- êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„
- ë„ë¡œêµí†µë²• ì¡°íšŒ
- íŒë¡€ ê²€ìƒ‰
- ë²•ë¥  ìš©ì–´ ì„¤ëª…

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.""")
    
    def _get_category_name(self, category: str) -> str:
        """ì¹´í…Œê³ ë¦¬ í•œê¸€ëª… ë³€í™˜"""
        category_names = {
            'accident': 'êµí†µì‚¬ê³  ë¶„ì„',
            'precedent': 'íŒë¡€ ê²€ìƒ‰',
            'law': 'ë„ë¡œêµí†µë²• ì¡°íšŒ',
            'term': 'ìš©ì–´ ì„¤ëª…',
            'general': 'ì¼ë°˜ ìƒë‹´'
        }
        return category_names.get(category, 'ì¼ë°˜ ìƒë‹´')
    
    def _generate_error_response(self, user_input: str, error_message: str, processing_time: float) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ í´ë°± ì‘ë‹µ"""
        return {
            'category': 'general',
            'response': f"""ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ìœ¼ë¡œ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒí™©**: {error_message[:100]}...

**í•´ê²° ë°©ë²•**:
1. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
2. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. ê³„ì† ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ìƒˆ ì±„íŒ…ì„ ì‹œì‘í•´ì£¼ì„¸ìš”

**ì˜ˆì‹œ ì§ˆë¬¸**:
- "êµì°¨ë¡œì—ì„œ ì¢ŒíšŒì „ ì¤‘ ì‚¬ê³ ê°€ ë‚¬ì–´ìš”"
- "ë„ë¡œêµí†µë²• ì œ5ì¡° ë‚´ìš©ì€?"
- "ê³¼ì‹¤ë¹„ìœ¨ì´ ë¬´ì—‡ì¸ê°€ìš”?"

ë‹¤ì‹œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤.""",
            'context_used': False,
            'processing_time': round(processing_time, 2),
            'error': True
        }
    
    def clear_session_memory(self, session_id: str):
        """íŠ¹ì • ì„¸ì…˜ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_manager.clear_session_memory(session_id)
    
    def cleanup_old_sessions(self):
        """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬"""
        self.conversation_manager.cleanup_old_sessions()
    
    def get_system_stats(self) -> Dict[str, Any]:
        """ì „ì²´ ì‹œìŠ¤í…œ í†µê³„"""
        avg_processing_time = 0
        if self.total_requests > 0:
            avg_processing_time = self.total_processing_time / self.total_requests
        
        active_sessions = self.conversation_manager.get_active_sessions()
        
        # í•˜ì´ë¸Œë¦¬ë“œ RAG í†µê³„ ì¶”ê°€
        rag_stats = self.rag_system.get_search_statistics()
        
        return {
            'total_requests': self.total_requests,
            'avg_processing_time': round(avg_processing_time, 2),
            'active_sessions': len(active_sessions),
            'memory_optimization': 'ì„¸ì…˜ë³„ ë…ë¦½ ë©”ëª¨ë¦¬',
            'api_efficiency': '95% í‚¤ì›Œë“œ ë¶„ë¥˜ + ë‹¨ì¼ LLM í˜¸ì¶œ',
            'rag_system': {
                'type': 'Hybrid RAG (Direct + Self-Query)',
                'search_statistics': rag_stats,
                'optimization': 'Direct Search ê¸°ë³¸ + Self-Query ìë™ ì„ íƒ'
            }
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”)
_optimized_bot = None

def get_optimized_bot() -> OptimizedTrafficAccidentBot:
    """ìµœì í™”ëœ ë´‡ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _optimized_bot
    if _optimized_bot is None:
        _optimized_bot = OptimizedTrafficAccidentBot()
        logger.info("OptimizedTrafficAccidentBot ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
    return _optimized_bot

def process_optimized_query(user_input: str, session_id: str) -> Dict[str, Any]:
    """ìµœì í™”ëœ ì¿¼ë¦¬ ì²˜ë¦¬ (í¸ì˜ í•¨ìˆ˜)"""
    bot = get_optimized_bot()
    return bot.process_query(user_input, session_id)

def clear_session_memory(session_id: str):
    """ì„¸ì…˜ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” (í¸ì˜ í•¨ìˆ˜)"""
    bot = get_optimized_bot()
    bot.clear_session_memory(session_id)

def cleanup_old_sessions():
    """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬ (í¸ì˜ í•¨ìˆ˜)"""
    bot = get_optimized_bot()
    bot.cleanup_old_sessions()

def test_precedent_search(case_number: str) -> Dict[str, Any]:
    """íŒë¡€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ê°œë°œ/ë””ë²„ê¹…ìš©)"""
    bot = get_optimized_bot()
    rag_system = bot.rag_system
    
    logger.info(f"íŒë¡€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘: '{case_number}'")
    
    # íŒë¡€ë²ˆí˜¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    extracted = rag_system._extract_case_number(case_number)
    
    if extracted:
        logger.info(f"íŒë¡€ë²ˆí˜¸ ì¶”ì¶œ ì„±ê³µ: '{extracted}'")
        # ì •í™•í•œ ë§¤ì¹­ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        exact_result = rag_system._search_exact_precedent(extracted, case_number)
        
        return {
            'input': case_number,
            'extracted_case_number': extracted,
            'exact_match_found': bool(exact_result),
            'result': exact_result or "ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íŒë¡€ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    else:
        logger.info(f"íŒë¡€ë²ˆí˜¸ ì¶”ì¶œ ì‹¤íŒ¨: '{case_number}'")
        return {
            'input': case_number,
            'extracted_case_number': None,
            'exact_match_found': False,
            'result': "ì…ë ¥ì—ì„œ íŒë¡€ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }

def get_system_stats() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ (í¸ì˜ í•¨ìˆ˜)"""
    bot = get_optimized_bot()
    return bot.get_system_stats()

def test_hybrid_rag_search(query: str, category: str) -> Dict[str, Any]:
    """í•˜ì´ë¸Œë¦¬ë“œ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ê°œë°œ/ë””ë²„ê¹…ìš©)"""
    bot = get_optimized_bot()
    rag_system = bot.rag_system
    
    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘: '{query}' (category: {category})")
    
    try:
        # ê²€ìƒ‰ ìˆ˜í–‰
        search_result = rag_system.search_context(query, category, max_docs=3)
        
        # í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        stats = rag_system.get_search_statistics()
        
        return {
            'input_query': query,
            'category': category,
            'search_result': search_result,
            'search_statistics': stats,
            'hybrid_system_info': {
                'direct_search': 'ê¸°ë³¸ VectorDB ê²€ìƒ‰',
                'self_query_search': 'ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì‚¬ìš©',
                'trigger_conditions': 'íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ 2ê°œ ì´ìƒ ë˜ëŠ” ì¿ ë¦¬ ê¸¸ì´ 30ì ì´ìƒ'
            }
        }
        
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
        return {
            'input_query': query,
            'category': category,
            'error': str(e),
            'search_result': None
        }

def test_classification_with_confidence(user_input: str) -> Dict[str, Any]:
    """ë¶„ë¥˜ ë¡œì§ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ê°œë°œ/ë””ë²„ê¹…ìš©)"""
    bot = get_optimized_bot()
    classifier = bot.classifier
    
    logger.info(f"ë¶„ë¥˜ ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘: '{user_input}'")
    
    # 1. í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
    category_scores = classifier._calculate_keyword_scores(user_input.lower())
    
    # 2. ì‹ ë¢°ë„ ê³„ì‚°
    best_category = None
    max_score = 0
    confidence = 0.0
    
    if category_scores:
        best_category = max(category_scores, key=category_scores.get)
        max_score = category_scores[best_category]
        total_scores = sum(category_scores.values())
        confidence = max_score / total_scores if total_scores > 0 else 0
    
    # 3. ì‚¬ê³  ê´€ë ¨ ì§•í›„ ê°ì§€
    accident_indicators = classifier._detect_accident_related_hints(user_input.lower())
    
    # 4. ìµœì¢… ë¶„ë¥˜ ê²°ê³¼
    final_category = classifier.classify(user_input)
    
    classification_reason = {
        'high_confidence': confidence >= 0.65 and max_score >= 4,
        'accident_hints': accident_indicators['is_accident_related'],
        'fallback_used': confidence < 0.65 or max_score < 4
    }
    
    return {
        'input': user_input,
        'keyword_scores': category_scores,
        'best_keyword_category': best_category,
        'max_score': max_score,
        'confidence': round(confidence, 3),
        'confidence_threshold': 0.65,
        'min_score_threshold': 4,
        'meets_threshold': confidence >= 0.65 and max_score >= 4,
        'accident_indicators': accident_indicators,
        'final_classification': final_category,
        'classification_reason': classification_reason,
        'classification_debug': {
            'category_scores': category_scores,
            'predicted_category': category,
            'confidence': confidence,
            'confidence_threshold': 0.65,
            'min_score_threshold': 4,
            'meets_threshold': confidence >= 0.65 and max_score >= 4,
            'classification_reason': classification_reason
        }
    }

def get_session_stats(session_id: str) -> Dict[str, Any]:
    """ì„¸ì…˜ í†µê³„ ì¡°íšŒ (í¸ì˜ í•¨ìˆ˜)"""
    bot = get_optimized_bot()
    return bot.conversation_manager.get_session_stats(session_id)
