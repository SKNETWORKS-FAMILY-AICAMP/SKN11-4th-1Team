"""
êµí†µì‚¬ê³  ì±—ë´‡ ì§ˆë¬¸ ë¶„ë¥˜ ì„œë¹„ìŠ¤ ë° RAG ì²˜ë¦¬
íŒŒì¸íŠœë‹ëœ GPT-3.5-turbo ëª¨ë¸ ì‚¬ìš© + OpenAI ì„ë² ë”© í†µì¼
"""

import openai
import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, List, Union
from django.conf import settings
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers import SelfQueryRetriever
from ..utils.vector_db import get_vector_db_manager

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„í¬íŠ¸ (ì§€ì—° ì„í¬íŠ¸ë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
def get_memory_manager():
    from ..utils.memory_system import get_memory_manager as _get_memory_manager
    return _get_memory_manager()

# ê³µí†µ ìƒìˆ˜ ì„í¬íŠ¸
from ..constants import (
    METADATA_KEYS, VECTOR_DB_COLLECTIONS, VALID_CATEGORIES, 
    FALLBACK_KEYWORDS, get_metadata_key, get_collection_name, is_valid_category
)

class TrafficAccidentClassifier:
    """
    íŒŒì¸íŠœë‹ëœ GPT-3.5-turboë¥¼ ì‚¬ìš©í•œ ì§ˆë¬¸ ë¶„ë¥˜ê¸° + RAG ì²˜ë¦¬ê¸°
    
    ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬:
    - accident: êµí†µì‚¬ê³  ìƒí™© ë¶„ì„
    - precedent: íŒë¡€ ê²€ìƒ‰
    - law: ë„ë¡œêµí†µë²• ì¡°íšŒ
    - term: ìš©ì–´ ì„¤ëª…
    - general: ì¼ë°˜ ì§ˆë¬¸
    """
    
    # constants.pyì—ì„œ ì„í¬íŠ¸ëœ ìƒìˆ˜ë“¤ ì‚¬ìš©
    # VALID_CATEGORIES, FALLBACK_KEYWORDSëŠ” constants.pyì—ì„œ ê´€ë¦¬
    

    
    def __init__(self):
        """ë¶„ë¥˜ê¸° ë° RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.client = openai.OpenAI(
                api_key=os.getenv('OPENAI_API_KEY')
            )
            
            # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ID
            self.model_id = os.getenv('FINETUNED_MODEL_ID')
            
            if not self.model_id:
                logger.warning("FINETUNED_MODEL_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í´ë°± ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            
            # GPT ëª¨ë¸ ì´ˆê¸°í™” (RAGìš©)
            self.gpt_4o_model = ChatOpenAI(
                model="gpt-4o-mini", 
                temperature=0,
                api_key=os.getenv('OPENAI_API_KEY')
            )
            
            # VectorDB ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.vector_db_manager = get_vector_db_manager()
            
            # modifier.json ê·œì¹™ ë¡œë“œ (ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ê¸°ì¤€)
            self._modifier_rules = self._load_modifier_rules()
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” (ì§€ì—° ì´ˆê¸°í™”)
            self._memory_manager = None
            
            logger.info(f"TrafficAccidentClassifier ì´ˆê¸°í™” ì™„ë£Œ (ë©”ëª¨ë¦¬ í¬í•¨) - ëª¨ë¸: {self.model_id}")
            
        except Exception as e:
            logger.error(f"ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    
    @property
    def memory_manager(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì í”„ë¡œí¼í‹° (ì§€ì—° ì´ˆê¸°í™”)"""
        if self._memory_manager is None:
            self._memory_manager = get_memory_manager()
        return self._memory_manager
    
    def classify_query(self, user_input: str) -> str:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
            
        Returns:
            str: ë¶„ë¥˜ ê²°ê³¼ ('accident', 'precedent', 'law', 'term', 'general')
        """
        import time
        start_time = time.time()
        
        if not user_input or not user_input.strip():
            return 'general'
        
        # 1ì°¨: íŒŒì¸íŠœë‹ëœ ëª¨ë¸ë¡œ ë¶„ë¥˜ ì‹œë„
        try:
            logger.info(f"íŒŒì¸íŠœë‹ ëª¨ë¸ ë¶„ë¥˜ ì‹œì‘: '{user_input[:30]}...'")
            api_start = time.time()
            
            category = self._classify_with_finetuned_model(user_input.strip())
            
            api_time = time.time() - api_start
            logger.info(f"API í˜¸ì¶œ ì‹œê°„: {api_time:.2f}ì´ˆ")
            
            if self._is_valid_category(category):
                total_time = time.time() - start_time
                logger.info(f"íŒŒì¸íŠœë‹ ëª¨ë¸ ë¶„ë¥˜ ì„±ê³µ: '{user_input[:30]}...' â†’ {category} (ì´ {total_time:.2f}ì´ˆ)")
                return category
        except Exception as e:
            logger.warning(f"íŒŒì¸íŠœë‹ ëª¨ë¸ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
        
        # 2ì°¨: í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ë¥˜
        fallback_start = time.time()
        category = self._fallback_classify(user_input.strip())
        fallback_time = time.time() - fallback_start
        
        total_time = time.time() - start_time
        logger.info(f"í´ë°± ë¶„ë¥˜ ì‚¬ìš©: '{user_input[:30]}...' â†’ {category} (í´ë°±: {fallback_time:.2f}ì´ˆ, ì´: {total_time:.2f}ì´ˆ)")
        return category
    
    def _load_modifier_rules(self) -> str:
        """
        modifier.jsonì„ ë¡œë“œí•˜ì—¬ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Returns:
            str: ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ê¸°ì¤€ í…ìŠ¤íŠ¸
        """
        try:
            # metadata ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            metadata_path = getattr(settings, 'METADATA_PATH', None)
            if not metadata_path:
                # settingsì— ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
                base_path = Path(__file__).parent.parent.parent.parent
                metadata_path = base_path / 'metadata'
            else:
                metadata_path = Path(metadata_path)
            
            modifier_path = metadata_path / 'modifier.json'
            
            if not modifier_path.exists():
                logger.warning(f"modifier.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {modifier_path}")
                return ""
            
            # JSON íŒŒì¼ ë¡œë“œ
            with open(modifier_path, 'r', encoding='utf-8') as f:
                modifier_data = json.load(f)
            
            # êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            rules_text = "## ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ê¸°ì¤€\n\n"
            
            for category in modifier_data:
                rules_text += f"### {category.get('category', 'ë¯¸ì§€ì •')}\n"
                
                if 'addable_percent' in category:
                    rules_text += f"**ê°€ì‚°ìœ¨**: {category['addable_percent']}\n"
                
                if 'description' in category:
                    rules_text += f"**ì„¤ëª…**: {category['description']}\n"
                
                if 'examples' in category and isinstance(category['examples'], list):
                    rules_text += "**ì˜ˆì‹œ**:\n"
                    for example in category['examples']:
                        rules_text += f"- {example}\n"
                
                if 'details' in category:
                    rules_text += "**ì„¸ë¶€ì‚¬í•­**:\n"
                    details = category['details']
                    
                    if isinstance(details, list):
                        for detail in details:
                            if isinstance(detail, str):
                                rules_text += f"- {detail}\n"
                            elif isinstance(detail, dict):
                                name = detail.get('name', 'ì´ë¦„ ì—†ìŒ')
                                percent_range = detail.get('percent_range', 'ë¹„ìœ¨ ì—†ìŒ')
                                explanation = detail.get('explanation', 'ì„¤ëª… ì—†ìŒ')
                                rules_text += f"- **{name}**: {percent_range} - {explanation}\n"
                    else:
                        rules_text += f"- {details}\n"
                
                rules_text += "\n"
            
            logger.info(f"modifier ê·œì¹™ ë¡œë“œ ì„±ê³µ: {len(modifier_data)}ê°œ ì¹´í…Œê³ ë¦¬")
            return rules_text
            
        except Exception as e:
            logger.error(f"modifier ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return ""
    
    def process_precedent(self, user_input: str) -> str:
        """
        Enhanced íŒë¡€ ê²€ìƒ‰ (íŒë¡€ë²ˆí˜¸ ì •í™•ì„± ê²€ì¦ í¬í•¨)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            str: íŒë¡€ ê²€ìƒ‰ ê²°ê³¼
        """
        import time
        start_time = time.time()
        
        try:
            logger.info(f"Enhanced íŒë¡€ ê²€ìƒ‰ ì‹œì‘: '{user_input[:30]}...'")
            
            # Enhanced Precedent Processor ì‚¬ìš©
            from .enhanced_precedent_processor import EnhancedPrecedentProcessor
            
            processor = EnhancedPrecedentProcessor(
                vector_db_manager=self.vector_db_manager,
                gpt_model=self.gpt_4o_model
            )
            
            result = processor.process_precedent_query(user_input)
            
            total_time = time.time() - start_time
            logger.info(f"Enhanced íŒë¡€ ê²€ìƒ‰ ì™„ë£Œ: '{user_input[:30]}...' (ì´: {total_time:.2f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            logger.error(f"Enhanced íŒë¡€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._generate_precedent_fallback_response(user_input)
    
    def process_law(self, user_input: str) -> str:
        """
        ë„ë¡œêµí†µë²• ì¡°íšŒ ë° ë¶„ì„ (OpenAI ì„ë² ë”© í†µì¼ ë°©ì‹)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            str: ë„ë¡œêµí†µë²• ì¡°íšŒ ê²°ê³¼
        """
        import time
        start_time = time.time()
        
        try:
            logger.info(f"ë„ë¡œêµí†µë²• ì¡°íšŒ ì‹œì‘: '{user_input[:30]}...'")
            
            # 1. VectorDBì—ì„œ traffic_law_rag ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
            law_db = self.vector_db_manager.get_vector_db(
                get_collection_name('TRAFFIC_LAW_RAG')
            )
            if not law_db:
                logger.error("traffic_law_rag VectorDBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return self._generate_law_fallback_response(user_input)
            
            # 2. ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ì˜ (Self-Query Retrieverìš©)
            metadata_field_info = [
                AttributeInfo(
                    name="article_title",
                    description="ë„ë¡œêµí†µë²• ì¡°ë¬¸ ì „ì²´ ì œëª© (ì˜ˆ: ì œ5ì¡°(ì‹ í˜¸ ë˜ëŠ” ì§€ì‹œì— ë”°ë¥¼ ì˜ë¬´), ì œ25ì¡°(êµì°¨ë¡œ í†µí–‰ë°©ë²•))",
                    type="string"
                ),
                AttributeInfo(
                    name="article_number",
                    description="ë„ë¡œêµí†µë²• ì¡°ë¬¸ ë²ˆí˜¸ (ì˜ˆ: ì œ5ì¡°, ì œ25ì¡°, ì œ27ì¡° ë“±)",
                    type="string"
                ),
                AttributeInfo(
                    name="article_name",
                    description="ë„ë¡œêµí†µë²• ì¡°ë¬¸ëª… (ì˜ˆ: ì‹ í˜¸ ë˜ëŠ” ì§€ì‹œì— ë”°ë¥¼ ì˜ë¬´, êµì°¨ë¡œ í†µí–‰ë°©ë²• ë“±)",
                    type="string"
                ),
                AttributeInfo(
                    name="subsection_title",
                    description="ì¡°ë¬¸ ë‚´ í•­ ì œëª© (ì˜ˆ: ì œ5ì¡° 1í•­, ì œ25ì¡° 2í•­ ë“±)",
                    type="string"
                ),
                AttributeInfo(
                    name="keywords",
                    description="ì¡°ë¬¸ ê´€ë ¨ í‚¤ì›Œë“œ (ì˜ˆ: ì‹ í˜¸, ì§€ì‹œ, êµí†µì•ˆì „ì‹œì„¤, ê²½ì°°ê³µë¬´ì› ë“±)",
                    type="string"
                )
            ]
            
            # 3. Self-Query Retriever ìƒì„±
            self_retriever = SelfQueryRetriever.from_llm(
                llm=self.gpt_4o_model,
                vectorstore=law_db,
                document_contents="ë„ë¡œêµí†µë²• ì¡°ë¬¸ ë‚´ìš© ë° í•´ì„ ë°ì´í„°",
                metadata_field_info=metadata_field_info,
                search_kwargs={"k": 5}  # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì¦ê°€
            )
            
            # 4. ë„ë¡œêµí†µë²• ì¡°íšŒ ë° ì„¤ëª… í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ì ì¹œí™”ì  í¬ë§·)
            prompt = PromptTemplate(
                input_variables=["question", "context"],
                template="""
ë„ˆëŠ” ë„ë¡œêµí†µë²•ì„ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ë¬¸ì„œ(context)ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ëœ ë„ë¡œêµí†µë²• ì¡°ë¬¸ì„ **ì‰½ê³  ì´í•´í•˜ê¸° ì‰¬ë¡­ê²Œ** ì„¤ëª…í•´ì¤˜.

---
ì§ˆë¬¸: {question}

ê²€ìƒ‰ëœ ë„ë¡œêµí†µë²• ë¬¸ì„œ:
{context}
---

ì¶œë ¥ í˜•ì‹:

ğŸ“š **ë„ë¡œêµí†µë²• ì¡°íšŒ ê²°ê³¼**

**ğŸ” ì¡°íšŒ ë‚´ìš©**: [ì‚¬ìš©ì ì§ˆë¬¸ ìš”ì•½]

**ğŸ“‹ ê´€ë ¨ ì¡°ë¬¸**:

**1ï¸âƒ£ [ì¡°ë¬¸ ì œëª©] - [ì¡°ë¬¸ë²ˆí˜¸]**
â€¢ **ì£¼ìš” ë‚´ìš©**: [ì£¼ìš” ë‚´ìš©ì„ 1-2ì¤„ë¡œ ê°„ë‹¨íˆ]
â€¢ **ìƒì„¸ ì„¤ëª…**: 
  - [ì£¼ìš” ìš”ì  1]
  - [ì£¼ìš” ìš”ì  2]
  - [ì£¼ìš” ìš”ì  3 (ìˆëŠ” ê²½ìš°ë§Œ)]
â€¢ **ìœ„ë°˜ ì‹œ ì²˜ë²Œ**: [ë²”ì¹™ê¸ˆ, ë²Œì  ë“± ëª…ì‹œëœ ê²½ìš°ë§Œ]

**2ï¸âƒ£ [ì¡°ë¬¸ ì œëª©] - [ì¡°ë¬¸ë²ˆí˜¸]**
â€¢ **ì£¼ìš” ë‚´ìš©**: [ì£¼ìš” ë‚´ìš©ì„ 1-2ì¤„ë¡œ ê°„ë‹¨íˆ]
â€¢ **ìƒì„¸ ì„¤ëª…**: [ì£¼ìš” ìš”ì ë“¤ì„ ì§ˆëŒ€ë³„ë¡œ ì •ë¦¬]
â€¢ **ìœ„ë°˜ ì‹œ ì²˜ë²Œ**: [ëª…ì‹œëœ ê²½ìš°ë§Œ í‘œì‹œ]

*(ìµœëŒ€ 3-4ê°œ ì¡°ë¬¸ë§Œ í‘œì‹œ)*

**ğŸ’¡ ì°¸ê³ ì‚¬í•­**:
- êµ¬ì²´ì ì¸ ì‚¬ê³  ìƒí™©ì— ë”°ë¼ ì ìš©ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ ìƒë‹´ì„ ë°›ì•„ë³´ì„¸ìš”

**ì¡°ê±´**:
- ê° ì¡°ë¬¸ì„ **ëª…í™•íˆ êµ¬ë¶„**í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”
- **ëŒ€ì¤‘ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´**ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- **ê¸´ ë‚´ìš©ì€ 1-2ì¤„ë¡œ ìš”ì•½**í•˜ì—¬ ì½ê¸° ì‰¬ë¡­ê²Œ í•˜ì„¸ìš”
- ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì„ì˜ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
- ì¡°ë¬¸ë²ˆí˜¸ì™€ ì œëª©ì„ **ì •í™•íˆ** í‘œì‹œí•˜ì„¸ìš”
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ íŠ¹ì • ì¡°ë¬¸ì„ ë¬¼ì–´ë´¤ë‹¤ë©´, í•´ë‹¹ ì¡°ë¬¸ì„ ìš°ì„ ì ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”

ë‹µë³€:
"""
            )
            
            # 5. QA ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
            qa_chain = RetrievalQA.from_chain_type(
                llm=self.gpt_4o_model,
                retriever=self_retriever,   # ìœ ì‚¬ë„ ê²€ìƒ‰
                chain_type="stuff",
                chain_type_kwargs={"prompt": prompt}
            )
            
            # 6. ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
            retrieval_start = time.time()
            result = qa_chain.invoke({"query": user_input})
            retrieval_time = time.time() - retrieval_start
            
            total_time = time.time() - start_time
            logger.info(f"ë„ë¡œêµí†µë²• ì¡°íšŒ ì™„ë£Œ: '{user_input[:30]}...' (ê²€ìƒ‰: {retrieval_time:.2f}ì´ˆ, ì´: {total_time:.2f}ì´ˆ)")
            
            return result['result']
            
        except Exception as e:
            logger.error(f"ë„ë¡œêµí†µë²• ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._generate_law_fallback_response(user_input)
    
    def process_accident(self, user_input: str) -> str:
        """
        êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ (RAG ê¸°ë°˜ + modifier ê·œì¹™ í¬í•¨)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            str: ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ê²°ê³¼
        """
        import time
        start_time = time.time()
        
        try:
            logger.info(f"ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ì‹œì‘: '{user_input[:30]}...'")
            
            # 1. VectorDBì—ì„œ car_case ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (modifier ì œì™¸ëœ ìˆœìˆ˜ ì‚¬ê³  ì‚¬ë¡€ë§Œ)
            car_case_db = self.vector_db_manager.get_vector_db(
                get_collection_name('CAR_CASE')
            )
            if not car_case_db:
                logger.error("car_case VectorDBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return self._generate_accident_fallback_response(user_input)
            
            # 2. ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ì˜ (Self-Query Retrieverìš©)
            metadata_field_info = [
                AttributeInfo(
                    name="id",
                    description="ì‚¬ê³  ì‚¬ë¡€ ID (ì˜ˆ: ì°¨01-1, ì°¨02-3 ë“±)",
                    type="string"
                ),
                AttributeInfo(
                    name="title",
                    description="ì‚¬ê³  ì‚¬ë¡€ ì œëª© (ì˜ˆ: êµì°¨ë¡œ ì¢ŒíšŒì „ vs ì§ì§„ ì‚¬ê³ )",
                    type="string"
                ),
                AttributeInfo(
                    name="situation",
                    description="ì‚¬ê³  ìƒí™© ì„¤ëª…",
                    type="string"
                ),
                AttributeInfo(
                    name="base_ratio",
                    description="ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨",
                    type="string"
                ),
                AttributeInfo(
                    name="modifiers",
                    description="ì¡°ì • ìš”ì†Œ",
                    type="string"
                ),
                AttributeInfo(
                    name="load_traffic_law",
                    description="ê´€ë ¨ ë²•ê·œ",
                    type="string"
                )
            ]
            
            # 3. Self-Query Retriever ìƒì„±
            self_retriever = SelfQueryRetriever.from_llm(
                llm=self.gpt_4o_model,
                vectorstore=car_case_db,
                document_contents="êµí†µì‚¬ê³  ìœ í˜•ë³„ ê³¼ì‹¤ë¹„ìœ¨ ì‚¬ë¡€ ë°ì´í„°",
                metadata_field_info=metadata_field_info,
                search_kwargs={"k": 3}
            )
            
            # 4. ì‚¬ê³  ì‚¬ë¡€ ê²€ìƒ‰
            retrieval_start = time.time()
            similar_cases = self_retriever.get_relevant_documents(user_input)
            retrieval_time = time.time() - retrieval_start
            
            if not similar_cases:
                logger.warning("ìœ ì‚¬í•œ ì‚¬ê³  ì‚¬ë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return self._generate_accident_fallback_response(user_input)
            
            # 5. ê²€ìƒ‰ëœ ì‚¬ë¡€ ì •ë³´ êµ¬ì„±
            cases_context = ""
            for i, case in enumerate(similar_cases):
                cases_context += f"\n=== ì‚¬ê³  ì‚¬ë¡€ {i+1} ===\n"
                cases_context += case.page_content + "\n"
            
            # 6. modifier ê·œì¹™ê³¼ í•¨ê»˜ ìµœì¢… ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            final_prompt = f"""
ë„ˆëŠ” êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ì „ë¬¸ê°€ì•¼.

## ì‚¬ìš©ì ì‚¬ê³  ìƒí™©
{user_input}

## ì°¸ê³  ì‚¬ê³  ì‚¬ë¡€ë“¤
{cases_context}

{self._modifier_rules}

## ë¶„ì„ ìš”ì²­
ìœ„ ì‚¬ê³  ìƒí™©ì„ ì°¸ê³  ì‚¬ë¡€ì™€ ë¹„êµ ë¶„ì„í•˜ê³ , ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ê¸°ì¤€ì„ ì ìš©í•˜ì—¬ ë‹¤ìŒì„ ì œì‹œí•´ì¤˜:

### ğŸ“‹ ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):

**ğŸ” ì‚¬ê³  ìƒí™© ë¶„ì„**
- ì‚¬ê³  ìœ„ì¹˜: [êµì°¨ë¡œ/ì¼ë°˜ë„ë¡œ/ì£¼ì°¨ì¥ ë“±]
- ì°¨ëŸ‰ í–‰ë™: Aì°¨ëŸ‰ [í–‰ë™], Bì°¨ëŸ‰ [í–‰ë™]
- íŠ¹ìˆ˜ ìƒí™©: [ì‹ í˜¸, ë‚ ì”¨, ì‹œê°„ëŒ€ ë“±]

**âš–ï¸ ìœ ì‚¬ ì‚¬ë¡€ ê¸°ë°˜ ê³¼ì‹¤ë¹„ìœ¨**
1. **ì°¸ê³  ì‚¬ë¡€**: [ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ë¡€ ì„ íƒ]
   - **ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨**: Aì°¨ëŸ‰ XX% vs Bì°¨ëŸ‰ XX%
   - **ì‚¬ë¡€ ê·¼ê±°**: [í•´ë‹¹ ì‚¬ë¡€ ì„ íƒ ì´ìœ ]

**ğŸ”§ ì¡°ì • ìš”ì†Œ ì ìš©**
- **ì ìš© ê°€ëŠ¥í•œ ì¡°ì • ìš”ì†Œ**:
  * [ì¡°ì • ìš”ì†Œ 1]: [ê°€ì‚°/ê°ì‚° ë¹„ìœ¨] - [ì¡°ì • ê¸°ì¤€ ì¹´í…Œê³ ë¦¬]
  * [ì¡°ì • ìš”ì†Œ 2]: [ê°€ì‚°/ê°ì‚° ë¹„ìœ¨] - [ì¡°ì • ê¸°ì¤€ ì¹´í…Œê³ ë¦¬]
- **ì¡°ì • ê·¼ê±°**: [ìœ„ ì¡°ì • ê¸°ì¤€ì—ì„œ í•´ë‹¹í•˜ëŠ” ê·œì¹™ ëª…ì‹œ]

**ğŸ¯ ìµœì¢… ì˜ˆìƒ ê³¼ì‹¤ë¹„ìœ¨**
- **Aì°¨ëŸ‰**: XX% (ê¸°ë³¸ XX% Â± ì¡°ì • XX%)
- **Bì°¨ëŸ‰**: XX% (ê¸°ë³¸ XX% Â± ì¡°ì • XX%)
- **ì¢…í•© íŒë‹¨**: [ìµœì¢… ë¹„ìœ¨ ê²°ì • ì´ìœ ]

**ğŸ“– ë²•ì  ê·¼ê±°**
- **ê´€ë ¨ ë²•ë ¹**: [ë„ë¡œêµí†µë²• ì¡°ë¬¸]
- **ì°¸ê³  íŒë¡€**: [ê´€ë ¨ íŒë¡€ê°€ ìˆë‹¤ë©´]

**âš ï¸ ì£¼ì˜ì‚¬í•­**
- [ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­]
- [ì‹¤ì œ ìƒí™©ì— ë”°ë¥¸ ë³€ë™ ê°€ëŠ¥ì„±]

### ì¡°ê±´:
- ë°˜ë“œì‹œ ì°¸ê³  ì‚¬ë¡€ ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•´
- ì¡°ì • ìš”ì†ŒëŠ” ìœ„ì— ì œì‹œëœ "ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ê¸°ì¤€"ì— ê·¼ê±°í•´ì„œë§Œ ì ìš©í•´
- ì¶”ì¸¡ì´ë‚˜ ìƒì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì œê³µëœ ìë£Œë§Œì„ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨í•´
- ì¡°ì • ìš”ì†Œê°€ ì—¬ëŸ¬ ê°œë©´ ì¤‘ë³µ ì ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ì¡°ì • ê¸°ì¤€ì—ì„œ í™•ì¸í•´
- ìµœì¢… ê³¼ì‹¤ë¹„ìœ¨ì€ 100%ê°€ ë˜ë„ë¡ ê³„ì‚°í•´
"""
            
            # 7. GPT ìµœì¢… ë¶„ì„
            analysis_start = time.time()
            response = self.gpt_4o_model.invoke(final_prompt)
            analysis_time = time.time() - analysis_start
            
            total_time = time.time() - start_time
            logger.info(f"ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ì™„ë£Œ: '{user_input[:30]}...' (ê²€ìƒ‰: {retrieval_time:.2f}ì´ˆ, ë¶„ì„: {analysis_time:.2f}ì´ˆ, ì´: {total_time:.2f}ì´ˆ)")
            
            return response.content
            
        except Exception as e:
            logger.error(f"ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._generate_accident_fallback_response(user_input)
    
    def process_user_query(self, user_input: str, use_memory: bool = False, session_id: str = None, user_id: str = None) -> Union[tuple, Dict[str, Any]]:
        """
        í†µí•© ì²˜ë¦¬ í•¨ìˆ˜ (ë¶„ë¥˜ + ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            use_memory (bool): ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
            session_id (str, optional): ì„¸ì…˜ ID (ë©”ëª¨ë¦¬ ì‚¬ìš© ì‹œ)
            user_id (str, optional): ì‚¬ìš©ì ID (ë©”ëª¨ë¦¬ ì‚¬ìš© ì‹œ)
            
        Returns:
            Union[tuple, Dict[str, Any]]: 
                - use_memory=False: (category, response) íŠœí”Œ
                - use_memory=True: ìƒì„¸ ì •ë³´ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
        """
        if use_memory:
            # ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ì‚¬ìš©
            return self.process_with_memory(user_input, session_id, user_id)
        else:
            # ê¸°ì¡´ ë°©ì‹ (ë©”ëª¨ë¦¬ ì—†ìŒ)
            return self._process_without_memory(user_input)
    
    def _process_without_memory(self, user_input: str) -> tuple:
        """
        ë©”ëª¨ë¦¬ ì—†ëŠ” ê¸°ë³¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            
        Returns:
            tuple: (category, response)
        """
        try:
            # 1. ì§ˆë¬¸ ë¶„ë¥˜
            category = self.classify_query(user_input)
            
            # 2. ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬
            if category == 'precedent':
                response = self.process_precedent(user_input)
            elif category == 'law':
                response = self.process_law(user_input)
            elif category == 'accident':
                response = self.process_accident(user_input)
            elif category == 'term':
                response = self.process_term(user_input)
            else:  # general
                response = self._process_general_placeholder(user_input)
            
            return category, response
            
        except Exception as e:
            logger.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return 'general', self._generate_error_response(user_input, str(e))
    
    def _classify_with_finetuned_model(self, user_input: str) -> str:
        """
        íŒŒì¸íŠœë‹ëœ GPT-3.5-turbo ëª¨ë¸ë¡œ ë¶„ë¥˜
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            
        Returns:
            str: ë¶„ë¥˜ ê²°ê³¼
            
        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        if not self.model_id:
            raise Exception("íŒŒì¸íŠœë‹ëœ ëª¨ë¸ IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        try:
            # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model_id,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¤ìŒ ì§ˆë¬¸ì„ accident, precedent, law, term, general ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": user_input
                    }
                ],
                max_tokens=10,
                temperature=0.0,
                timeout=5
            )
            
            # ì‘ë‹µ íŒŒì‹±
            category = response.choices[0].message.content.strip().lower()
            
            # ì‘ë‹µ ê²€ì¦
            if not self._is_valid_category(category):
                logger.warning(f"íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ë°˜í™˜: {category}")
                raise Exception(f"ì˜ëª»ëœ ë¶„ë¥˜ ê²°ê³¼: {category}")
            
            return category
            
        except openai.APITimeoutError:
            logger.error("OpenAI API íƒ€ì„ì•„ì›ƒ")
            raise Exception("API íƒ€ì„ì•„ì›ƒ")
        except openai.APIError as e:
            logger.error(f"OpenAI API ì—ëŸ¬: {str(e)}")
            raise Exception(f"API ì—ëŸ¬: {str(e)}")
        except Exception as e:
            logger.error(f"ë¶„ë¥˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}")
            raise
    
    def _fallback_classify(self, user_input: str) -> str:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë¶„ë¥˜
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            
        Returns:
            str: ë¶„ë¥˜ ê²°ê³¼
        """
        user_input_lower = user_input.lower()
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        category_scores = {}
        
        for category, keywords in FALLBACK_KEYWORDS.items():
            score = 0
            for keyword in keywords:
                if keyword in user_input_lower:
                    score += 1
            category_scores[category] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        if category_scores and max(category_scores.values()) > 0:
            best_category = max(category_scores.items(), key=lambda x: x[1])[0]
            logger.info(f"í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼: {category_scores}, ì„ íƒ: {best_category}")
            return best_category
        
        # ë§¤ì¹­ë˜ëŠ” í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ general
        return 'general'
    
    def _is_valid_category(self, category: str) -> bool:
        """
        ìœ íš¨í•œ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ì¸ì§€ í™•ì¸
        
        Args:
            category (str): ë¶„ë¥˜ ê²°ê³¼
            
        Returns:
            bool: ìœ íš¨ ì—¬ë¶€
        """
        return is_valid_category(category)
    
    def _generate_precedent_fallback_response(self, user_input: str) -> str:
        """íŒë¡€ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ (ê°œì„ ëœ í¬ë§·)"""
        return f"""âš–ï¸ **íŒë¡€ ê²€ìƒ‰ ê²°ê³¼**

**ğŸ” ê²€ìƒ‰ ë‚´ìš©**: "{user_input}"

**âš ï¸ ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ**

ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ íŒë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ğŸ’¡ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”**:

**ğŸ¯ êµ¬ì²´ì ì¸ ì‚¬ê±´ë²ˆí˜¸ë¡œ ê²€ìƒ‰**
â€¢ "ëŒ€ë²•ì› 2019ë‹¤12345 íŒë¡€ ë‚´ìš©ì€?"
â€¢ "ì„œìš¸ê³ ë“±ë²•ì› 2015ë‚˜60480 íŒë¡€ ê²€ìƒ‰"

**ğŸ¯ ì‚¬ê³  ìœ í˜•ê³¼ í•¨ê»˜ ê²€ìƒ‰**
â€¢ "êµì°¨ë¡œ ì¢ŒíšŒì „ ì‚¬ê³  íŒë¡€"
â€¢ "ì‹ í˜¸ìœ„ë°˜ ê´€ë ¨ íŒë¡€"
â€¢ "ì£¼ì°¨ì¥ ì ‘ì´‰ì‚¬ê³  íŒë¡€"

**ğŸ¯ ë²•ì›ë³„ ê²€ìƒ‰**
â€¢ "ëŒ€ë²•ì› êµí†µì‚¬ê³  íŒë¡€"
â€¢ "ê³ ë“±ë²•ì› ê³¼ì‹¤ë¹„ìœ¨ íŒë¡€"

**ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!**"""
    
    def _generate_law_fallback_response(self, user_input: str) -> str:
        """ë„ë¡œêµí†µë²• ì¡°íšŒ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ (ê°œì„ ëœ í¬ë§·)"""
        return f"""ğŸ“š **ë„ë¡œêµí†µë²• ì¡°íšŒ ê²°ê³¼**

**ğŸ” ì¡°íšŒ ë‚´ìš©**: "{user_input}"

**âš ï¸ ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ**

ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë„ë¡œêµí†µë²• ì¡°íšŒ ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ğŸ’¡ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”**:

**ğŸ¯ êµ¬ì²´ì ì¸ ì¡°ë¬¸ë²ˆí˜¸ë¡œ ê²€ìƒ‰**
â€¢ "ë„ë¡œêµí†µë²• ì œ5ì¡° ë‚´ìš©ì€?"
â€¢ "ì œ25ì¡° êµì°¨ë¡œ í†µí–‰ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”"

**ğŸ¯ í‚¤ì›Œë“œì™€ í•¨ê»˜ ê²€ìƒ‰**
â€¢ "ì‹ í˜¸ìœ„ë°˜ ì²˜ë²Œ ê·œì •"
â€¢ "êµì°¨ë¡œ í†µí–‰ ê·œì¹™"
â€¢ "ì°¨ë¡œë³€ê²½ ê´€ë ¨ ë²•ë¥ "

**ğŸ¯ ìƒí™©ë³„ ê²€ìƒ‰**
â€¢ "ì¢ŒíšŒì „ ê´€ë ¨ ë„ë¡œêµí†µë²•"
â€¢ "ì†ë„ìœ„ë°˜ ë²Œê¸ˆ ê·œì •"
â€¢ "ë³´í–‰ì ë³´í˜¸ ì˜ë¬´ ë²•ë¥ "

**ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!**"""
    
    def process_term(self, user_input: str) -> str:
        """
        êµí†µì‚¬ê³  ê´€ë ¨ ìš©ì–´ ì„¤ëª… (RAG ê¸°ë°˜)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            str: ìš©ì–´ ì„¤ëª… ê²°ê³¼
        """
        import time
        start_time = time.time()
        
        try:
            logger.info(f"ìš©ì–´ ì„¤ëª… ì‹œì‘: '{user_input[:30]}...'")
            
            # 1. VectorDBì—ì„œ term ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
            term_db = self.vector_db_manager.get_vector_db(
                get_collection_name('TERM')
            )
            if not term_db:
                logger.error("term VectorDBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return self._generate_term_fallback_response(user_input)
            
            # 2. ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ì˜ (Self-Query Retrieverìš©)
            metadata_field_info = [
                AttributeInfo(
                    name="term_category",
                    description="ìš©ì–´ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ë²•ë¥ ìš©ì–´, ì‚¬ê³ ìœ í˜•, ë„ë¡œì‹œì„¤ ë“±)",
                    type="string"
                ),
                AttributeInfo(
                    name="related_terms",
                    description="ê´€ë ¨ ìš©ì–´ë“¤",
                    type="string"
                ),
                AttributeInfo(
                    name="law_reference",
                    description="ê´€ë ¨ ë²•ê·œ ì¡°ë¬¸",
                    type="string"
                ),
                AttributeInfo(
                    name="precedent_reference",
                    description="ê´€ë ¨ íŒë¡€",
                    type="string"
                )
            ]
            
            # 3. Self-Query Retriever ìƒì„±
            self_retriever = SelfQueryRetriever.from_llm(
                llm=self.gpt_4o_model,
                vectorstore=term_db,
                document_contents="êµí†µì‚¬ê³  ê´€ë ¨ ìš©ì–´ ë° ì •ì˜ ë°ì´í„°",
                metadata_field_info=metadata_field_info,
                search_kwargs={"k": 3}
            )
            
            # 4. ìš©ì–´ ì„¤ëª… í”„ë¡¬í”„íŠ¸
            prompt = PromptTemplate(
                input_variables=["question", "context"],
                template="""
ë„ˆëŠ” êµí†µì‚¬ê³  ê´€ë ¨ ìš©ì–´ë¥¼ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ë¬¸ì„œ(context)ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.

---
ì§ˆë¬¸: {question}

ê²€ìƒ‰ëœ ìš©ì–´ ì •ë³´:
{context}
---

ì¶œë ¥ í˜•ì‹:

ğŸ“– **ìš©ì–´ ì„¤ëª…**

**ğŸ” ì§ˆë¬¸**: [ì‚¬ìš©ì ì§ˆë¬¸]

**ğŸ“š ìš©ì–´ ì •ì˜**:
â€¢ **ì •ì˜**: [ìš©ì–´ì˜ ì •í™•í•œ ì •ì˜]
â€¢ **ë²•ì  ê·¼ê±°**: [ê´€ë ¨ ë²•ê·œ]
â€¢ **ì‹¤ë¬´ ì ìš©**: [ì‹¤ë¬´ì—ì„œì˜ ì ìš© ë°©ë²•]

**ğŸ’¡ ì‰½ê²Œ ì„¤ëª…**:
[ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…]

**ğŸ”— ê´€ë ¨ ìš©ì–´**:
â€¢ [ê´€ë ¨ ìš©ì–´ 1]: [ê°„ë‹¨ ì„¤ëª…]
â€¢ [ê´€ë ¨ ìš©ì–´ 2]: [ê°„ë‹¨ ì„¤ëª…]

**ğŸ“Œ ì°¸ê³ ì‚¬í•­**:
â€¢ [ì£¼ì˜ì‚¬í•­ 1]
â€¢ [ì£¼ì˜ì‚¬í•­ 2]

**ì¡°ê±´**:
- ì „ë¬¸ ìš©ì–´ëŠ” ë°˜ë“œì‹œ ì‰¬ìš´ ì–¸ì–´ë¡œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- ë²•ì  ê·¼ê±°ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
- ê´€ë ¨ ìš©ì–´ëŠ” 2-3ê°œë§Œ ì„ íƒì ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”
- ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì„ì˜ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ìê°€ íŠ¹ì • ìš©ì–´ë¥¼ ë¬¼ì–´ë´¤ë‹¤ë©´, í•´ë‹¹ ìš©ì–´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”

ë‹µë³€:
"""
            )
            
            # 5. QA ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
            qa_chain = RetrievalQA.from_chain_type(
                llm=self.gpt_4o_model,
                retriever=self_retriever,
                chain_type="stuff",
                chain_type_kwargs={"prompt": prompt}
            )
            
            # 6. ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
            retrieval_start = time.time()
            result = qa_chain.invoke({"query": user_input})
            retrieval_time = time.time() - retrieval_start
            
            total_time = time.time() - start_time
            logger.info(f"ìš©ì–´ ì„¤ëª… ì™„ë£Œ: '{user_input[:30]}...' (ê²€ìƒ‰: {retrieval_time:.2f}ì´ˆ, ì´: {total_time:.2f}ì´ˆ)")
            
            return result['result']
            
        except Exception as e:
            logger.error(f"ìš©ì–´ ì„¤ëª… ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._generate_term_fallback_response(user_input)
    
    def _generate_term_fallback_response(self, user_input: str) -> str:
        """ìš©ì–´ ì„¤ëª… ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ"""
        return f"""ğŸ“– **ìš©ì–´ ì„¤ëª… ê²°ê³¼**

**ğŸ” ì§ˆë¬¸ ë‚´ìš©**: "{user_input}"

**âš ï¸ ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ**

ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš©ì–´ ì„¤ëª… ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ğŸ’¡ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”**:

**ğŸ¯ êµ¬ì²´ì ì¸ ìš©ì–´ë¡œ ê²€ìƒ‰**
â€¢ "ê³¼ì‹¤ë¹„ìœ¨ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
â€¢ "ì‹ í˜¸ìœ„ë°˜ì˜ ì •ì˜ëŠ”?"
â€¢ "êµì°¨ë¡œ í†µí–‰ë°©ë²• ì„¤ëª…í•´ì£¼ì„¸ìš”"

**ğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰**
â€¢ "ë²•ë¥  ìš©ì–´: ê³¼ì‹¤ì´ë€?"
â€¢ "ì‚¬ê³  ìœ í˜•: ì¶”ëŒì‚¬ê³ ë€?"
â€¢ "ë„ë¡œ ì‹œì„¤: êµì°¨ë¡œë€?"

**ğŸ¯ ê´€ë ¨ ìš©ì–´ ê²€ìƒ‰**
â€¢ "ê³¼ì‹¤ë¹„ìœ¨ê³¼ ê´€ë ¨ëœ ìš©ì–´ë“¤"
â€¢ "ì‹ í˜¸ìœ„ë°˜ ê´€ë ¨ ìš©ì–´"
â€¢ "êµì°¨ë¡œ í†µí–‰ ê´€ë ¨ ìš©ì–´"

**ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!**"""
    
    def _process_general_placeholder(self, user_input: str) -> str:
        """ì¼ë°˜ ì§ˆë¬¸ í”Œë ˆì´ìŠ¤í™€ë” - ê°œì„ ëœ í¬ë§·"""
        return f"""ğŸ‘‹ **ë…¸ëŠ ìƒë‹´ ì±—ë´‡**

ì•ˆë…•í•˜ì„¸ìš”! êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ìƒë‹´ ì±—ë´‡ **ë…¸ëŠ**ì…ë‹ˆë‹¤! ğŸš—

**ğŸ¯ í˜„ì¬ ì´ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**:

**âœ… íŒë¡€ ê²€ìƒ‰** (ì™„ë£Œ)
â€¢ "ëŒ€ë²•ì› 92ë„2077 íŒë¡€ ë‚´ìš©ì€?"
â€¢ "êµì°¨ë¡œ ì¢ŒíšŒì „ ì‚¬ê³  íŒë¡€ ê²€ìƒ‰"
â€¢ "ì‹ í˜¸ìœ„ë°˜ ê´€ë ¨ íŒë¡€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"

**ğŸ”§ ê°œë°œ ì¤‘ì¸ ê¸°ëŠ¥**:
â€¢ ğŸš— **êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„**
â€¢ ğŸ“– **êµí†µì‚¬ê³  ìš©ì–´ ì„¤ëª…**

**ğŸ’¡ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´**:
â€¢ êµ¬ì²´ì ì¸ ì‚¬ê±´ë²ˆí˜¸ë‚˜ ì‚¬ê³  ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”
â€¢ ê¶ê¸ˆí•œ íŒë¡€ë‚˜ ë²•ë¥  ì¡°ë¬¸ì„ ë§ì”€í•´ì£¼ì„¸ìš”

**ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?** ğŸ˜Š"""
    
    def _generate_error_response(self, user_input: str, error_msg: str) -> str:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‘ë‹µ - ê°œì„ ëœ í¬ë§·"""
        return f"""âŒ **ì‹œìŠ¤í…œ ì¼ì‹œ ì˜¤ë¥˜**

**ğŸ” ìš”ì²­ ë‚´ìš©**: "{user_input}"

**âš ï¸ ì˜¤ë¥˜ ìƒí™©**
ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ğŸ’¡ í•´ê²° ë°©ë²•**:
â€¢ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
â€¢ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”
â€¢ êµ¬ì²´ì ì¸ ì‚¬ê±´ë²ˆí˜¸ë‚˜ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”

**ğŸ¯ ì¶”ì²œ ì§ˆë¬¸ ë°©ì‹**:
â€¢ "ëŒ€ë²•ì› [ì‚¬ê±´ë²ˆí˜¸] íŒë¡€"
â€¢ "[ì‚¬ê³ ìœ í˜•] ê´€ë ¨ íŒë¡€"
â€¢ "[ë²•ì›ëª…] êµí†µì‚¬ê³  íŒë¡€"

**ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!** ğŸ™

*ê¸°ìˆ  ì •ë³´: {error_msg}*"""
    
    def _generate_accident_fallback_response(self, user_input: str) -> str:
        """ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ"""
        return f"""ğŸš— **êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ê²°ê³¼**\n\n**ğŸ” ì§ˆë¬¸ ë‚´ìš©**: \"{user_input}\"\n\n**âš ï¸ ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ**\n\nì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„ ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n**ğŸ’¡ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”**:\nâ€¢ ì‚¬ê³ ìœ í˜•ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš” (ì˜ˆ: êµì°¨ë¡œ ì¢ŒíšŒì „ vs ì§ì§„)\nâ€¢ ì‹ í˜¸, ìœ„ì¹˜, ë„ë¡œ ìƒí™© ë“±ë„ í•¨ê»˜ ì…ë ¥í•´ ì£¼ì„¸ìš”\n\n**ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!**"""
    
    def get_classification_stats(self) -> Dict[str, Any]:
        """
        ë¶„ë¥˜ê¸° í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        return {
            'model_id': self.model_id,
            'valid_categories': list(VALID_CATEGORIES),
            'fallback_keywords_count': {
                category: len(keywords) 
                for category, keywords in FALLBACK_KEYWORDS.items()
            },
            'implemented_functions': ['classify_query', 'process_precedent', 'process_law'],
            'upcoming_functions': ['process_accident', 'process_term'],
            'status': 'partial_implementation',
            'memory_enabled': True
        }
    
    # ======= ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ì¶”ê°€ ë©”ì„œë“œë“¤ =======
    
    def process_with_memory(self, user_input: str, session_id: str = None, user_id: str = None) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ í†µí•© ì§ˆë¬¸ ì²˜ë¦¬
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            session_id (str, optional): ì„¸ì…˜ ID
            user_id (str, optional): ì‚¬ìš©ì ID
            
        Returns:
            Dict[str, Any]: ì²˜ë¦¬ ê²°ê³¼ (ì‘ë‹µ, ì„¸ì…˜ ì •ë³´, ë©”ëª¨ë¦¬ ì¸ì‚¬ì´íŠ¸ ë“±)
        """
        try:
            # 1. ì§ˆë¬¸ ë¶„ë¥˜ (ê¸°ì¡´ ë©”ì„œë“œ ì‚¬ìš©)
            category = self.classify_query(user_input)
            logger.info(f"ë©”ëª¨ë¦¬ ëª¨ë“œ ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼: {category}")
            
            # 2. ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì„¸ì…˜ ê´€ë¦¬ ë° ê¸°ë³¸ ì •ë³´ ê¸°ë¡
            if category == 'general':
                # ì¼ë°˜ ì§ˆë¬¸ì€ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì²˜ë¦¬
                memory_result = self.memory_manager.process_general_query(
                    user_input, session_id, user_id
                )
                return {
                    'session_id': memory_result['session_id'],
                    'category': category,
                    'response': memory_result['response'],
                    'memory_insights': memory_result.get('memory_insights', {}),
                    'user_stats': memory_result.get('user_stats', {}),
                    'recommendations': memory_result.get('recommendations', []),
                    'status': 'success'
                }
            else:
                # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ í›„ AI ì²˜ë¦¬
                memory_info = self.memory_manager.process_any_category(
                    user_input, category, session_id, user_id
                )
                
                # 3. AI ì²˜ë¦¬ (ê¸°ì¡´ ë©”ì„œë“œ ì‚¬ìš©)
                if category == 'accident':
                    ai_response = self.process_accident(user_input)
                elif category == 'precedent':
                    ai_response = self.process_precedent(user_input)
                elif category == 'law':
                    ai_response = self.process_law(user_input)
                elif category == 'term':
                    ai_response = self.process_term(user_input)
                else:
                    ai_response = self._process_general_placeholder(user_input)
                
                # 4. AI ì‘ë‹µì„ ë©”ëª¨ë¦¬ì— ê¸°ë¡
                self.memory_manager.record_response(
                    memory_info['session_id'], ai_response, category
                )
                
                # 5. ìµœì¢… ê²°ê³¼ êµ¬ì„±
                return {
                    'session_id': memory_info['session_id'],
                    'category': category,
                    'response': ai_response,
                    'memory_insights': memory_info.get('memory_insights', {}),
                    'user_stats': memory_info.get('user_stats', {}),
                    'recommendations': self._get_session_recommendations(memory_info['session_id']),
                    'status': 'success'
                }
                
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ í†µí•© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'session_id': session_id or 'error',
                'category': 'error',
                'response': self._generate_error_response(user_input, str(e)),
                'memory_insights': {},
                'user_stats': {},
                'recommendations': [],
                'status': 'error'
            }
    
    def _get_session_recommendations(self, session_id: str) -> List[str]:
        """ì„¸ì…˜ ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        try:
            session_summary = self.memory_manager.get_session_summary(session_id)
            if not session_summary:
                return []
            
            recommendations = []
            category_usage = session_summary.get('category_usage', {})
            
            # ì‚¬ìš©í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ ì¶”ì²œ
            all_categories = {'accident', 'precedent', 'law', 'term', 'general'}
            unused_categories = all_categories - set(category_usage.keys())
            
            category_suggestions = {
                'accident': 'êµí†µì‚¬ê³  ìƒí™©ì„ ì…ë ¥í•´ì„œ ê³¼ì‹¤ë¹„ìœ¨ì„ ë¶„ì„í•´ë³´ì„¸ìš”',
                'precedent': 'êµ¬ì²´ì ì¸ ì‚¬ê±´ë²ˆí˜¸ë¡œ íŒë¡€ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”',
                'law': 'ë„ë¡œêµí†µë²• ì¡°ë¬¸ì„ ì¡°íšŒí•´ë³´ì„¸ìš”',
                'term': 'ê¶ê¸ˆí•œ ë²•ë¥  ìš©ì–´ë¥¼ ì§ˆë¬¸í•´ë³´ì„¸ìš”'
            }
            
            for category in unused_categories:
                if category in category_suggestions:
                    recommendations.append(category_suggestions[category])
            
            # ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì‹¬í™” ì¶”ì²œ
            if category_usage:
                most_used = max(category_usage.items(), key=lambda x: x[1])[0]
                if most_used == 'precedent':
                    recommendations.append('ë‹¤ë¥¸ ë²•ì›(ê³ ë“±ë²•ì›, ì§€ë°©ë²•ì›) íŒë¡€ë„ ê²€ìƒ‰í•´ë³´ì„¸ìš”')
                elif most_used == 'law':
                    recommendations.append('ê´€ë ¨ íŒë¡€ì™€ í•¨ê»˜ ë²•ë¥ ì„ ë¹„êµí•´ë³´ì„¸ìš”')
                elif most_used == 'term':
                    recommendations.append('ì‹¤ì œ ì‚¬ê³  ìƒí™©ì— ìš©ì–´ë¥¼ ì ìš©í•´ë³´ì„¸ìš”')
            
            return recommendations[:3]  # ìµœëŒ€ 3ê°œë§Œ
            
        except Exception as e:
            logger.error(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def get_session_insights(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ"""
        try:
            return self.memory_manager.get_session_summary(session_id) or {}
        except Exception as e:
            logger.error(f"ì„¸ì…˜ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def cleanup_old_sessions(self) -> int:
        """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬"""
        try:
            return self.memory_manager.cleanup_expired_sessions()
        except Exception as e:
            logger.error(f"ì„¸ì…˜ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return 0
    
    def export_session_data(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        try:
            return self.memory_manager.export_session_data(session_id) or {}
        except Exception as e:
            logger.error(f"ì„¸ì…˜ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}


# ì „ì—­ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_classifier_instance = None

def get_classifier() -> TrafficAccidentClassifier:
    """
    ë¶„ë¥˜ê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        TrafficAccidentClassifier: ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    global _classifier_instance
    
    if _classifier_instance is None:
        _classifier_instance = TrafficAccidentClassifier()
    
    return _classifier_instance


# í¸ì˜ í•¨ìˆ˜ë“¤
def classify_user_query(user_input: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ë¥˜ í¸ì˜ í•¨ìˆ˜
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        str: ë¶„ë¥˜ ê²°ê³¼
    """
    classifier = get_classifier()
    return classifier.classify_query(user_input)


def process_user_query(user_input: str) -> tuple:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ í¸ì˜ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ê¸°ë³¸ í™œì„±í™”, í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        tuple: (category, response) - í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ tuple ìœ ì§€
    """
    classifier = get_classifier()
    result = classifier.process_user_query(user_input, use_memory=True)
    
    # ë©”ëª¨ë¦¬ ëª¨ë“œì—ì„œëŠ” Dictë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ tupleë¡œ ë³€í™˜
    if isinstance(result, dict):
        return result['category'], result['response']
    else:
        # ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        return classifier.process_user_query(user_input, use_memory=False)


# ======= ë©”ëª¨ë¦¬ ê¸°ëŠ¥ í†µí•© í¸ì˜ í•¨ìˆ˜ë“¤ =======

def process_user_query_with_memory(user_input: str, session_id: str = None, user_id: str = None) -> Dict[str, Any]:
    """
    ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì´ í†µí•©ëœ ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ í¸ì˜ í•¨ìˆ˜
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        session_id (str, optional): ì„¸ì…˜ ID
        user_id (str, optional): ì‚¬ìš©ì ID
        
    Returns:
        Dict[str, Any]: ì²˜ë¦¬ ê²°ê³¼
        
    Example:
        result = process_user_query_with_memory("êµì°¨ë¡œ ì‚¬ê³ ", session_id="abc123")
        response = result['response']
        session_id = result['session_id']
        insights = result['memory_insights']
    """
    classifier = get_classifier()
    return classifier.process_user_query(user_input, use_memory=True, session_id=session_id, user_id=user_id)


def get_user_session_insights(session_id: str) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì„¸ì…˜ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜
    
    Args:
        session_id (str): ì„¸ì…˜ ID
        
    Returns:
        Dict[str, Any]: ì„¸ì…˜ ì¸ì‚¬ì´íŠ¸
    """
    classifier = get_classifier()
    return classifier.get_session_insights(session_id)


def cleanup_expired_sessions() -> int:
    """
    ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬ í¸ì˜ í•¨ìˆ˜
    
    Returns:
        int: ì •ë¦¬ëœ ì„¸ì…˜ ìˆ˜
    """
    classifier = get_classifier()
    return classifier.cleanup_old_sessions()


def export_user_session_data(session_id: str) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì„¸ì…˜ ë°ì´í„° ë‚´ë³´ë‚´ê¸° í¸ì˜ í•¨ìˆ˜
    
    Args:
        session_id (str): ì„¸ì…˜ ID
        
    Returns:
        Dict[str, Any]: ì„¸ì…˜ ë°ì´í„°
    """
    classifier = get_classifier()
    return classifier.export_session_data(session_id)
