"""
VectorDB ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
ui.pyì˜ ChromaDB ë¡œì§ì„ Djangoë¡œ ì´ì‹ (ìµœì‹  langchain-chroma ì‚¬ìš©)
"""

import os
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from langchain.schema import Document
from langchain_chroma import Chroma  # ìµœì‹  ë°©ì‹
from langchain_openai import OpenAIEmbeddings
from django.conf import settings
from .document_processor import DocumentProcessor

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


class VectorDBManager:
    """
    ChromaDBë¥¼ ì‚¬ìš©í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì
    ui.pyì˜ VectorDB ë¡œì§ì„ Djangoì— ë§ê²Œ ì´ì‹ (ìµœì‹  langchain-chroma 0.1.4)
    """
    
    # ë²¡í„°DB ì»¬ë ‰ì…˜ ì´ë¦„ ì •ì˜ (ì‹¤ì œ ìƒì„±ëœ ì»¬ë ‰ì…˜ëª…ê³¼ ì¼ì¹˜)
    VECTOR_DB_COLLECTION = {
        'TERM': "term",
        'TRAFFIC_LAW_RAG': "traffic_law_rag",  # traffic_law_rag.jsonì—ì„œ ìƒì„±
        'CAR_CASE': "car_case",               # car_to_car.jsonì—ì„œ ìƒì„±
        'PRECEDENT': "precedent",             # precedent.jsonì—ì„œ ìƒì„±
    }
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì»¬ë ‰ì…˜ ë§¤í•‘ (ai_classifier.pyì—ì„œ ì‚¬ìš©)
    COLLECTIONS = {
        'term': 'term',                       # ìš©ì–´ ì„¤ëª…
        'law': 'traffic_law_rag',            # ë„ë¡œêµí†µë²• (traffic_law_rag.json)
        'car_case': 'car_case',              # êµí†µì‚¬ê³  ì‚¬ë¡€ (car_to_car.json)
        'precedent': 'precedent',            # íŒë¡€ (precedent.json)
    }
    
    def __init__(self, vector_db_path: str = None, embedding_model_name: str = 'text-embedding-3-large'):
        """
        VectorDB ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            vector_db_path: VectorDB ì €ì¥ ê²½ë¡œ (Noneì´ë©´ settingsì—ì„œ ê°€ì ¸ì˜´)
            embedding_model_name: OpenAI ì„ë² ë”© ëª¨ë¸ëª…
        """
        # VectorDB ì €ì¥ ê²½ë¡œ ì„¤ì •
        if vector_db_path:
            self.vector_db_path = Path(vector_db_path)
        else:
            self.vector_db_path = getattr(
                settings, 
                'VECTOR_DB_PATH', 
                Path(__file__).parent.parent.parent / 'vector_db'
            )
        
        # ê²½ë¡œ ìƒì„±
        self.vector_db_path.mkdir(parents=True, exist_ok=True)
        
        # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        try:
            self.embedding_model = OpenAIEmbeddings(
                model=embedding_model_name,
                api_key=getattr(settings, 'OPENAI_API_KEY', None)
            )
            logger.info(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {embedding_model_name}")
        except Exception as e:
            logger.error(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
        
        # ì´ˆê¸°í™”ëœ ì»¬ë ‰ì…˜ë“¤ ìºì‹œ
        self._collection_cache = {}
        
        logger.info(f"VectorDBManager ì´ˆê¸°í™” ì™„ë£Œ - ê²½ë¡œ: {self.vector_db_path}")
        logger.info(f"ì§€ì› ì»¬ë ‰ì…˜: {list(self.COLLECTIONS.keys())} â†’ {list(self.COLLECTIONS.values())}")
    
    def docs_to_chroma_db(self, docs: List[Document], collection_name: str) -> Chroma:
        """
        Documentë¥¼ ChromaDBì— ì €ì¥/ë¡œë“œ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ í† í° ì œí•œ í•´ê²°)
        
        Args:
            docs: ì €ì¥í•  Document ë¦¬ìŠ¤íŠ¸
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            
        Returns:
            Chroma: ChromaDB ì¸ìŠ¤í„´ìŠ¤
        """
        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹œë„
            try:
                vectorstore = Chroma(
                    persist_directory=str(self.vector_db_path),
                    embedding_function=self.embedding_model,
                    collection_name=collection_name
                )
                
                # ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì•ˆì „í•œ ë°©ë²•)
                try:
                    collection_count = vectorstore._collection.count()
                    if collection_count > 0:
                        logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´(ê°€) ì¡´ì¬í•˜ì—¬ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ë¬¸ì„œ ìˆ˜: {collection_count})")
                        # ìºì‹œì— ì €ì¥
                        self._collection_cache[collection_name] = vectorstore
                        return vectorstore
                    else:
                        # ì»¬ë ‰ì…˜ì€ ìˆì§€ë§Œ ë¹„ì–´ìˆìŒ
                        logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´ ë¹„ì–´ìˆì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                        raise Exception("Empty collection")
                except Exception:
                    # ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ìƒˆë¡œ ìƒì„±
                    raise Exception("Collection check failed")
                    
            except Exception:
                # ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´(ê°€) ì—†ì–´ ìƒˆë¡œ ìƒì„±í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                
                if not docs:
                    raise ValueError(f"ë¬¸ì„œê°€ ì—†ì–´ì„œ ì»¬ë ‰ì…˜ '{collection_name}'ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # ğŸ”§ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ (í† í° ì œí•œ í•´ê²°)
                batch_size = 50  # ë°°ì¹˜ í¬ê¸° (í† í° ì œí•œì— ë§ê²Œ ì¡°ì •)
                total_docs = len(docs)
                
                if total_docs <= batch_size:
                    # ì‘ì€ ë°ì´í„°ëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                    vectorstore = Chroma.from_documents(
                        documents=docs,
                        embedding=self.embedding_model,
                        persist_directory=str(self.vector_db_path),
                        collection_name=collection_name
                    )
                else:
                    # ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ë°°ì¹˜ ì²˜ë¦¬
                    logger.info(f"ëŒ€ìš©ëŸ‰ ë°ì´í„° ({total_docs}ê°œ) ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ - ë°°ì¹˜ í¬ê¸°: {batch_size}")
                    
                    # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ ì»¬ë ‰ì…˜ ìƒì„±
                    first_batch = docs[:batch_size]
                    vectorstore = Chroma.from_documents(
                        documents=first_batch,
                        embedding=self.embedding_model,
                        persist_directory=str(self.vector_db_path),
                        collection_name=collection_name
                    )
                    logger.info(f"ì²« ë²ˆì§¸ ë°°ì¹˜ ì™„ë£Œ: {len(first_batch)}ê°œ ë¬¸ì„œ")
                    
                    # ë‚˜ë¨¸ì§€ ë°°ì¹˜ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€
                    for i in range(batch_size, total_docs, batch_size):
                        batch = docs[i:i + batch_size]
                        vectorstore.add_documents(batch)
                        logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ: {len(batch)}ê°œ ë¬¸ì„œ ì¶”ê°€ ({i + len(batch)}/{total_docs})")
                
                # ìºì‹œì— ì €ì¥
                self._collection_cache[collection_name] = vectorstore
                logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„± ì™„ë£Œ - ì´ ë¬¸ì„œ ìˆ˜: {total_docs}")
                return vectorstore
                
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ '{collection_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def get_vector_db(self, collection_name: str) -> Optional[Chroma]:
        """
        ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ (ChromaDB ì •í™•í•œ í™•ì¸ ë°©ë²•)
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            
        Returns:
            Chroma: ChromaDB ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ None)
        """
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        if collection_name in self._collection_cache:
            return self._collection_cache[collection_name]
        
        try:
            # ChromaDBë¡œ ì§ì ‘ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹œë„ (ìˆ˜ì •ëœ ë°©ì‹)
            vectorstore = Chroma(
                persist_directory=str(self.vector_db_path),
                embedding_function=self.embedding_model,
                collection_name=collection_name
            )
            
            # ì»¬ë ‰ì…˜ì— ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            try:
                collection_count = vectorstore._collection.count()
                if collection_count > 0:
                    # ìºì‹œì— ì €ì¥
                    self._collection_cache[collection_name] = vectorstore
                    logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}' ë¡œë“œ ì™„ë£Œ - ë¬¸ì„œ ìˆ˜: {collection_count}")
                    return vectorstore
                else:
                    logger.warning(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    return None
            except Exception as e:
                logger.warning(f"ì»¬ë ‰ì…˜ '{collection_name}' ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
                return None
                
        except Exception as e:
            logger.warning(f"ì»¬ë ‰ì…˜ '{collection_name}' ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def initialize_all_vector_dbs(self, metadata_path: str = None, force_rebuild: bool = False) -> Dict[str, Chroma]:
        """
        ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ VectorDBë¥¼ ì¼ê´„ ì´ˆê¸°í™”
        
        Args:
            metadata_path: metadata í´ë” ê²½ë¡œ
            force_rebuild: ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆì–´ë„ ê°•ì œë¡œ ì¬êµ¬ì¶•
            
        Returns:
            Dict[str, Chroma]: ì¹´í…Œê³ ë¦¬ë³„ VectorDB ë”•ì…”ë„ˆë¦¬
        """
        logger.info("ëª¨ë“  VectorDB ì´ˆê¸°í™” ì‹œì‘...")
        
        try:
            # ë¬¸ì„œ ë¡œë“œ ë° ë³€í™˜
            if metadata_path:
                documents = DocumentProcessor.load_and_convert_all_documents(Path(metadata_path))
            else:
                metadata_path = getattr(settings, 'METADATA_PATH', None)
                if not metadata_path:
                    raise ValueError("metadata_pathê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ê³  settings.METADATA_PATHë„ ì—†ìŠµë‹ˆë‹¤.")
                documents = DocumentProcessor.load_and_convert_all_documents(Path(metadata_path))
            
            # ì¹´í…Œê³ ë¦¬ë³„ VectorDB ìƒì„±
            vector_dbs = {}
            
            for category, docs in documents.items():
                if not docs:
                    logger.warning(f"ì¹´í…Œê³ ë¦¬ '{category}'ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆë›°ê¸°.")
                    continue
                
                # ì¹´í…Œê³ ë¦¬ë³„ ì»¬ë ‰ì…˜ëª… ë§¤í•‘
                collection_name = self.COLLECTIONS.get(category, category)
                logger.info(f"ì¹´í…Œê³ ë¦¬ '{category}' â†’ ì»¬ë ‰ì…˜ '{collection_name}' ë§¤í•‘")
                
                # ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸
                if not force_rebuild:
                    existing_db = self.get_vector_db(collection_name)
                    if existing_db:
                        vector_dbs[category] = existing_db
                        logger.info(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ì‚¬ìš©")
                        continue
                
                # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
                if force_rebuild and collection_name in self._collection_cache:
                    del self._collection_cache[collection_name]
                
                vector_db = self.docs_to_chroma_db(docs, collection_name)
                vector_dbs[category] = vector_db
                
                logger.info(f"ì¹´í…Œê³ ë¦¬ '{category}' VectorDB ìƒì„± ì™„ë£Œ - ë¬¸ì„œ ìˆ˜: {len(docs)}")
            
            logger.info(f"ëª¨ë“  VectorDB ì´ˆê¸°í™” ì™„ë£Œ - ì´ {len(vector_dbs)}ê°œ ì¹´í…Œê³ ë¦¬")
            return vector_dbs
            
        except Exception as e:
            logger.error(f"VectorDB ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def search_similar_documents(self, query: str, collection_name: str, k: int = 3, 
                               score_threshold: float = 0.0) -> List[Document]:
        """
        ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            score_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜
            
        Returns:
            List[Document]: ìœ ì‚¬í•œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            vector_db = self.get_vector_db(collection_name)
            if not vector_db:
                logger.error(f"ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰
            results = vector_db.similarity_search(query, k=k)
            
            # ì ìˆ˜ í•„í„°ë§ (í•„ìš”í•œ ê²½ìš°)
            if score_threshold > 0.0:
                scored_results = vector_db.similarity_search_with_score(query, k=k)
                results = [doc for doc, score in scored_results if score >= score_threshold]
            
            logger.info(f"ê²€ìƒ‰ ì™„ë£Œ - ì¿¼ë¦¬: '{query[:30]}...', ê²°ê³¼: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """
        ëª¨ë“  ì»¬ë ‰ì…˜ì˜ í†µê³„ ì •ë³´
        
        Returns:
            Dict[str, Any]: ì»¬ë ‰ì…˜ë³„ í†µê³„
        """
        stats = {}
        
        try:
            for category, collection_name in self.COLLECTIONS.items():
                vector_db = self.get_vector_db(collection_name)
                if vector_db:
                    try:
                        # ì»¬ë ‰ì…˜ì˜ ë¬¸ì„œ ìˆ˜ í™•ì¸
                        collection = vector_db._collection
                        count = collection.count() if hasattr(collection, 'count') else 'Unknown'
                        
                        stats[category] = {
                            'collection_name': collection_name,
                            'document_count': count,
                            'exists': True,
                            'cached': collection_name in self._collection_cache
                        }
                    except Exception as e:
                        stats[category] = {
                            'collection_name': collection_name,
                            'error': str(e),
                            'exists': True,
                            'cached': collection_name in self._collection_cache
                        }
                else:
                    stats[category] = {
                        'collection_name': collection_name,
                        'exists': False,
                        'cached': False
                    }
            
            stats['summary'] = {
                'total_collections': len([s for s in stats.values() if isinstance(s, dict) and s.get('exists', False)]),
                'cached_collections': len(self._collection_cache),
                'vector_db_path': str(self.vector_db_path)
            }
            
        except Exception as e:
            logger.error(f"í†µê³„ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            stats['error'] = str(e)
        
        return stats
    
    def get_collection_as_vectorstore(self, collection_name: str) -> Optional[Chroma]:
        """
        Self-Query Retrieverì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ VectorStore ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            
        Returns:
            Chroma: ChromaDB VectorStore ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ None)
        """
        try:
            vector_db = self.get_vector_db(collection_name)
            if vector_db:
                logger.info(f"VectorStore ë¡œë“œ ì„±ê³µ: {collection_name}")
                return vector_db
            else:
                logger.warning(f"VectorStoreë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {collection_name}")
                return None
        except Exception as e:
            logger.error(f"VectorStore ë¡œë“œ ì‹¤íŒ¨ ({collection_name}): {str(e)}")
            return None
    
    def clear_cache(self):
        """ì»¬ë ‰ì…˜ ìºì‹œ ì´ˆê¸°í™”"""
        self._collection_cache.clear()
        logger.info("VectorDB ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def delete_collection(self, collection_name: str) -> bool:
        """
        ì»¬ë ‰ì…˜ ì‚­ì œ
        
        Args:
            collection_name: ì‚­ì œí•  ì»¬ë ‰ì…˜ ì´ë¦„
            
        Returns:
            bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ìºì‹œì—ì„œ ì œê±°
            if collection_name in self._collection_cache:
                del self._collection_cache[collection_name]
            
            logger.warning(f"ì»¬ë ‰ì…˜ '{collection_name}' ìºì‹œì—ì„œ ì œê±°ë¨.")
            return True
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False


# ì „ì—­ VectorDB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_vector_db_manager = None

def get_vector_db_manager() -> VectorDBManager:
    """
    VectorDB ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        VectorDBManager: VectorDB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
    """
    global _vector_db_manager
    
    if _vector_db_manager is None:
        _vector_db_manager = VectorDBManager()
    
    return _vector_db_manager


# í¸ì˜ í•¨ìˆ˜ë“¤
def initialize_vector_databases(metadata_path: str = None, force_rebuild: bool = False) -> Dict[str, Any]:
    """
    VectorDB ì´ˆê¸°í™” í¸ì˜ í•¨ìˆ˜
    
    Args:
        metadata_path: metadata í´ë” ê²½ë¡œ
        force_rebuild: ê°•ì œ ì¬êµ¬ì¶• ì—¬ë¶€
        
    Returns:
        Dict[str, Any]: ì´ˆê¸°í™” ê²°ê³¼
    """
    manager = get_vector_db_manager()
    
    try:
        vector_dbs = manager.initialize_all_vector_dbs(metadata_path, force_rebuild)
        stats = manager.get_collection_stats()
        
        return {
            'success': True,
            'vector_dbs': list(vector_dbs.keys()),
            'stats': stats,
            'message': f"{len(vector_dbs)}ê°œ VectorDB ì´ˆê¸°í™” ì™„ë£Œ"
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'message': "VectorDB ì´ˆê¸°í™” ì‹¤íŒ¨"
        }


def search_documents(query: str, category: str, k: int = 3) -> List[Document]:
    """
    ë¬¸ì„œ ê²€ìƒ‰ í¸ì˜ í•¨ìˆ˜
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        category: ì¹´í…Œê³ ë¦¬ ('term', 'law', 'car_case', 'precedent')
        k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
        
    Returns:
        List[Document]: ê²€ìƒ‰ ê²°ê³¼
    """
    manager = get_vector_db_manager()
    collection_name = manager.COLLECTIONS.get(category, category)
    return manager.search_similar_documents(query, collection_name, k)


def get_vector_db_stats() -> Dict[str, Any]:
    """
    VectorDB í†µê³„ ì •ë³´ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜
    
    Returns:
        Dict[str, Any]: í†µê³„ ì •ë³´
    """
    manager = get_vector_db_manager()
    return manager.get_collection_stats()
