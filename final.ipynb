{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c34e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_5164\\1998050127.py:171: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()  # ë§¤ ë°°ì¹˜ í›„ ì¦‰ì‹œ ì €ì¥\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "\n",
    "# íŒŒì¼ ë¡œë“œ ë° doc í™”\n",
    "file_paths = {\n",
    "    \"term\": \"./metadata/term.json\",\n",
    "    \"load_traffic_law\": \"./metadata/load_traffic_law.json\",\n",
    "    \"modifier\": \"./metadata/modifier.json\",\n",
    "    \"car_case\": \"./metadata/car_to_car.json\",\n",
    "    \"precedent\": \"./metadata/precedent.json\"\n",
    "}\n",
    "\n",
    "# êµí†µì‚¬ê³  ì¼€ì´ìŠ¤ìš© í•„ë“œ ìƒìˆ˜\n",
    "CASE_ID = \"ì‚¬ê±´ ID\"\n",
    "CASE_TITLE = \"ì‚¬ê±´ ì œëª©\"\n",
    "CASE_SITUATION = \"ì‚¬ê³ ìƒí™©\"\n",
    "BASE_RATIO = \"ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨\"\n",
    "MODIFIERS = \"ì¼€ì´ìŠ¤ë³„ ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì •ì˜ˆì‹œ\"\n",
    "LAW_REFERENCES = \"ê´€ë ¨ ë²•ê·œ\"\n",
    "PRECEDENT = \"ì°¸ê³  íŒë¡€\"\n",
    "REASON = \"ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨ í•´ì„¤\"\n",
    "\n",
    "# JSON ë¡œë“œ í•¨ìˆ˜\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸í˜• JSON ë³€í™˜ (term, modifier, law_meta)\n",
    "def convert_list_to_documents(data_list, doc_type):\n",
    "    return [\n",
    "        Document(page_content=json.dumps(item, ensure_ascii=False), metadata={\"type\": doc_type})\n",
    "        for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_precedent_documents(data_list):\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=f\"{item['court']} {item['case_id']} : {item['content']}\",\n",
    "            metadata={\n",
    "                \"court\": item[\"court\"],\n",
    "                \"case_id\": item[\"case_id\"],\n",
    "            }\n",
    "        ) for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_term_documents(data_list):\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=f\"{item['term']} : {item['desc']}\",\n",
    "            metadata={\n",
    "                \"term\": item[\"term\"]\n",
    "            }\n",
    "        ) for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_car_case_documents(data_list):\n",
    "    documents = []\n",
    "\n",
    "    def safe_value(value):\n",
    "        if isinstance(value, list):\n",
    "            return \", \".join(map(str, value))\n",
    "        elif isinstance(value, dict):\n",
    "            return json.dumps(value, ensure_ascii=False)\n",
    "        elif value is None:\n",
    "            return \"\"  # nullë„ í—ˆìš© ì•ˆ ë˜ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬\n",
    "        else:\n",
    "            return str(value)\n",
    "\n",
    "    for item in data_list:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "\n",
    "        # page_contentëŠ” ì›ë³¸ ì „ì²´ JSON ë¬¸ìì—´\n",
    "        content = json.dumps(item, ensure_ascii=False)\n",
    "\n",
    "        # ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨ í•´ì„¤ì´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ â†’ ë¬¸ìì—´ë¡œ ë³‘í•©\n",
    "        reason = item.get(REASON)\n",
    "        if isinstance(reason, list):\n",
    "            reason = \"\\n\".join(map(str, reason))\n",
    "\n",
    "        metadata = {\n",
    "            \"type\": \"car_case\",\n",
    "            \"id\": safe_value(item.get(CASE_ID)),\n",
    "            \"title\": safe_value(item.get(CASE_TITLE)),\n",
    "            \"situation\": safe_value(item.get(CASE_SITUATION)),\n",
    "            \"base_ratio\": safe_value(item.get(BASE_RATIO)),\n",
    "            \"modifiers\": safe_value(item.get(MODIFIERS)),\n",
    "            \"load_traffic_law\": safe_value(item.get(LAW_REFERENCES)),\n",
    "            \"precedent\": safe_value(item.get(PRECEDENT)),\n",
    "            \"reason\": safe_value(reason)\n",
    "        }\n",
    "\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "# ë„ë¡œêµí†µë²• law JSON â†’ ë¬¸ì„œí™”\n",
    "def convert_law_json_to_documents(data_dict):\n",
    "    documents = []\n",
    "\n",
    "    def normalize(item):\n",
    "        return json.dumps(item, ensure_ascii=False) if isinstance(item, dict) else str(item)\n",
    "\n",
    "    for law_name, content in data_dict.items():\n",
    "        if isinstance(content, dict):\n",
    "            for clause, text in content.items():\n",
    "                lines = [normalize(x) for x in (text if isinstance(text, list) else [text])]\n",
    "                full_text = f\"{law_name} {clause}\\n\" + \"\\n\".join(lines)\n",
    "                documents.append(Document(page_content=full_text, metadata={\"type\": \"load_traffic_law\"}))\n",
    "        else:\n",
    "            lines = [normalize(x) for x in (content if isinstance(content, list) else [content])]\n",
    "            full_text = f\"{law_name}\\n\" + \"\\n\".join(lines)\n",
    "            documents.append(Document(page_content=full_text, metadata={\"type\": \"load_traffic_law\"}))\n",
    "    \n",
    "    return documents\n",
    "    \n",
    "\n",
    "import random\n",
    "json_precedent = load_json(file_paths[\"precedent\"])\n",
    "random_precedent = random.sample(json_precedent, 10)\n",
    "# for precedent in random_precedent:\n",
    "#     print(precedent['court'])\n",
    "#     print(precedent['case_id'])\n",
    "\n",
    "# ë¬¸ì„œí™” ì‹¤í–‰\n",
    "term_docs = convert_term_documents(load_json(file_paths[\"term\"]))\n",
    "modifier_docs = convert_list_to_documents(load_json(file_paths[\"modifier\"]), \"modifier\")\n",
    "precedent_docs = convert_precedent_documents(load_json(file_paths[\"precedent\"]))\n",
    "car_case_docs = convert_car_case_documents(load_json(file_paths[\"car_case\"]))\n",
    "load_traffic_law_docs = convert_law_json_to_documents(load_json(file_paths[\"load_traffic_law\"]))\n",
    "\n",
    "\n",
    "# ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "all_docs = term_docs + modifier_docs + car_case_docs + precedent_docs + load_traffic_law_docs\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma  # persist ì§€ì›\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. ì²­í¬ í¬ê¸° ì¡°ì • (500~1000 ê¶Œì¥)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\\\. )\", \" \", \"\"],\n",
    "    is_separator_regex=True,\n",
    ")\n",
    "\n",
    "# 2. ë¬¸ì„œ ë¶„í• \n",
    "all_splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# 4. Chroma DBì— ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì €ì¥\n",
    "batch_size = 100  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì²­í¬ ìˆ˜\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits[:batch_size],  # ì²« ë°°ì¹˜\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./vectordb\"\n",
    ")\n",
    "\n",
    "# ë‚¨ì€ ì²­í¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€ \n",
    "for i in range(0, len(all_splits), batch_size):\n",
    "    try:\n",
    "        batch = all_splits[i:i+batch_size]\n",
    "        vectorstore.add_documents(batch)\n",
    "        vectorstore.persist()  # ë§¤ ë°°ì¹˜ í›„ ì¦‰ì‹œ ì €ì¥\n",
    "    except Exception as e:\n",
    "        print(f\"ë°°ì¹˜ {i}~{i+batch_size} ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9e2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš— êµí†µì‚¬ê³  AI ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\n",
      "ì‚¬ê³  ìƒí™©ì´ë‚˜ ì•Œê³  ì‹¶ì€ ë²•ë¥ /íŒë¡€ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ğŸ“˜ ê²°ê³¼ ì¶œë ¥:\n",
      "\n",
      "[íŒë¡€ ì„¤ëª… ê²°ê³¼]\n",
      "- ìš©ì–´/ì¡°í•­ ì •ì˜: ë™ì¼í­ êµì°¨ë¡œì™€ ëŒ€ë¡œ/ì†Œë¡œ êµì°¨ë¡œëŠ” ë„ë¡œì˜ í­ì— ë”°ë¼ êµì°¨ë¡œì—ì„œì˜ ê³¼ì‹¤ ì—¬ë¶€ ë° ê°€í•´ìì™€ í”¼í•´ìì˜ êµ¬ë¶„ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. ëŒ€ë¡œì™€ ì†Œë¡œì˜ êµ¬ë¶„ì€ ë„ë¡œì˜ í­ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ë©°, ì´ëŠ” ìƒëŒ€ì ì¸ ê°œë…ì…ë‹ˆë‹¤. ëŒ€ë¡œì™€ ì†Œë¡œì˜ êµ¬ë¶„ì€ ì—„ê²©í•˜ê²Œ ì ìš©ë˜ì–´ì•¼ í•˜ë©°, ì§„í–‰í•œ ë„ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ê³ , ê³„ì¸¡ìœ¼ë¡œ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ìš´ì „ìê°€ ì¼ê²¬ ë¶„ë³„í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- ì¶œì²˜ê°€ ëª…ì‹œëœ ê²½ìš°: íŒë¡€(ëŒ€ë²•ì› 97ë‹¤14187)\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ëŠ¥ ë¶„ë¥˜ ë° ë¼ìš°íŒ… ì²˜ë¦¬ + ì‚¬ê³  ìƒí™© ê¸°ë°˜ ê³¼ì‹¤ë¹„ìœ¨ íŒë‹¨ í¬í•¨\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "# í•¨ìˆ˜ ì •ì˜ (ì‚¬ê³  ìƒí™© ì…ë ¥ì‹œ)\n",
    "def assess_accident_fault(user_input: str, all_docs: list) -> str:\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import re\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from langchain.schema import Document\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import LLMChain\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    # car_case ë¬¸ì„œ í•„í„°ë§ ë° ì‚¬ê³ ìƒí™© ì¶”ì¶œ\n",
    "    case_docs = [doc for doc in all_docs if doc.metadata.get(\"type\") == \"car_case\"]\n",
    "    case_texts = [doc.metadata.get(\"situation\", \"\") for doc in case_docs if doc.metadata.get(\"situation\")]\n",
    "\n",
    "    # ko-sbert ì„ë² ë”©\n",
    "    embed_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "    case_embeddings = embed_model.encode(case_texts)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥\n",
    "    query_embedding = embed_model.encode([user_input])[0]\n",
    "\n",
    "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ë° Top-3 ì¶”ì¶œ\n",
    "    cos_similarities = np.dot(case_embeddings, query_embedding) / (\n",
    "        np.linalg.norm(case_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "    )\n",
    "    top_k_idx = np.argsort(cos_similarities)[-3:][::-1]\n",
    "    top_candidates = [case_docs[i] for i in top_k_idx]\n",
    "\n",
    "    # íŒë¡€ ìš”ì•½ ì¶œë ¥\n",
    "    def summarize(doc, idx):\n",
    "        return f\"{idx+1}. ì‚¬ê±´ ID: {doc.metadata.get('id')}\\nì‚¬ê³ ìƒí™©: {doc.metadata.get('situation')}\"\n",
    "\n",
    "    case_summaries = \"\\n\\n\".join([summarize(doc, i) for i, doc in enumerate(top_candidates)])\n",
    "\n",
    "    # GPT - ì‚¬ê±´ID ì„ íƒ(3ê°œ ì¤‘ì— í•˜ë‚˜ íŒë‹¨)\n",
    "    selection_prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"case_summaries\"],\n",
    "        template=\"\"\"\n",
    "    [ì‚¬ìš©ì ì…ë ¥ ì‚¬ê³  ìƒí™©]\n",
    "    {user_input}\n",
    "\n",
    "    [í›„ë³´ íŒë¡€ 3ê±´]\n",
    "    {case_summaries}\n",
    "\n",
    "    ìœ„ 3ê±´ ì¤‘, ì‚¬ê³ ì˜ ì „ê°œ êµ¬ì¡°(ì˜ˆ: ì§ì§„ vs ì¢ŒíšŒì „, ë„ë¡œ ì™¸ ì¥ì†Œì—ì„œ ì§„ì…, êµì°¨ë¡œ ë‚´ ì§„ì… ì—¬ë¶€ ë“±)ê°€ ì‚¬ìš©ì ìƒí™©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ **ì‚¬ê±´ ID** í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "    ë°˜ë“œì‹œ ë‹¤ìŒ ê¸°ì¤€ì„ ê³ ë ¤í•˜ì„¸ìš”:\n",
    "    - ì°¨ëŸ‰ë“¤ì˜ ìœ„ì¹˜ì™€ ì§„ì… ê²½ë¡œê°€ ìœ ì‚¬í•œê°€?\n",
    "    - ì‚¬ê³  ë°œìƒ ì§€ì ê³¼ ë°©í–¥ì´ ìœ ì‚¬í•œê°€?\n",
    "    - ê° ì°¨ëŸ‰ì˜ ì‹ í˜¸Â·ìš°ì„ ê¶Œ ìƒí™©ì´ ìœ ì‚¬í•œê°€?|\n",
    "    - ë„ë¡œ êµ¬ì¡°(êµì°¨ë¡œ, ì‹ í˜¸ ìœ ë¬´, ë„ë¡œ ì™¸ ì¥ì†Œ ë“±)ê°€ ìœ ì‚¬í•œê°€?\n",
    "\n",
    "    ì¶œë ¥ í˜•ì‹ (ê³ ì •):\n",
    "    - ì‚¬ê±´ ID: ì°¨XX-X\n",
    "    - íŒë‹¨ ê·¼ê±°: (ì„ íƒí•œ ì´ìœ . ë‹¨ìˆœ ìœ ì‚¬ì„±ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ì§€ì ì´ ìœ ì‚¬í–ˆëŠ”ì§€ ëª…í™•íˆ ì„¤ëª…í•  ê²ƒ)\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    selection_chain = LLMChain(llm=llm, prompt=selection_prompt)\n",
    "    selection_result = selection_chain.run(user_input=user_input, case_summaries=case_summaries)\n",
    "\n",
    "    # ì‚¬ê±´ ID íŒŒì‹± ë° ì„ íƒ\n",
    "    match = re.search(r\"ì‚¬ê±´ ID[:ï¼š]?\\s*(ì°¨\\d{1,2}-\\d{1,2})\", selection_result)\n",
    "    selected_id = match.group(1) if match else None\n",
    "    selected_doc = next((doc for doc in case_docs if doc.metadata.get(\"id\") == selected_id), None)\n",
    "\n",
    "    # ìµœì¢… íŒë‹¨ GPT í”„ë¡¬í”„íŠ¸(ì„ íƒí•œ ì‚¬ê±´ object ë‚´ì—ì„œ ê³¼ì‹¤ë¹„ìœ¨ íŒë‹¨)\n",
    "    if selected_doc:\n",
    "        # í•´ë‹¹ ì‚¬ê±´ ê´€ë ¨ ë³´ì¡° ë¬¸ì„œë“¤ì„ í•¨ê»˜ ì „ë‹¬\n",
    "        related_docs = [doc for doc in all_docs if selected_id in doc.page_content]\n",
    "        context_str = \"\\n\\n\".join(doc.page_content for doc in related_docs)\n",
    "\n",
    "        final_prompt = PromptTemplate(\n",
    "            input_variables=[\"user_input\", \"case_data\"],\n",
    "            template=\"\"\"\n",
    "    ë„ˆëŠ” êµí†µì‚¬ê³  ê³¼ì‹¤ íŒë‹¨ ì „ë¬¸ê°€ì•¼.\n",
    "    ì•„ë˜ 'ì‚¬ê³  ìƒí™©'ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ìš”ì†Œë¥¼ êµ¬ì¡°í™”í•˜ê³ , ë°˜ë“œì‹œ ë¬¸ì„œ ë‚´ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ë¡€(case)ë¥¼ ì°¾ì•„ ê³¼ì‹¤ë¹„ìœ¨ì„ íŒë‹¨í•´ì¤˜.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ì‚¬ê³  ìƒí™© ì›ë¬¸:\n",
    "    {user_input}\n",
    "\n",
    "    â¤ ì‚¬ê³  ìƒí™© ìš”ì•½ (ë‹¤ìŒ í•­ëª© ê¸°ì¤€):\n",
    "    - Aì°¨ëŸ‰ ì‹ í˜¸ ë° ì§„í–‰ ë°©ì‹:\n",
    "    - Bì°¨ëŸ‰ ì‹ í˜¸ ë° ì§„í–‰ ë°©ì‹:\n",
    "    - ì¶©ëŒ ë°©ì‹ ë° ìœ„ì¹˜:\n",
    "    - êµì°¨ë¡œ/ì‹ í˜¸ê¸° ìœ ë¬´ ë“± ë„ë¡œ í™˜ê²½:\n",
    "\n",
    "    ë¬¸ì„œ:\n",
    "    {case_data}\n",
    "\n",
    "    ì¶œë ¥ í˜•ì‹ (ê³ ì •):\n",
    "    1. ê³¼ì‹¤ë¹„ìœ¨: Aì°¨ëŸ‰ xx% vs Bì°¨ëŸ‰ xx%\n",
    "    2. íŒë‹¨ ê·¼ê±° ìš”ì•½\n",
    "    3. ì ìš© ë²•ë¥ :\n",
    "    - [ë²•ë¥ ëª…] ì œ[ì¡°]ì¡° [í•­]\n",
    "    4. ì°¸ê³  íŒë¡€:\n",
    "    - [ë²•ì›ëª…] [ì‚¬ê±´ë²ˆí˜¸]\n",
    "\n",
    "    ì¡°ê±´:\n",
    "    - ë°˜ë“œì‹œ ë¬¸ì„œ ë‚´ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•´.\n",
    "    - ìœ ì‚¬ ì‚¬ë¡€ì™€ í˜„ì¬ ì‚¬ê³  ìƒí™©ì´ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´, ì°¨ì´ì ì„ ëª…ì‹œí•˜ê³  ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ì´ìœ ë¥¼ ì„¤ëª…í•´.\n",
    "    - ì¶”ì¸¡ì´ë‚˜ ìƒì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ë¬¸ì„œ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨í•´.\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "        final_chain = LLMChain(llm=llm, prompt=final_prompt)\n",
    "        final_result = final_chain.run(user_input=user_input, case_data=context_str)\n",
    "\n",
    "        print(f\"\\nì„ íƒëœ ì‚¬ê±´ ID: {selected_id}\")\n",
    "        print(\"GPT ìµœì¢… íŒë‹¨ ê²°ê³¼:\\n\")\n",
    "        print(final_result)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nâŒ ì‚¬ê±´ IDë¥¼ ì •í™•íˆ ì„ íƒí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"GPT ì‘ë‹µ:\\n\", selection_result)\n",
    "\n",
    "# í•¨ìˆ˜ ì •ì˜ (ìš©ì–´/íŒë¡€ ì…ë ¥ì‹œ)\n",
    "def precedent_result(user_input):\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain.chains.query_constructor.base import AttributeInfo\n",
    "    from langchain.retrievers import SelfQueryRetriever\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)    \n",
    "\n",
    "    # ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ì˜ (í•„ìˆ˜!)\n",
    "    metadata_field_info = [\n",
    "        AttributeInfo(\n",
    "            name=\"court\",\n",
    "            description=\"íŒë¡€ì˜ ë²•ì›ëª… (ì˜ˆ: ëŒ€ë²•ì›, ì„œìš¸ê³ ë“±ë²•ì› ë“±)\",\n",
    "            type=\"string\"\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"case_id\",\n",
    "            description=\"ì‚¬ê±´ë²ˆí˜¸ (ì˜ˆ: 92ë„2077)\",\n",
    "            type=\"string\"\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"term\",\n",
    "            description=\"ìš©ì–´\",\n",
    "            type=\"string\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # SelfQueryRetriever ìƒì„± (metadata_field_info í•„ìˆ˜)\n",
    "    self_retriever = SelfQueryRetriever.from_llm(\n",
    "        llm=llm,\n",
    "        vectorstore=vectorstore,\n",
    "        document_contents=\"êµí†µì‚¬ê³  íŒë¡€ ë°ì´í„°\",\n",
    "        metadata_field_info=metadata_field_info  # âœ… ë°˜ë“œì‹œ í•„ìš”\n",
    "    )\n",
    "\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"context\"],\n",
    "        template=\"\"\"ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ìš©ì–´ë‚˜ ë²•ë¥  ì¡°í•­, íŒë¡€ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n",
    "        \n",
    "        ì§ˆë¬¸: {question}\n",
    "        \n",
    "        ë¬¸ì„œ: {context}\n",
    "\n",
    "        ë‹µë³€ í˜•ì‹:\n",
    "        - ìš©ì–´/ì¡°í•­ ì •ì˜: [ì •í™•í•œ ì„¤ëª…]\n",
    "        - ì¶œì²˜ê°€ ëª…ì‹œëœ ê²½ìš°: ê´€ë ¨ ë²•ë¥ /ì¡°ë¬¸ ë²ˆí˜¸/íŒë¡€ëª…ì„ ë°˜ë“œì‹œ í¬í•¨\n",
    "\n",
    "        ë‹µë³€:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # QA ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=self_retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": user_input})\n",
    "    return f\"[íŒë¡€ ì„¤ëª… ê²°ê³¼]\\n{result['result']}\" \n",
    "\n",
    "routing_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ë„ˆëŠ” êµí†µì‚¬ê³  ì „ë¬¸ AI ë¹„ì„œì•¼.\n",
    "\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì½ê³ , ì•„ë˜ ì¤‘ ì–´ë–¤ ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ì•¼ í• ì§€ í•˜ë‚˜ë§Œ ê³¨ë¼ì¤˜:\n",
    "- ì‚¬ê³ ìƒí™© ê³¼ì‹¤ë¹„ìœ¨ íŒë‹¨: \"function_1\"\n",
    "- íŒë¡€ì— ëŒ€í•œ ì„¤ëª… ë°ìš©ì–´ ì„¤ëª…: \"function_2\"\n",
    "\n",
    "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ëŒ€ë‹µí•´:\n",
    "[ì„ íƒëœ í•¨ìˆ˜]: function_X\n",
    "[ì„ íƒ ì´ìœ ]: (ê°„ë‹¨í•œ ì´ìœ  ì„¤ëª…)\n",
    "\n",
    "ì§ˆë¬¸: {user_input}\n",
    "\"\"\")\n",
    "\n",
    "# ë¼ìš°íŒ… í•¨ìˆ˜\n",
    "def route_and_respond(user_input: str, all_docs: list) -> str:\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "    routing_chain = LLMChain(llm=llm, prompt=routing_prompt)\n",
    "    result = routing_chain.run(user_input=user_input)\n",
    "\n",
    "    match = re.search(r\"function_\\d\", result)\n",
    "    if match:\n",
    "        chosen = match.group()\n",
    "        if chosen == \"function_1\":\n",
    "            return assess_accident_fault(user_input, all_docs)\n",
    "        elif chosen == \"function_2\":\n",
    "            return precedent_result(user_input)\n",
    "    else:\n",
    "        return f\"âŒ ê¸°ëŠ¥ ë¶„ë¥˜ ì‹¤íŒ¨.\\nGPT ì‘ë‹µ: {result}\"\n",
    "    \n",
    "\n",
    "# í”„ë¡œê·¸ë¨ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš— êµí†µì‚¬ê³  AI ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\")\n",
    "    print(\"ì‚¬ê³  ìƒí™©ì´ë‚˜ ì•Œê³  ì‹¶ì€ ë²•ë¥ /íŒë¡€ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.\")\n",
    "    user_input = input(\"ì…ë ¥ > \").strip()\n",
    "\n",
    "    if user_input:\n",
    "        result = route_and_respond(user_input, all_docs)\n",
    "        print(\"\\nğŸ“˜ ê²°ê³¼ ì¶œë ¥:\\n\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(\"âŒ ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d396e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4d210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "pystudy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
