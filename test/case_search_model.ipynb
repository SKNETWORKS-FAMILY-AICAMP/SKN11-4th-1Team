{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "# 파일 경로 \n",
    "file_paths = {\n",
    "    \"term\": \"./metadata/term.json\",\n",
    "    \"law\": \"./metadata/load_traffic_law.json\",\n",
    "    \"modifier\": \"./metadata/modiflier.json\",\n",
    "    \"car_case\": \"./metadata/car_to_car.json\",\n",
    "    \"law_meta\": \"./metadata/law.json\"\n",
    "}\n",
    "\n",
    "# 교통사고 케이스용 필드 상수\n",
    "CASE_ID = \"사건 ID\"\n",
    "CASE_TITLE = \"사건 제목\"\n",
    "CASE_SITUATION = \"사고상황\"\n",
    "BASE_RATIO = \"기본 과실비율\"\n",
    "MODIFIERS = \"케이스별 과실비율 조정예시\"\n",
    "LAW_REFERENCES = \"관련 법규\"\n",
    "LEGAL_NOTES = \"참고 판례\"\n",
    "REASON = \"기본 과실비율 해설\"\n",
    "\n",
    "# JSON 로드 함수\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 리스트형 JSON 변환 (term, modifier, law_meta)\n",
    "def convert_list_to_documents(data_list, doc_type):\n",
    "    return [\n",
    "        Document(page_content=json.dumps(item, ensure_ascii=False), metadata={\"type\": doc_type})\n",
    "        for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_car_case_documents(data_list):\n",
    "    documents = []\n",
    "\n",
    "    def safe_value(value):\n",
    "        if isinstance(value, list):\n",
    "            return \", \".join(map(str, value))\n",
    "        elif isinstance(value, dict):\n",
    "            return json.dumps(value, ensure_ascii=False)\n",
    "        elif value is None:\n",
    "            return \"\"  # null도 허용 안 되므로 빈 문자열로 처리\n",
    "        else:\n",
    "            return str(value)\n",
    "\n",
    "    for item in data_list:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "\n",
    "        # page_content는 원본 전체 JSON 문자열\n",
    "        content = json.dumps(item, ensure_ascii=False)\n",
    "\n",
    "        # 기본 과실비율 해설이 리스트일 수 있음 → 문자열로 병합\n",
    "        reason = item.get(REASON)\n",
    "        if isinstance(reason, list):\n",
    "            reason = \"\\n\".join(map(str, reason))\n",
    "\n",
    "        metadata = {\n",
    "            \"type\": \"car_case\",\n",
    "            \"id\": safe_value(item.get(CASE_ID)),\n",
    "            \"title\": safe_value(item.get(CASE_TITLE)),\n",
    "            \"situation\": safe_value(item.get(CASE_SITUATION)),\n",
    "            \"base_ratio\": safe_value(item.get(BASE_RATIO)),\n",
    "            \"modifiers\": safe_value(item.get(MODIFIERS)),\n",
    "            \"law\": safe_value(item.get(LAW_REFERENCES)),\n",
    "            \"legal_notes\": safe_value(item.get(LEGAL_NOTES)),\n",
    "            \"reason\": safe_value(reason)\n",
    "        }\n",
    "\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "# 도로교통법 law JSON → 문서화\n",
    "def convert_law_json_to_documents(data_dict):\n",
    "    documents = []\n",
    "\n",
    "    def normalize(item):\n",
    "        return json.dumps(item, ensure_ascii=False) if isinstance(item, dict) else str(item)\n",
    "\n",
    "    for law_name, content in data_dict.items():\n",
    "        if isinstance(content, dict):\n",
    "            for clause, text in content.items():\n",
    "                lines = [normalize(x) for x in (text if isinstance(text, list) else [text])]\n",
    "                full_text = f\"{law_name} {clause}\\n\" + \"\\n\".join(lines)\n",
    "                documents.append(Document(page_content=full_text, metadata={\"type\": \"law\"}))\n",
    "        else:\n",
    "            lines = [normalize(x) for x in (content if isinstance(content, list) else [content])]\n",
    "            full_text = f\"{law_name}\\n\" + \"\\n\".join(lines)\n",
    "            documents.append(Document(page_content=full_text, metadata={\"type\": \"law\"}))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "# 문서화 실행\n",
    "term_docs       = convert_list_to_documents(load_json(file_paths[\"term\"]), \"term\")\n",
    "modifier_docs   = convert_list_to_documents(load_json(file_paths[\"modifier\"]), \"modifier\")\n",
    "law_meta_docs   = convert_list_to_documents(load_json(file_paths[\"law_meta\"]), \"law_metadata\")\n",
    "car_case_docs   = convert_car_case_documents(load_json(file_paths[\"car_case\"]))\n",
    "law_docs        = convert_law_json_to_documents(load_json(file_paths[\"law\"]))\n",
    "\n",
    "\n",
    "# 전체 문서 리스트\n",
    "all_docs = term_docs + modifier_docs + car_case_docs + law_meta_docs + law_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffceef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# car_case 문서 필터링 및 사고상황 추출\n",
    "case_docs = [doc for doc in all_docs if doc.metadata.get(\"type\") == \"car_case\"]\n",
    "case_texts = [doc.metadata.get(\"situation\", \"\") for doc in case_docs if doc.metadata.get(\"situation\")]\n",
    "\n",
    "# ko-sbert 임베딩\n",
    "embed_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "case_embeddings = embed_model.encode(case_texts)\n",
    "\n",
    "# 사용자 입력\n",
    "user_input = input(\"사고 상황을 입력하세요: \")\n",
    "query_embedding = embed_model.encode([user_input])[0]\n",
    "\n",
    "# 코사인 유사도 계산 및 Top-3 추출\n",
    "cos_similarities = np.dot(case_embeddings, query_embedding) / (\n",
    "    np.linalg.norm(case_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    ")\n",
    "top_k_idx = np.argsort(cos_similarities)[-3:][::-1]\n",
    "top_candidates = [case_docs[i] for i in top_k_idx]\n",
    "\n",
    "# 판례 요약 출력\n",
    "def summarize(doc, idx):\n",
    "    return f\"{idx+1}. 사건 ID: {doc.metadata.get('id')}\\n사고상황: {doc.metadata.get('situation')}\"\n",
    "\n",
    "case_summaries = \"\\n\\n\".join([summarize(doc, i) for i, doc in enumerate(top_candidates)])\n",
    "\n",
    "# GPT - 사건ID 선택(3개 중에 하나 판단)\n",
    "selection_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\", \"case_summaries\"],\n",
    "    template=\"\"\"\n",
    "[사용자 입력 사고 상황]\n",
    "{user_input}\n",
    "\n",
    "[후보 판례 3건]\n",
    "{case_summaries}\n",
    "\n",
    "위 3건 중, 사고의 전개 구조(예: 직진 vs 좌회전, 도로 외 장소에서 진입, 교차로 내 진입 여부 등)가 사용자 상황과 가장 유사한 **사건 ID** 하나를 선택하세요.\n",
    "\n",
    "반드시 다음 기준을 고려하세요:\n",
    "- 차량들의 위치와 진입 경로가 유사한가?\n",
    "- 사고 발생 지점과 방향이 유사한가?\n",
    "- 각 차량의 신호·우선권 상황이 유사한가?|\n",
    "- 도로 구조(교차로, 신호 유무, 도로 외 장소 등)가 유사한가?\n",
    "\n",
    "출력 형식 (고정):\n",
    "- 사건 ID: 차XX-X\n",
    "- 판단 근거: (선택한 이유. 단순 유사성이 아니라, 어떤 지점이 유사했는지 명확히 설명할 것)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "selection_chain = LLMChain(llm=llm, prompt=selection_prompt)\n",
    "selection_result = selection_chain.run(user_input=user_input, case_summaries=case_summaries)\n",
    "\n",
    "# 사건 ID 파싱 및 선택\n",
    "match = re.search(r\"사건 ID[:：]?\\s*(차\\d{1,2}-\\d{1,2})\", selection_result)\n",
    "selected_id = match.group(1) if match else None\n",
    "selected_doc = next((doc for doc in case_docs if doc.metadata.get(\"id\") == selected_id), None)\n",
    "\n",
    "# 최종 판단 GPT 프롬프트(선택한 사건 object 내에서 과실비율 판단)\n",
    "if selected_doc:\n",
    "    # 해당 사건 관련 보조 문서들을 함께 전달\n",
    "    related_docs = [doc for doc in all_docs if selected_id in doc.page_content]\n",
    "    context_str = \"\\n\\n\".join(doc.page_content for doc in related_docs)\n",
    "\n",
    "    final_prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"case_data\"],\n",
    "        template=\"\"\"\n",
    "너는 교통사고 과실 판단 전문가야.\n",
    "아래 '사고 상황'을 분석하여 핵심 요소를 구조화하고, 반드시 문서 내에서 가장 유사한 사례(case)를 찾아 과실비율을 판단해줘.\n",
    "\n",
    "---\n",
    "\n",
    "사고 상황 원문:\n",
    "{user_input}\n",
    "\n",
    "➤ 사고 상황 요약 (다음 항목 기준):\n",
    "- A차량 신호 및 진행 방식:\n",
    "- B차량 신호 및 진행 방식:\n",
    "- 충돌 방식 및 위치:\n",
    "- 교차로/신호기 유무 등 도로 환경:\n",
    "\n",
    "문서:\n",
    "{case_data}\n",
    "\n",
    "출력 형식 (고정):\n",
    "1. 과실비율: A차량 xx% vs B차량 xx%\n",
    "2. 판단 근거 요약\n",
    "3. 적용 법률:\n",
    "   - [법률명] 제[조]조 [항]\n",
    "4. 참고 판례:\n",
    "   - [법원명] [사건번호]\n",
    "\n",
    "조건:\n",
    "- 반드시 문서 내 유사 사례를 기반으로 판단해야 해.\n",
    "- 유사 사례와 현재 사고 상황이 정확히 일치하지 않으면, 차이점을 명시하고 과실비율 조정 이유를 설명해.\n",
    "- 추측이나 상식은 사용하지 말고, 문서 정보만을 기반으로 판단해.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    final_chain = LLMChain(llm=llm, prompt=final_prompt)\n",
    "    final_result = final_chain.run(user_input=user_input, case_data=context_str)\n",
    "\n",
    "    print(f\"\\n선택된 사건 ID: {selected_id}\")\n",
    "    print(\"GPT 최종 판단 결과:\\n\")\n",
    "    print(final_result)\n",
    "\n",
    "else:\n",
    "    print(\"\\n❌ 사건 ID를 정확히 선택하지 못했습니다.\")\n",
    "    print(\"GPT 응답:\\n\", selection_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7447533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# # 1. all_docs를 기반으로 벡터스토어 생성 (한 번만 수행하면 됨)\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-nli\")\n",
    "# vectorstore = Chroma.from_documents(documents=all_docs, embedding=embedding_model)\n",
    "\n",
    "# # 2. Retriever 생성\n",
    "# retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# # 3. 프롬프트 정의\n",
    "# detail_prompt = PromptTemplate(\n",
    "#     template=\"\"\"\n",
    "# 아래 문서 내용을 바탕으로 사용자가 물어본 용어나 법률 조항, 판례에 대해 정확하고 간결하게 설명해 주세요.\n",
    "\n",
    "# 질문: {question}\n",
    "\n",
    "# 문서: {context}\n",
    "\n",
    "# 답변 형식:\n",
    "# - 용어/조항 정의: [정확한 설명]\n",
    "# - 출처가 명시된 경우: 관련 법률/조문 번호/판례명을 반드시 포함\n",
    "\n",
    "# 답변:\n",
    "# \"\"\",\n",
    "#     input_variables=[\"question\", \"context\"]\n",
    "# )\n",
    "\n",
    "# # 4. Retrieval QA 체인 구성\n",
    "# detail_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,  \n",
    "#     retriever=retriever,\n",
    "#     chain_type=\"stuff\",\n",
    "#     chain_type_kwargs={\"prompt\": detail_prompt}\n",
    "# )\n",
    "\n",
    "# # 5. 질문 실행\n",
    "# question = \"보행자우선도로가 뭔지 설명해줘\"\n",
    "# res2 = detail_chain.run(question)\n",
    "\n",
    "# print(\"기능② 답변:\\n\", res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"판례 서울중앙지방법원 2020나59927에 대해 설명해줘\"\n",
    "# res2 = detail_chain.run(question)\n",
    "\n",
    "# print(\"기능② 답변:\\n\", res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22338b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
