{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ebb58f",
   "metadata": {},
   "source": [
    "# Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌååÏùº Í≤ΩÎ°ú\n",
    "FILE_PATH = {\n",
    "    'TERM' : '../metadata/term.json',                            # Ïö©Ïñ¥\n",
    "    'LOAD_TRAFFIC_LAW' : '../metadata/load_traffic_law.json',    # ÎèÑÎ°úÍµêÌÜµÎ≤ï\n",
    "    'MODIFIER' : '../metadata/modifier.json',                    # ÏàòÏ†ïÏöîÏÜå\n",
    "    'CAR_CASE' : '../metadata/car_to_car.json',                  # Ï∞® sÏ∞® ÏÇ¨Í≥† ÏºÄÏù¥Ïä§\n",
    "    'PRECEDENT' : '../metadata/precedent.json',                  # Ï∞∏Í≥† ÌåêÎ°Ä\n",
    "\n",
    "    'VECTOR_DB' : '../vector_db',                                # Î≤°ÌÑ∞ DB Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "}\n",
    "\n",
    "# Î≤°ÌÑ∞DB Ïª¨Î†âÏÖò Ïù¥Î¶Ñ Ï†ïÏùò\n",
    "VECTOR_DB_COLLECTION = {\n",
    "    'TERM' : \"term\",\n",
    "    'LOAD_TRAFFIC_LAW' : \"load_traffic_law\",\n",
    "    'MODIFIER' : \"modifier\",\n",
    "    'CAR_CASE' : \"car_case\",\n",
    "    'PRECEDENT' : \"precedent\",\n",
    "}\n",
    "\n",
    "# JSON ÌååÏùº KEY Í∞í Ï†ïÏùò\n",
    "METADATA_KEY = {\n",
    "    'ACCIDENT_CASE' : {\n",
    "        'CASE_ID' : \"ÏÇ¨Í±¥ ID\",\n",
    "        'CASE_TITLE' : \"ÏÇ¨Í±¥ Ï†úÎ™©\",\n",
    "        'CASE_SITUATION' : \"ÏÇ¨Í≥†ÏÉÅÌô©\",\n",
    "        'BASE_RATIO' : \"Í∏∞Î≥∏ Í≥ºÏã§ÎπÑÏú®\",\n",
    "        'MODIFIERS' : \"ÏºÄÏù¥Ïä§Î≥Ñ Í≥ºÏã§ÎπÑÏú® Ï°∞Ï†ïÏòàÏãú\",\n",
    "        'LAW_REFERENCES' : \"Í¥ÄÎ†® Î≤ïÍ∑ú\",\n",
    "        'PRECEDENT' : \"Ï∞∏Í≥† ÌåêÎ°Ä\",\n",
    "        'REASON' : \"Í∏∞Î≥∏ Í≥ºÏã§ÎπÑÏú® Ìï¥ÏÑ§\",\n",
    "    },\n",
    "\n",
    "    'PRECEDENT' : {\n",
    "        'COURT' : \"court\",\n",
    "        'CASE_ID' : \"case_id\",\n",
    "        'CONTENT' : \"content\",\n",
    "    },\n",
    "\n",
    "    'TERM' : {\n",
    "        'TERM' : \"term\",\n",
    "        'DESC' : \"desc\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233e862",
   "metadata": {},
   "source": [
    "# 1. Documentation (Î¨∏ÏÑúÌôî)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb5bfa",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0afcb",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c34e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Î°úÎìú Ìï®Ïàò\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Î¶¨Ïä§Ìä∏Ìòï JSON -> Document Î≥ÄÌôò (modifier)\n",
    "def convert_list_to_documents(data_list, doc_type):\n",
    "    return [\n",
    "        Document(page_content=json.dumps(item, ensure_ascii=False), metadata={\"type\": doc_type})\n",
    "        for item in data_list\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "# precedent JSON -> Document Î≥ÄÌôò\n",
    "def convert_precedent_to_docs(data_list):\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=f\"{item[METADATA_KEY['PRECEDENT']['COURT']]} {item[METADATA_KEY['PRECEDENT']['CASE_ID']]} : {item[METADATA_KEY['PRECEDENT']['CONTENT']]}\",\n",
    "            metadata={\n",
    "                METADATA_KEY['PRECEDENT']['COURT']: item[METADATA_KEY['PRECEDENT']['COURT']],\n",
    "                METADATA_KEY['PRECEDENT']['CASE_ID']: item[METADATA_KEY['PRECEDENT']['CASE_ID']],\n",
    "            }\n",
    "        ) for item in data_list\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "# term JSON -> Document Î≥ÄÌôò\n",
    "def convert_term_to_docs(data_list):\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=f\"{item[METADATA_KEY['TERM']['TERM']]} : {item[METADATA_KEY['TERM']['DESC']]}\",\n",
    "            metadata={\n",
    "                METADATA_KEY['TERM']['TERM']: item[METADATA_KEY['TERM']['TERM']]\n",
    "            }\n",
    "        ) for item in data_list\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "# car_case JSON -> Document Î≥ÄÌôò\n",
    "def convert_car_case_to_docs(data_list):\n",
    "    documents = []\n",
    "\n",
    "    def safe_value(value):\n",
    "        if isinstance(value, list):\n",
    "            return \", \".join(map(str, value))\n",
    "        elif isinstance(value, dict):\n",
    "            return json.dumps(value, ensure_ascii=False)\n",
    "        elif value is None:\n",
    "            return \"\"  # nullÎèÑ ÌóàÏö© Ïïà ÎêòÎØÄÎ°ú Îπà Î¨∏ÏûêÏó¥Î°ú Ï≤òÎ¶¨\n",
    "        else:\n",
    "            return str(value)\n",
    "\n",
    "    for item in data_list:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "\n",
    "        # page_contentÎäî ÏõêÎ≥∏ Ï†ÑÏ≤¥ JSON Î¨∏ÏûêÏó¥\n",
    "        content = json.dumps(item, ensure_ascii=False)\n",
    "\n",
    "        # Í∏∞Î≥∏ Í≥ºÏã§ÎπÑÏú® Ìï¥ÏÑ§Ïù¥ Î¶¨Ïä§Ìä∏Ïùº Ïàò ÏûàÏùå ‚Üí Î¨∏ÏûêÏó¥Î°ú Î≥ëÌï©\n",
    "        reason = item.get(METADATA_KEY['ACCIDENT_CASE']['REASON'])\n",
    "        if isinstance(reason, list):\n",
    "            reason = \"\\n\".join(map(str, reason))\n",
    "\n",
    "        metadata = {\n",
    "            \"type\": \"car_case\",\n",
    "            \"id\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['CASE_ID'])),\n",
    "            \"title\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['CASE_TITLE'])),\n",
    "            \"situation\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['CASE_SITUATION'])),\n",
    "            \"base_ratio\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['BASE_RATIO'])),\n",
    "            \"modifiers\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['MODIFIERS'])),\n",
    "            \"load_traffic_law\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['LAW_REFERENCES'])),\n",
    "            \"precedent\": safe_value(item.get(METADATA_KEY['ACCIDENT_CASE']['PRECEDENT'])),\n",
    "            \"reason\": safe_value(reason)\n",
    "        }\n",
    "\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# ÎèÑÎ°úÍµêÌÜµÎ≤ï law JSON ‚Üí Î¨∏ÏÑúÌôî\n",
    "def convert_traffic_law_to_docs(data_dict):\n",
    "    documents = []\n",
    "\n",
    "    # def normalize(item):\n",
    "    #     return json.dumps(item, ensure_ascii=False) if isinstance(item, dict) else str(item)\n",
    "\n",
    "    # for law_name, content in data_dict.items():\n",
    "    #     if isinstance(content, dict):\n",
    "    #         for clause, text in content.items():\n",
    "    #             lines = [normalize(x) for x in (text if isinstance(text, list) else [text])]\n",
    "    #             full_text = f\"{law_name} {clause}\\n\" + \"\\n\".join(lines)\n",
    "    #             documents.append(Document(page_content=full_text, metadata={\"type\": \"load_traffic_law\"}))\n",
    "    #     else:\n",
    "    #         lines = [normalize(x) for x in (content if isinstance(content, list) else [content])]\n",
    "    #         full_text = f\"{law_name}\\n\" + \"\\n\".join(lines)\n",
    "    #         documents.append(Document(page_content=full_text, metadata={\"type\": \"load_traffic_law\"}))\n",
    "    \n",
    "    # return documents\n",
    "    for article_title, article_content in data_dict.items():\n",
    "        main_clause = article_title.split(\"(\")[0].strip()\n",
    "        clause_name = article_title.split(\"(\")[1].replace(\")\", \"\").strip()\n",
    "        for sub_clause, texts in article_content.items():\n",
    "            clause_num = int(sub_clause.replace(\"Ìï≠\", \"\"))\n",
    "            content = \" \".join(texts)\n",
    "            metadata = {\n",
    "                \"Î≤ïÎ•†Ï°∞Î¨∏\": main_clause,\n",
    "                \"Ï°∞Ìï≠Î™Ö\": clause_name,\n",
    "                \"Ìï≠Î≤àÌò∏\": clause_num,\n",
    "                \"Ï†ÑÏ≤¥Ï∞∏Ï°∞\": f\"{main_clause} {sub_clause}\"\n",
    "            }\n",
    "            documents.append(Document(page_content=content, metadata=metadata))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ï†ÑÏ≤¥ JSON Î¨∏ÏÑúÌôî\n",
    "# def convert_all_docs():\n",
    "#     term_docs = convert_term_to_docs(load_json(FILE_PATH['TERM']))\n",
    "#     modifier_docs = convert_list_to_documents(load_json(FILE_PATH['MODIFIER']), 'modifier')\n",
    "#     precedent_docs = convert_precedent_to_docs(load_json(FILE_PATH['PRECEDENT']))\n",
    "#     car_case_docs = convert_car_case_to_docs(load_json(FILE_PATH['CAR_CASE']))\n",
    "#     load_traffic_law_docs = convert_load_traffic_law_to_docs(load_json(FILE_PATH['LOAD_TRAFFIC_LAW']))\n",
    "\n",
    "#     return term_docs + modifier_docs + precedent_docs + car_case_docs + load_traffic_law_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13a296",
   "metadata": {},
   "source": [
    "### Make Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÏ≤¥ Î¨∏ÏÑúÌôî\n",
    "# all_docs = convert_all_docs()\n",
    "\n",
    "term_docs = convert_term_to_docs(load_json(FILE_PATH['TERM']))\n",
    "precedent_docs = convert_precedent_to_docs(load_json(FILE_PATH['PRECEDENT']))\n",
    "load_traffic_law_docs = convert_traffic_law_to_docs(load_json(FILE_PATH['LOAD_TRAFFIC_LAW']))\n",
    "\n",
    "car_case_docs = convert_car_case_to_docs(load_json(FILE_PATH['CAR_CASE']))\n",
    "modifier_docs = convert_list_to_documents(load_json(FILE_PATH['MODIFIER']), 'modifier')\n",
    "accident_docs = car_case_docs + modifier_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba73fd30",
   "metadata": {},
   "source": [
    "# 2. Vector DB Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1447ba80",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc6bc8",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏûÑÎ≤†Îî© Î™®Îç∏\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5e2f8",
   "metadata": {},
   "source": [
    "### Í∞Å Î¨∏ÏÑúÎ≥Ñ Collection ÎÇòÎà† Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2052d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document -> Vector DB Ï†ÄÏû•\n",
    "def docs_to_chroma_db(docs, collection_name):\n",
    "    db = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=FILE_PATH['VECTOR_DB'],\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDBÏóê Ï†ÄÏû•\n",
    "term_db = docs_to_chroma_db(term_docs, VECTOR_DB_COLLECTION['TERM'])\n",
    "precedent_db = docs_to_chroma_db(precedent_docs, VECTOR_DB_COLLECTION['PRECEDENT'])\n",
    "load_traffic_law_db = docs_to_chroma_db(load_traffic_law_docs, VECTOR_DB_COLLECTION['LOAD_TRAFFIC_LAW'])\n",
    "\n",
    "car_case_db = docs_to_chroma_db(car_case_docs + modifier_docs, VECTOR_DB_COLLECTION['CAR_CASE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b607b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# # 1. Ï≤≠ÌÅ¨ ÌÅ¨Í∏∞ Ï°∞Ï†ï (500~1000 Í∂åÏû•)\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=500,\n",
    "#     chunk_overlap=100,\n",
    "#     length_function=len,\n",
    "#     separators=[\"\\n\\n\", \"\\n\", \"(?<=\\\\. )\", \" \", \"\"],\n",
    "#     is_separator_regex=True,\n",
    "# )\n",
    "\n",
    "# # 2. Î¨∏ÏÑú Î∂ÑÌï†\n",
    "# all_splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "# # 3. ÏûÑÎ≤†Îî© Î™®Îç∏ ()\n",
    "# embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "# # 4. Chroma DBÏóê Î∞∞Ïπò Ï≤òÎ¶¨Î°ú Ï†ÄÏû•\n",
    "# batch_size = 100  # Ìïú Î≤àÏóê Ï≤òÎ¶¨Ìï† Ï≤≠ÌÅ¨ Ïàò\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=all_splits[:batch_size],  # Ï≤´ Î∞∞Ïπò\n",
    "#     embedding=embedding_model,\n",
    "#     persist_directory=FILE_PATH['VECTOR_DB']\n",
    "# )\n",
    "\n",
    "# # ÎÇ®ÏùÄ Ï≤≠ÌÅ¨Î•º ÏàúÏ∞®Ï†ÅÏúºÎ°ú Ï∂îÍ∞Ä \n",
    "# for i in range(0, len(all_splits), batch_size):\n",
    "#     try:\n",
    "#         batch = all_splits[i:i+batch_size]\n",
    "#         vectorstore.add_documents(batch)\n",
    "#         vectorstore.persist()  # Îß§ Î∞∞Ïπò ÌõÑ Ï¶âÏãú Ï†ÄÏû•\n",
    "#     except Exception as e:\n",
    "#         print(f\"Î∞∞Ïπò {i}~{i+batch_size} Ï†ÄÏû• Ïã§Ìå®: {e}\")\n",
    "\n",
    "# vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a890d",
   "metadata": {},
   "source": [
    "# ÏÇ¨Ïö©Ïûê Î™©Ï†ÅÏóê Îî∞Î•∏ LLM ÏàòÌñâÎèôÏûë Î∂ÑÎ¶¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabc9ac",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í∏∞Îä• Î∂ÑÎ•ò Î∞è ÎùºÏö∞ÌåÖ Ï≤òÎ¶¨ + ÏÇ¨Í≥† ÏÉÅÌô© Í∏∞Î∞ò Í≥ºÏã§ÎπÑÏú® ÌåêÎã® Ìè¨Ìï®\n",
    "import re\n",
    "import numpy as np\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31afb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏÇ¨Ïö©Ïûê ÏßàÏùò Î™©Ï†Å Ï†ïÏùò\n",
    "SITUATION_CASE = {\n",
    "    'GENERAL' : \"general\",\n",
    "\n",
    "    'ACCIDENT' : \"accident\",\n",
    "    'TERM' : \"term\",\n",
    "    'PRECEDENT' : \"precedent\",\n",
    "    'LAW' : \"law\",\n",
    "}\n",
    "\n",
    "GPT_4O_MODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "GPT_3_5_MODEL = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbc829",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c40195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏßàÏùò Î™©Ï†Å Íµ¨Î∂Ñ\n",
    "def classify_query(user_input: str) -> str:\n",
    "    classification_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ÎÑàÎäî ÍµêÌÜµÏÇ¨Í≥† ÏÉÅÎã¥ Ï±óÎ¥áÏùò ÏßàÎ¨∏ Î∂ÑÎ•òÍ∏∞Ïïº.\n",
    "\n",
    "ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïù¥ Îã§Ïùå Ï§ë Ïñ¥Îñ§ Ïú†ÌòïÏù∏ÏßÄ ÌåêÎã®Ìï¥:\n",
    "\n",
    "1. ÏÇ¨Í≥† ÏÉÅÌô© ÌåêÎã® ÏßàÎ¨∏ (Ïòà: ÏÇ¨Í≥† Í≤ΩÏúÑ ÏÑ§Î™Ö, Í≥ºÏã§ÎπÑÏú® ÏöîÏ≤≠)\n",
    "2. ÎèÑÎ°úÍµêÌÜµÎ≤ïÎ•† ÏÑ§Î™Ö ÏßàÎ¨∏ (Ïòà: ÎèÑÎ°úÍµêÌÜµÎ≤ï Ï°∞Ìï≠ Ï†ïÏùò, ÎèÑÎ°úÍµêÌÜµÎ≤ï Ï†ú5Ï°∞ 1Ìï≠ Îì±)\n",
    "3. ÌåêÎ°Ä ÏÑ§Î™Ö ÏßàÎ¨∏ (Ïòà: ÌåêÎ°Ä Î≤àÌò∏, ÏÑúÏö∏Í≥†Îì±Î≤ïÏõê 2002ÎÇò57692 Îì±)\n",
    "4. ÍµêÌÜµÏÇ¨Í≥† Ïö©Ïñ¥ ÏÑ§Î™Ö ÏßàÎ¨∏ (Ïòà: Ïö©Ïñ¥, 'Í≥ºÏã§' Ï†ïÏùò, 'ÌöåÏ†ÑÍµêÏ∞®Î°ú' Ï†ïÏùò Îì±)\n",
    "5. ÏùºÎ∞ò ÏßàÎ¨∏ (Ïòà: \"ÎÑàÎäî ÎàÑÍµ¨Ïïº?\", \"ÎÇ†Ïî® Ïñ¥Îïå?\", \"GPTÎûÄ Î≠êÏïº?\" Îì± ÍµêÌÜµÏÇ¨Í≥†ÏôÄ Î¨¥Í¥ÄÌïú ÏßàÎ¨∏)\n",
    "\n",
    "Ï∂úÎ†•ÏùÄ Î∞òÎìúÏãú ÏïÑÎûò Ï§ë ÌïòÎÇòÎßå Ìï¥:\n",
    "- accident\n",
    "- precedent\n",
    "- law\n",
    "- term\n",
    "- general\n",
    "\n",
    "Îã§Î•∏ Îßê ÏóÜÏù¥ ÏúÑ Îã§ÏÑØ Îã®Ïñ¥ Ï§ë ÌïòÎÇòÎßå Ï†ïÌôïÌûà Ï∂úÎ†•Ìï¥.\n",
    "\n",
    "ÏßàÎ¨∏:\n",
    "{question}\n",
    "\n",
    "Ï∂úÎ†•:\n",
    "\"\"\")\n",
    "    \n",
    "    prompt = classification_prompt.format(question=user_input)\n",
    "    result = GPT_4O_MODEL.invoke(prompt)\n",
    "\n",
    "    return result.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏßàÏùò Î™©Ï†Å : ÏÇ¨Í≥† Í≥ºÏã§ ÎπÑÏú®\n",
    "# SITUATION_CASE['ACCIDENT'] = \"accident\"\n",
    "def process_accident(user_input: str) -> str:\n",
    "    # car_case Î¨∏ÏÑú ÌïÑÌÑ∞ÎßÅ Î∞è ÏÇ¨Í≥†ÏÉÅÌô© Ï∂îÏ∂ú\n",
    "    case_texts = [doc.metadata.get(\"situation\", \"\") for doc in car_case_docs if doc.metadata.get(\"situation\")]\n",
    "\n",
    "    # ko-sbert ÏûÑÎ≤†Îî©\n",
    "    embed_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "    case_embeddings = embed_model.encode(case_texts)\n",
    "\n",
    "    # ÏÇ¨Ïö©Ïûê ÏûÖÎ†•\n",
    "    query_embedding = embed_model.encode([user_input])[0]\n",
    "\n",
    "    # ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞ Î∞è Top-3 Ï∂îÏ∂ú\n",
    "    cos_similarities = np.dot(case_embeddings, query_embedding) / (\n",
    "        np.linalg.norm(case_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "    )\n",
    "    top_k_idx = np.argsort(cos_similarities)[-3:][::-1]\n",
    "    top_candidates = [car_case_docs[i] for i in top_k_idx]\n",
    "\n",
    "    # ÌåêÎ°Ä ÏöîÏïΩ Ï∂úÎ†•\n",
    "    def summarize(doc, idx):\n",
    "        return f\"{idx+1}. ÏÇ¨Í±¥ ID: {doc.metadata.get('id')}\\nÏÇ¨Í≥†ÏÉÅÌô©: {doc.metadata.get('situation')}\"\n",
    "\n",
    "    case_summaries = \"\\n\\n\".join([summarize(doc, i) for i, doc in enumerate(top_candidates)])\n",
    "\n",
    "    # GPT - ÏÇ¨Í±¥ID ÏÑ†ÌÉù(3Í∞ú Ï§ëÏóê ÌïòÎÇò ÌåêÎã®)\n",
    "    selection_prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"case_summaries\"],\n",
    "        template=\"\"\"\n",
    "    [ÏÇ¨Ïö©Ïûê ÏûÖÎ†• ÏÇ¨Í≥† ÏÉÅÌô©]\n",
    "    {user_input}\n",
    "\n",
    "    [ÌõÑÎ≥¥ ÌåêÎ°Ä 3Í±¥]\n",
    "    {case_summaries}\n",
    "\n",
    "    ÏúÑ 3Í±¥ Ï§ë, ÏÇ¨Í≥†Ïùò Ï†ÑÍ∞ú Íµ¨Ï°∞(Ïòà: ÏßÅÏßÑ vs Ï¢åÌöåÏ†Ñ, ÎèÑÎ°ú Ïô∏ Ïû•ÏÜåÏóêÏÑú ÏßÑÏûÖ, ÍµêÏ∞®Î°ú ÎÇ¥ ÏßÑÏûÖ Ïó¨Î∂Ä Îì±)Í∞Ä ÏÇ¨Ïö©Ïûê ÏÉÅÌô©Í≥º Í∞ÄÏû• Ïú†ÏÇ¨Ìïú **ÏÇ¨Í±¥ ID** ÌïòÎÇòÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.\n",
    "\n",
    "    Î∞òÎìúÏãú Îã§Ïùå Í∏∞Ï§ÄÏùÑ Í≥†Î†§ÌïòÏÑ∏Ïöî:\n",
    "    - Ï∞®ÎüâÎì§Ïùò ÏúÑÏπòÏôÄ ÏßÑÏûÖ Í≤ΩÎ°úÍ∞Ä Ïú†ÏÇ¨ÌïúÍ∞Ä?\n",
    "    - ÏÇ¨Í≥† Î∞úÏÉù ÏßÄÏ†êÍ≥º Î∞©Ìñ•Ïù¥ Ïú†ÏÇ¨ÌïúÍ∞Ä?\n",
    "    - Í∞Å Ï∞®ÎüâÏùò Ïã†Ìò∏¬∑Ïö∞ÏÑ†Í∂å ÏÉÅÌô©Ïù¥ Ïú†ÏÇ¨ÌïúÍ∞Ä?|\n",
    "    - ÎèÑÎ°ú Íµ¨Ï°∞(ÍµêÏ∞®Î°ú, Ïã†Ìò∏ Ïú†Î¨¥, ÎèÑÎ°ú Ïô∏ Ïû•ÏÜå Îì±)Í∞Ä Ïú†ÏÇ¨ÌïúÍ∞Ä?\n",
    "\n",
    "    Ï∂úÎ†• ÌòïÏãù (Í≥†Ï†ï):\n",
    "    - ÏÇ¨Í±¥ ID: Ï∞®XX-X\n",
    "    - ÌåêÎã® Í∑ºÍ±∞: (ÏÑ†ÌÉùÌïú Ïù¥Ïú†. Îã®Ïàú Ïú†ÏÇ¨ÏÑ±Ïù¥ ÏïÑÎãàÎùº, Ïñ¥Îñ§ ÏßÄÏ†êÏù¥ Ïú†ÏÇ¨ÌñàÎäîÏßÄ Î™ÖÌôïÌûà ÏÑ§Î™ÖÌï† Í≤É)\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    selection_chain = LLMChain(llm=GPT_4O_MODEL, prompt=selection_prompt)\n",
    "    selection_result = selection_chain.run(user_input=user_input, case_summaries=case_summaries)\n",
    "\n",
    "    # ÏÇ¨Í±¥ ID ÌååÏã± Î∞è ÏÑ†ÌÉù\n",
    "    match = re.search(r\"ÏÇ¨Í±¥ ID[:Ôºö]?\\s*(Ï∞®\\d{1,2}-\\d{1,2})\", selection_result)\n",
    "    selected_id = match.group(1) if match else None\n",
    "    selected_doc = next((doc for doc in car_case_docs if doc.metadata.get(\"id\") == selected_id), None)\n",
    "\n",
    "    # ÏµúÏ¢Ö ÌåêÎã® GPT ÌîÑÎ°¨ÌîÑÌä∏(ÏÑ†ÌÉùÌïú ÏÇ¨Í±¥ object ÎÇ¥ÏóêÏÑú Í≥ºÏã§ÎπÑÏú® ÌåêÎã®)\n",
    "    if selected_doc:\n",
    "        # Ìï¥Îãπ ÏÇ¨Í±¥ Í¥ÄÎ†® Î≥¥Ï°∞ Î¨∏ÏÑúÎì§ÏùÑ Ìï®Íªò Ï†ÑÎã¨\n",
    "        related_docs = [doc for doc in car_case_docs if selected_id in doc.page_content]\n",
    "        context_str = \"\\n\\n\".join(doc.page_content for doc in related_docs)\n",
    "\n",
    "        final_prompt = PromptTemplate(\n",
    "            input_variables=[\"user_input\", \"case_data\"],\n",
    "            template=\"\"\"\n",
    "    ÎÑàÎäî ÍµêÌÜµÏÇ¨Í≥† Í≥ºÏã§ ÌåêÎã® Ï†ÑÎ¨∏Í∞ÄÏïº.\n",
    "    ÏïÑÎûò 'ÏÇ¨Í≥† ÏÉÅÌô©'ÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÌïµÏã¨ ÏöîÏÜåÎ•º Íµ¨Ï°∞ÌôîÌïòÍ≥†, Î∞òÎìúÏãú Î¨∏ÏÑú ÎÇ¥ÏóêÏÑú Í∞ÄÏû• Ïú†ÏÇ¨Ìïú ÏÇ¨Î°Ä(case)Î•º Ï∞æÏïÑ Í≥ºÏã§ÎπÑÏú®ÏùÑ ÌåêÎã®Ìï¥Ï§ò.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ÏÇ¨Í≥† ÏÉÅÌô© ÏõêÎ¨∏:\n",
    "    {user_input}\n",
    "\n",
    "    ‚û§ ÏÇ¨Í≥† ÏÉÅÌô© ÏöîÏïΩ (Îã§Ïùå Ìï≠Î™© Í∏∞Ï§Ä):\n",
    "    - AÏ∞®Îüâ Ïã†Ìò∏ Î∞è ÏßÑÌñâ Î∞©Ïãù:\n",
    "    - BÏ∞®Îüâ Ïã†Ìò∏ Î∞è ÏßÑÌñâ Î∞©Ïãù:\n",
    "    - Ï∂©Îèå Î∞©Ïãù Î∞è ÏúÑÏπò:\n",
    "    - ÍµêÏ∞®Î°ú/Ïã†Ìò∏Í∏∞ Ïú†Î¨¥ Îì± ÎèÑÎ°ú ÌôòÍ≤Ω:\n",
    "\n",
    "    Î¨∏ÏÑú:\n",
    "    {case_data}\n",
    "\n",
    "    Ï∂úÎ†• ÌòïÏãù (Í≥†Ï†ï):\n",
    "    1. Í≥ºÏã§ÎπÑÏú®: AÏ∞®Îüâ xx% vs BÏ∞®Îüâ xx%\n",
    "    2. ÌåêÎã® Í∑ºÍ±∞ ÏöîÏïΩ\n",
    "    3. Ï†ÅÏö© Î≤ïÎ•†:\n",
    "    - [Î≤ïÎ•†Î™Ö] Ï†ú[Ï°∞]Ï°∞ [Ìï≠]\n",
    "    4. Ï∞∏Í≥† ÌåêÎ°Ä:\n",
    "    - [Î≤ïÏõêÎ™Ö] [ÏÇ¨Í±¥Î≤àÌò∏]\n",
    "\n",
    "    Ï°∞Í±¥:\n",
    "    - Î∞òÎìúÏãú Î¨∏ÏÑú ÎÇ¥ Ïú†ÏÇ¨ ÏÇ¨Î°ÄÎ•º Í∏∞Î∞òÏúºÎ°ú ÌåêÎã®Ìï¥Ïïº Ìï¥.\n",
    "    - Ïú†ÏÇ¨ ÏÇ¨Î°ÄÏôÄ ÌòÑÏû¨ ÏÇ¨Í≥† ÏÉÅÌô©Ïù¥ Ï†ïÌôïÌûà ÏùºÏπòÌïòÏßÄ ÏïäÏúºÎ©¥, Ï∞®Ïù¥Ï†êÏùÑ Î™ÖÏãúÌïòÍ≥† Í≥ºÏã§ÎπÑÏú® Ï°∞Ï†ï Ïù¥Ïú†Î•º ÏÑ§Î™ÖÌï¥.\n",
    "    - Ï∂îÏ∏°Ïù¥ÎÇò ÏÉÅÏãùÏùÄ ÏÇ¨Ïö©ÌïòÏßÄ ÎßêÍ≥†, Î¨∏ÏÑú Ï†ïÎ≥¥ÎßåÏùÑ Í∏∞Î∞òÏúºÎ°ú ÌåêÎã®Ìï¥.\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "        chain = LLMChain(llm=GPT_4O_MODEL, prompt=final_prompt)\n",
    "        response = chain.run(user_input=user_input, case_data=context_str)\n",
    "\n",
    "        print(f\"\\nÏÑ†ÌÉùÎêú ÏÇ¨Í±¥ ID: {selected_id}\")\n",
    "        print(\"GPT ÏµúÏ¢Ö ÌåêÎã® Í≤∞Í≥º:\\n\")\n",
    "        print(response)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n‚ùå ÏÇ¨Í±¥ IDÎ•º Ï†ïÌôïÌûà ÏÑ†ÌÉùÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§.\")\n",
    "        print(\"GPT ÏùëÎãµ:\\n\", selection_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏßàÏùò Î™©Ï†Å : ÌåêÎ°Ä Í≤ÄÏÉâ\n",
    "# SITUATION_CASE['PRECEDENT'] = \"precedent\"\n",
    "def process_precedent(user_input):\n",
    "    # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌïÑÎìú Ï†ïÏùò (ÌïÑÏàò!)\n",
    "    metadata_field_info = [\n",
    "        AttributeInfo(\n",
    "            name=METADATA_KEY['PRECEDENT']['COURT'],\n",
    "            description=\"ÌåêÎ°ÄÏùò Î≤ïÏõêÎ™Ö (Ïòà: ÎåÄÎ≤ïÏõê, ÏÑúÏö∏Í≥†Îì±Î≤ïÏõê Îì±)\",\n",
    "            type=\"string\"\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=METADATA_KEY['PRECEDENT']['CASE_ID'],\n",
    "            description=\"ÏÇ¨Í±¥Î≤àÌò∏ (Ïòà: 92ÎèÑ2077)\",\n",
    "            type=\"string\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # SelfQueryRetriever ÏÉùÏÑ± (metadata_field_info ÌïÑÏàò)\n",
    "    self_retriever = SelfQueryRetriever.from_llm(\n",
    "        llm=GPT_4O_MODEL,\n",
    "        vectorstore=precedent_db,\n",
    "        document_contents=\"ÍµêÌÜµÏÇ¨Í≥† ÌåêÎ°Ä Îç∞Ïù¥ÌÑ∞\",\n",
    "        metadata_field_info=metadata_field_info  # ‚úÖ Î∞òÎìúÏãú ÌïÑÏöî\n",
    "    )\n",
    "\n",
    "\n",
    "    # ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"context\"],\n",
    "        template=\"\"\"ÏïÑÎûò Î¨∏ÏÑú ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©ÏûêÍ∞Ä Î¨ºÏñ¥Î≥∏ ÌåêÎ°ÄÏóê ÎåÄÌï¥ Ï†ïÌôïÌïòÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî.\n",
    "        \n",
    "        ÏßàÎ¨∏: {question}\n",
    "        \n",
    "        Î¨∏ÏÑú: {context}\n",
    "\n",
    "        ÎãµÎ≥Ä ÌòïÏãù:\n",
    "        - Ïö©Ïñ¥/Ï°∞Ìï≠ Ï†ïÏùò: [Ï†ïÌôïÌïú ÏÑ§Î™Ö]\n",
    "        - Ï∂úÏ≤òÍ∞Ä Î™ÖÏãúÎêú Í≤ΩÏö∞: Í¥ÄÎ†® Î≤ïÎ•†/Ï°∞Î¨∏ Î≤àÌò∏/ÌåêÎ°ÄÎ™ÖÏùÑ Î∞òÎìúÏãú Ìè¨Ìï®\n",
    "\n",
    "        ÎãµÎ≥Ä:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # QA Ï≤¥Ïù∏ Íµ¨ÏÑ± Î∞è Ïã§Ìñâ\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=GPT_4O_MODEL,\n",
    "        retriever=self_retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": user_input})\n",
    "    return f\"[ÌåêÎ°Ä ÏÑ§Î™Ö Í≤∞Í≥º]\\n{result['result']}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eacef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏßàÏùò Î™©Ï†Å : Ïö©Ïñ¥ Í≤ÄÏÉâ\n",
    "# SITUATION_CASE['TERM'] = \"term\"\n",
    "def process_term(user_input):\n",
    "    # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌïÑÎìú Ï†ïÏùò (ÌïÑÏàò!)\n",
    "    metadata_field_info = [\n",
    "        AttributeInfo(\n",
    "            name=METADATA_KEY['TERM']['TERM'],\n",
    "            description=\"ÍµêÌÜµÏÇ¨Í≥† Í¥ÄÎ†® Ïö©Ïñ¥ (Ïòà: Î≥¥ÌñâÏûêÏ†ÑÏö©ÎèÑÎ°ú, Ï∞®Îßà Îì±)\",\n",
    "            type=\"string\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # SelfQueryRetriever ÏÉùÏÑ± (metadata_field_info ÌïÑÏàò)\n",
    "    self_retriever = SelfQueryRetriever.from_llm(\n",
    "        llm=GPT_4O_MODEL,\n",
    "        vectorstore=term_db,\n",
    "        document_contents=\"ÍµêÌÜµÏÇ¨Í≥† Í¥ÄÎ†® Ïö©Ïñ¥ Îç∞Ïù¥ÌÑ∞\",\n",
    "        metadata_field_info=metadata_field_info  # ‚úÖ Î∞òÎìúÏãú ÌïÑÏöî\n",
    "    )\n",
    "\n",
    "\n",
    "    # ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"context\"],\n",
    "        template=\"\"\"ÏïÑÎûò Î¨∏ÏÑú ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©ÏûêÍ∞Ä Î¨ºÏñ¥Î≥∏ Ïö©Ïñ¥Ïóê ÎåÄÌï¥ Ï†ïÌôïÌïòÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî.\n",
    "        \n",
    "        ÏßàÎ¨∏: {question}\n",
    "        \n",
    "        Î¨∏ÏÑú: {context}\n",
    "\n",
    "        ÎãµÎ≥Ä ÌòïÏãù:\n",
    "        - Ïö©Ïñ¥/Ï°∞Ìï≠ Ï†ïÏùò: [Ï†ïÌôïÌïú ÏÑ§Î™Ö]\n",
    "        - Ï∂úÏ≤òÍ∞Ä Î™ÖÏãúÎêú Í≤ΩÏö∞: Í¥ÄÎ†® Î≤ïÎ•†/Ï°∞Î¨∏ Î≤àÌò∏/ÌåêÎ°ÄÎ™ÖÏùÑ Î∞òÎìúÏãú Ìè¨Ìï®\n",
    "\n",
    "        ÎãµÎ≥Ä:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # QA Ï≤¥Ïù∏ Íµ¨ÏÑ± Î∞è Ïã§Ìñâ\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=GPT_4O_MODEL,\n",
    "        retriever=self_retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": user_input})\n",
    "    return f\"[Ïö©Ïñ¥ ÏÑ§Î™Ö Í≤∞Í≥º]\\n{result['result']}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b45297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏßàÏùò Î™©Ï†Å : ÎèÑÎ°úÍµêÌÜµÎ≤ïÎ≤ï Í≤ÄÏÉâ\n",
    "# SITUATION_CASE['TERM'] = \"term\"\n",
    "def process_load_traffic_law(user_input):\n",
    "    # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌïÑÎìú Ï†ïÏùò (ÌïÑÏàò!)\n",
    "    metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"Î≤ïÎ•†Ï°∞Î¨∏\",\n",
    "        description=\"Î≤ïÎ•†Ïùò Ï°∞Î¨∏ Î≤àÌò∏ (Ïòà: Ï†ú5Ï°∞, Ï†ú8Ï°∞)\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Ï°∞Ìï≠Î™Ö\",\n",
    "        description=\"Ï°∞Ìï≠Ïùò Ï†úÎ™© (Ïòà: Ïã†Ìò∏ ÎòêÎäî ÏßÄÏãúÏóê Îî∞Î•º ÏùòÎ¨¥, Î≥¥ÌñâÏûêÏùò ÌÜµÌñâ)\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Ìï≠Î≤àÌò∏\",\n",
    "        description=\"Ï°∞Ìï≠ ÎÇ¥ Ìï≠ Î≤àÌò∏ (Ïòà: 1, 2, 3, ...)\",\n",
    "        type=\"integer\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Ï†ÑÏ≤¥Ï∞∏Ï°∞\",\n",
    "        description=\"Ï°∞Î¨∏Í≥º Ìï≠ÏùÑ Ìï©Ïπú Ï†ÑÏ≤¥ Ï∞∏Ï°∞ (Ïòà: Ï†ú5Ï°∞ 1Ìï≠)\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "    # SelfQueryRetriever ÏÉùÏÑ± (metadata_field_info ÌïÑÏàò)\n",
    "    self_retriever = SelfQueryRetriever.from_llm(\n",
    "        llm=GPT_4O_MODEL,\n",
    "        vectorstore=load_traffic_law_db,\n",
    "        document_contents=\"ÎèÑÎ°úÍµêÌÜµÎ≤ï Ï°∞Î¨∏ Î∞è Ìï≠Ïùò Ï£ºÏöî ÎÇ¥Ïö©\",\n",
    "        metadata_field_info=metadata_field_info  # ‚úÖ Î∞òÎìúÏãú ÌïÑÏöî\n",
    "    )\n",
    "\n",
    "\n",
    "    # ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"context\"],\n",
    "        template=\"\"\"ÏïÑÎûò Î¨∏ÏÑú ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©ÏûêÍ∞Ä Î¨ºÏñ¥Î≥∏ ÎèÑÎ°úÍµêÌÜµÎ≤ï ÎÇ¥Ïö©Ïö©Ïóê ÎåÄÌï¥ Ï†ïÌôïÌïòÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî.\n",
    "        \n",
    "        ÏßàÎ¨∏: {question}\n",
    "        \n",
    "        Î¨∏ÏÑú: {context}\n",
    "\n",
    "        ÎãµÎ≥Ä ÌòïÏãù:\n",
    "        - Ïö©Ïñ¥/Ï°∞Ìï≠ Ï†ïÏùò: [Ï†ïÌôïÌïú ÏÑ§Î™Ö]\n",
    "        - Ï∂úÏ≤òÍ∞Ä Î™ÖÏãúÎêú Í≤ΩÏö∞: Í¥ÄÎ†® Î≤ïÎ•†/Ï°∞Î¨∏ Î≤àÌò∏/ÌåêÎ°ÄÎ™ÖÏùÑ Î∞òÎìúÏãú Ìè¨Ìï®\n",
    "\n",
    "        ÎãµÎ≥Ä:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # QA Ï≤¥Ïù∏ Íµ¨ÏÑ± Î∞è Ïã§Ìñâ\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=GPT_4O_MODEL,\n",
    "        retriever=self_retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": user_input})\n",
    "    return f\"[ÎèÑÎ°úÍµêÌÜµÎ≤ïÎ°úÍµêÌÜµÎ≤ï ÏÑ§Î™Ö Í≤∞Í≥º]\\n{result['result']}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_general(user_input):\n",
    "    general_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ÎÑàÎäî ÍµêÌÜµÏÇ¨Í≥† ÏÉÅÎã¥ Ï†ÑÎ¨∏ AI Ï±óÎ¥áÏù¥Ïïº.\n",
    "\n",
    "ÍµêÌÜµÏÇ¨Í≥† ÌåêÎ°Ä, ÎèÑÎ°úÍµêÌÜµÎ≤ï, Î≤ïÎ•† Ïö©Ïñ¥ Îì±Ïóê ÎåÄÌï¥ ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÎèÑÏõÄÏùÑ Ï£ºÎäî Ïó≠Ìï†ÏùÑ Ìï¥.\n",
    "\n",
    "ÌïòÏßÄÎßå ÏïÑÎûòÏôÄ Í∞ôÏùÄ ÏÉÅÌô©ÏóêÏÑúÎèÑ ÌòºÏûê Ïú†Ïó∞ÌïòÍ≤å ÎãµÎ≥ÄÌï¥Ïïº Ìï¥:\n",
    "- Î¨∏ÏÑúÏóêÏÑú Ï∞æÏùÑ Ïàò ÏóÜÎäî Ïö©Ïñ¥, Î≤ïÎ•† Ï°∞Ìï≠, ÌåêÎ°Ä Î≤àÌò∏Í∞Ä ÎÇòÏôîÏùÑ Í≤ΩÏö∞\n",
    "- Î¨∏ÏÑúÏóê ÏóÜÎäî ÏßàÎ¨∏Ïù¥ÎùºÎèÑ, ÎÑàÏùò ÏßÄÏãùÍ≥º ÏÉÅÏãùÏúºÎ°ú ÏÑ§Î™ÖÏù¥ Í∞ÄÎä•Ìïú Í≤ΩÏö∞\n",
    "- Î¨∏ÏÑúÏôÄ ÏÉÅÍ¥ÄÏóÜÎäî ÏùºÎ∞òÏ†ÅÏù∏ ÏßàÎ¨∏ (Ïòà: ÏûêÍ∏∞ÏÜåÍ∞ú, Ïù∏Í≥µÏßÄÎä•, ÎÇ†Ïî® Îì±)\n",
    "\n",
    "Ïù¥Îü¥ Îïê ‚ÄúÎ¨∏ÏÑúÏóê Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏßÄ ÏïäÏäµÎãàÎã§‚Äù Í∞ôÏùÄ ÎßêÏùÄ ÌïòÏßÄ ÎßêÍ≥†,\n",
    "AI Ï±óÎ¥áÏúºÎ°úÏÑú ÎÑàÏùò ÏßÄÏãùÏúºÎ°ú ÏµúÎåÄÌïú Ï†ïÌôïÌïòÍ≥† ÏûêÏó∞Ïä§ÎüΩÍ≤å ÎãµÎ≥ÄÌï¥Ï§ò.\n",
    "\n",
    "ÏßàÎ¨∏:\n",
    "{question}\n",
    "\n",
    "ÎãµÎ≥Ä:\n",
    "\"\"\")    \n",
    "    \n",
    "    prompt = general_prompt.format(question=user_input)    \n",
    "    result = GPT_3_5_MODEL.invoke(prompt)\n",
    "    \n",
    "    return result.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd140c",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITUATION_CASE = {\n",
    "    'GENERAL' : \"general\",\n",
    "\n",
    "    'ACCIDENT' : \"accident\",\n",
    "    'TERM' : \"term\",\n",
    "    'PRECEDENT' : \"precedent\",\n",
    "    'LAW' : \"law\",\n",
    "}\n",
    "# ÌîÑÎ°úÍ∑∏Îû® Ïã§Ìñâ\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöó ÍµêÌÜµÏÇ¨Í≥† AI Î∂ÑÏÑùÍ∏∞ÏûÖÎãàÎã§.\")\n",
    "    print(\"ÏÇ¨Í≥† ÏÉÅÌô©Ïù¥ÎÇò ÏïåÍ≥† Ïã∂ÏùÄ Î≤ïÎ•†/ÌåêÎ°Ä Ï†ïÎ≥¥Î•º ÏûÖÎ†•Ìï¥ Ï£ºÏÑ∏Ïöî.\")\n",
    "    user_input = input(\"ÏûÖÎ†• > \").strip()\n",
    "\n",
    "    if user_input:\n",
    "        category = classify_query(user_input)\n",
    "        print(category)\n",
    "        \n",
    "        if (category == SITUATION_CASE['ACCIDENT']):\n",
    "            response = process_accident(user_input)\n",
    "        elif (category == SITUATION_CASE['TERM']):\n",
    "            response = process_term(user_input)\n",
    "        elif (category == SITUATION_CASE['PRECEDENT']):\n",
    "            response = process_precedent(user_input)\n",
    "        elif (category == SITUATION_CASE['LAW']):\n",
    "            response = process_load_traffic_law(user_input)\n",
    "        else:\n",
    "            response = process_general(user_input)\n",
    "        print(\"\\nüìò Í≤∞Í≥º Ï∂úÎ†•:\\n\")\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"‚ùå ÏûÖÎ†•Ïù¥ ÎπÑÏñ¥ÏûàÏäµÎãàÎã§. ÌîÑÎ°úÍ∑∏Îû®ÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344ba04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
